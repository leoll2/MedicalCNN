{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Scratch_CNN_4_class.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxomVJNs0j51",
        "colab_type": "text"
      },
      "source": [
        "# Environment setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxvRGmwLzQKm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Connect to Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTygnMX_0yM0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copy the dataset from Google Drive to local\n",
        "\n",
        "!cp \"/content/gdrive/My Drive/CBIS_DDSM.zip\" .\n",
        "!unzip -qq CBIS_DDSM.zip\n",
        "!rm CBIS_DDSM.zip\n",
        "cbis_path = 'CBIS_DDSM'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zb4q_kXo2Wz-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import libraries\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import itertools\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, Callback\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKn5o0nd2c_r",
        "colab_type": "text"
      },
      "source": [
        "# Data pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvffFA7C2bD9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_training():\n",
        "    \"\"\"\n",
        "    Load the training set (excluding baseline patches)\n",
        "    \"\"\"\n",
        "    images = np.load(os.path.join(cbis_path, 'numpy data', 'train_tensor.npy'))[1::2]\n",
        "    labels = np.load(os.path.join(cbis_path, 'numpy data', 'train_labels.npy'))[1::2]\n",
        "    return images, labels\n",
        "\n",
        "\n",
        "def load_testing():\n",
        "    \"\"\"\n",
        "    Load the test set (abnormalities patches and labels, no baseline)\n",
        "    \"\"\"\n",
        "    images = np.load(os.path.join(cbis_path, 'numpy data', 'public_test_tensor.npy'))[1::2]\n",
        "    labels = np.load(os.path.join(cbis_path, 'numpy data', 'public_test_labels.npy'))[1::2]\n",
        "    return images, labels\n",
        "\n",
        "\n",
        "def remap_label(l):\n",
        "    \"\"\"\n",
        "    Remap the labels to:\n",
        "        0 -> mass benign \n",
        "        1 -> mass malignant\n",
        "        2 -> calcification benign\n",
        "        3 -> calcification malignant\n",
        "    \"\"\"\n",
        "    if 1 <= l <= 4:\n",
        "        return l-1\n",
        "    else:\n",
        "        print(\"[WARN] Unrecognized label (%d)\" % l)\n",
        "        return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_Q0cPtr3jJt",
        "colab_type": "text"
      },
      "source": [
        "The data is prepared following these steps:\n",
        "\n",
        "\n",
        "1.   Import the training and testing data from numpy arrays\n",
        "2.   Remove the images and labels related to baseline patches (even indices in the arrays)\n",
        "3.   Adjust the labels for the classification problem, so that 0 corresponds to 'benign mass', 1 to 'malignant mass', 2 to 'bening calcification' and 3 to 'malignant calcification'\n",
        "4.   Convert the labels to categorical format, required by the categorical_crossentropy loss function\n",
        "5.   Normalize the pixels to be in the range (0-1) floating point\n",
        "6.   Shuffle the training set (and labels accordingly, of course)\n",
        "7.   Split the training data into 'training' and 'validation' subsets\n",
        "8.   Build Keras generators for training and validation data. Note that data augmentation is used from the beginning, as its value was proven in the previous notebook (Scratch_CNN_2_class)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkNzi8mk3j3P",
        "colab_type": "code",
        "outputId": "6b2891fc-392d-4953-f54b-59306c6740e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Load training and test images (abnormalities only, no baseline)\n",
        "train_images, train_labels= load_training()\n",
        "test_images, test_labels= load_testing()\n",
        "\n",
        "# Number of images\n",
        "n_train_img = train_images.shape[0]\n",
        "n_test_img = test_images.shape[0]\n",
        "print(\"Train size: %d \\t Test size: %d\" % (n_train_img, n_test_img))\n",
        "\n",
        "# Compute width and height of images\n",
        "img_w = train_images.shape[1]\n",
        "img_h = train_images.shape[2]\n",
        "print(\"Image size: %dx%d\" % (img_w, img_h))\n",
        "\n",
        "# Remap labels\n",
        "train_labels = np.array([remap_label(l) for l in train_labels])\n",
        "test_labels = np.array([remap_label(l) for l in test_labels])\n",
        "\n",
        "# Convert the labels to categorical format\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels_raw = test_labels.copy()\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "# Create a new dimension for color in the images arrays\n",
        "train_images = train_images.reshape((n_train_img, img_w, img_h, 1))\n",
        "test_images = test_images.reshape((n_test_img, img_w, img_h, 1))\n",
        "\n",
        "# Convert from 16-bit (0-65535) to float (0-1)\n",
        "train_images = train_images.astype('uint16') / 65535\n",
        "test_images = test_images.astype('uint16') / 65535\n",
        "\n",
        "# Shuffle the training set (originally sorted by label)\n",
        "perm = np.random.permutation(n_train_img)\n",
        "train_images = train_images[perm]\n",
        "train_labels = train_labels[perm]\n",
        "\n",
        "# Create a generator for training images\n",
        "train_datagen = ImageDataGenerator(\n",
        "    validation_split=0.2,\n",
        "    rotation_range=180,\n",
        "    shear_range=10,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    fill_mode='reflect'\n",
        ")\n",
        "\n",
        "# Fit the generator with some images\n",
        "train_datagen.fit(train_images)\n",
        "\n",
        "# Split train images into actual training and validation\n",
        "train_generator = train_datagen.flow(train_images, train_labels, batch_size=128, subset='training')\n",
        "validation_generator = train_datagen.flow(train_images, train_labels, batch_size=128, subset='validation')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size: 2676 \t Test size: 336\n",
            "Image size: 150x150\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDplDtnJ6Tl9",
        "colab_type": "code",
        "outputId": "50498bed-a954-4b43-e45e-3775c10e0b13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "# Visualize one image from the dataset and its label, just to make sure the data format is correct\n",
        "\n",
        "idx = 0\n",
        "\n",
        "plt.imshow(train_images[idx][:,:,0], cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "print(\"Label: \" + str(train_labels[idx]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD8CAYAAAB3lxGOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEWhouOFoi0BDww1HWwQaGm44/n8z1wsu5Sv+DgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Label: [0. 0. 1. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46axQ5Fo6aLL",
        "colab_type": "text"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQWmPE116hT0",
        "colab_type": "text"
      },
      "source": [
        "The task is quite similar to the one addressed in another notebook (Scratch_CNN_2_class), but slightly more complex because here are 4 classes instead than 2. Not only it is important to distinguish between masses and calcifications, but also to diagnose whether the abnormality is benign or malignant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoxlYfAu-cnu",
        "colab_type": "text"
      },
      "source": [
        "## Experiment 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkZGkkX6-kRk",
        "colab_type": "text"
      },
      "source": [
        "The model that achieved the best performance in the two-class classification is a good starting point for sure, since both tasks partially overlap and they work on the same dataset.\n",
        "That CNN had an accuracy above 88\\% on the test set.\n",
        "Of course, some modifications are required, especially in the output layer, because the problem is now a multiclass classification: 4 softmax neurons replace the old sigmoid unit.\n",
        "Likewise, the loss function is now the categorical crossentropy, a generalized version of binary crossentropy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iCdo4qC6bWM",
        "colab_type": "code",
        "outputId": "5fc960e2-af22-4f58-966b-f32903170033",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        }
      },
      "source": [
        "# Model 1\n",
        "\n",
        "model_1 = models.Sequential()\n",
        "model_1.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 1)))\n",
        "model_1.add(layers.MaxPooling2D((2, 2)))\n",
        "model_1.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model_1.add(layers.MaxPooling2D((2, 2)))\n",
        "model_1.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model_1.add(layers.MaxPooling2D((2, 2)))\n",
        "model_1.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
        "model_1.add(layers.MaxPooling2D((2, 2)))\n",
        "model_1.add(layers.Flatten())\n",
        "model_1.add(layers.Dense(48, activation='relu'))\n",
        "model_1.add(layers.Dropout(0.5))\n",
        "model_1.add(layers.Dense(4, activation='softmax'))\n",
        "\n",
        "model_1.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 148, 148, 32)      320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 72, 72, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 36, 36, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 34, 34, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 17, 17, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 15, 15, 256)       295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 48)                602160    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 48)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 4)                 196       \n",
            "=================================================================\n",
            "Total params: 990,196\n",
            "Trainable params: 990,196\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjG0h4Ij_9v9",
        "colab_type": "code",
        "outputId": "a305ee7e-289e-43ce-d5cd-5eadda7d31b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Early stopping (stop training after the validation loss reaches the minimum)\n",
        "earlystopping = EarlyStopping(monitor='val_loss', mode='min', patience=80, verbose=1)\n",
        "\n",
        "# Callback for checkpointing\n",
        "checkpoint = ModelCheckpoint('model_1_4cl_best.h5', \n",
        "        monitor='val_loss', mode='min', verbose=1, \n",
        "        save_best_only=True, save_freq='epoch'\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model_1.compile(optimizer=RMSprop(learning_rate=0.001, decay=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "history_1 = model_1.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=int(0.8*n_train_img) // 128,\n",
        "        epochs=500,\n",
        "        validation_data=validation_generator,\n",
        "        callbacks=[checkpoint, earlystopping],\n",
        "        shuffle=True,\n",
        "        verbose=1,\n",
        "        initial_epoch=0\n",
        ")\n",
        "\n",
        "# Save\n",
        "models.save_model(model_1, 'model_1_4cl_end.h5')\n",
        "!cp model* \"/content/gdrive/My Drive/models/\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.6142 - acc: 0.3257Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 1.3598 - acc: 0.3555\n",
            "Epoch 00001: val_loss improved from inf to 1.36900, saving model to model_1_4cl_best.h5\n",
            "16/16 [==============================] - 6s 348ms/step - loss: 1.5989 - acc: 0.3294 - val_loss: 1.3690 - val_acc: 0.3514\n",
            "Epoch 2/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.3792 - acc: 0.3454Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 1.3710 - acc: 0.3535\n",
            "Epoch 00002: val_loss did not improve from 1.36900\n",
            "16/16 [==============================] - 5s 294ms/step - loss: 1.3790 - acc: 0.3438 - val_loss: 1.3781 - val_acc: 0.3514\n",
            "Epoch 3/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.3719 - acc: 0.3427Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 1.3638 - acc: 0.3535\n",
            "Epoch 00003: val_loss improved from 1.36900 to 1.36840, saving model to model_1_4cl_best.h5\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 1.3728 - acc: 0.3408 - val_loss: 1.3684 - val_acc: 0.3514\n",
            "Epoch 4/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.3639 - acc: 0.3581Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.3505 - acc: 0.3535\n",
            "Epoch 00004: val_loss did not improve from 1.36840\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.3614 - acc: 0.3592 - val_loss: 1.3718 - val_acc: 0.3514\n",
            "Epoch 5/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.3626 - acc: 0.3507Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.3496 - acc: 0.3535\n",
            "Epoch 00005: val_loss improved from 1.36840 to 1.35952, saving model to model_1_4cl_best.h5\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.3615 - acc: 0.3512 - val_loss: 1.3595 - val_acc: 0.3514\n",
            "Epoch 6/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.3576 - acc: 0.3581Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.3501 - acc: 0.3535\n",
            "Epoch 00006: val_loss improved from 1.35952 to 1.35438, saving model to model_1_4cl_best.h5\n",
            "16/16 [==============================] - 5s 299ms/step - loss: 1.3565 - acc: 0.3597 - val_loss: 1.3544 - val_acc: 0.3514\n",
            "Epoch 7/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.3574 - acc: 0.3536Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.3429 - acc: 0.3926\n",
            "Epoch 00007: val_loss improved from 1.35438 to 1.34314, saving model to model_1_4cl_best.h5\n",
            "16/16 [==============================] - 5s 296ms/step - loss: 1.3578 - acc: 0.3511 - val_loss: 1.3431 - val_acc: 0.3907\n",
            "Epoch 8/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.3579 - acc: 0.3546Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.3366 - acc: 0.3535\n",
            "Epoch 00008: val_loss did not improve from 1.34314\n",
            "16/16 [==============================] - 4s 281ms/step - loss: 1.3549 - acc: 0.3635 - val_loss: 1.3439 - val_acc: 0.3514\n",
            "Epoch 9/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.3450 - acc: 0.3536Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.4279 - acc: 0.3613\n",
            "Epoch 00009: val_loss did not improve from 1.34314\n",
            "16/16 [==============================] - 5s 287ms/step - loss: 1.3423 - acc: 0.3589 - val_loss: 1.4355 - val_acc: 0.3589\n",
            "Epoch 10/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.3303 - acc: 0.3735Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.3083 - acc: 0.3672\n",
            "Epoch 00010: val_loss improved from 1.34314 to 1.32075, saving model to model_1_4cl_best.h5\n",
            "16/16 [==============================] - 4s 280ms/step - loss: 1.3307 - acc: 0.3711 - val_loss: 1.3208 - val_acc: 0.3645\n",
            "Epoch 11/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.3205 - acc: 0.3655Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 1.2880 - acc: 0.3981\n",
            "Epoch 00011: val_loss improved from 1.32075 to 1.28802, saving model to model_1_4cl_best.h5\n",
            "16/16 [==============================] - 4s 280ms/step - loss: 1.3211 - acc: 0.3651 - val_loss: 1.2880 - val_acc: 0.3981\n",
            "Epoch 12/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.2835 - acc: 0.4048Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.3327 - acc: 0.3809\n",
            "Epoch 00012: val_loss did not improve from 1.28802\n",
            "16/16 [==============================] - 4s 275ms/step - loss: 1.2861 - acc: 0.4039 - val_loss: 1.3238 - val_acc: 0.3813\n",
            "Epoch 13/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.2902 - acc: 0.3968Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 1.1927 - acc: 0.4430\n",
            "Epoch 00013: val_loss improved from 1.28802 to 1.19275, saving model to model_1_4cl_best.h5\n",
            "16/16 [==============================] - 4s 280ms/step - loss: 1.2837 - acc: 0.3994 - val_loss: 1.1927 - val_acc: 0.4430\n",
            "Epoch 14/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.2277 - acc: 0.4344Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 1.2058 - acc: 0.5252\n",
            "Epoch 00014: val_loss did not improve from 1.19275\n",
            "16/16 [==============================] - 4s 281ms/step - loss: 1.2300 - acc: 0.4287 - val_loss: 1.2058 - val_acc: 0.5252\n",
            "Epoch 15/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.2275 - acc: 0.4202Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.1507 - acc: 0.5117\n",
            "Epoch 00015: val_loss improved from 1.19275 to 1.16826, saving model to model_1_4cl_best.h5\n",
            "16/16 [==============================] - 4s 281ms/step - loss: 1.2248 - acc: 0.4252 - val_loss: 1.1683 - val_acc: 0.5178\n",
            "Epoch 16/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.2073 - acc: 0.4615Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.1943 - acc: 0.4883\n",
            "Epoch 00016: val_loss did not improve from 1.16826\n",
            "16/16 [==============================] - 4s 277ms/step - loss: 1.2029 - acc: 0.4610 - val_loss: 1.1968 - val_acc: 0.4916\n",
            "Epoch 17/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1802 - acc: 0.4727Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0959 - acc: 0.5508\n",
            "Epoch 00017: val_loss improved from 1.16826 to 1.13327, saving model to model_1_4cl_best.h5\n",
            "16/16 [==============================] - 5s 284ms/step - loss: 1.1809 - acc: 0.4714 - val_loss: 1.1333 - val_acc: 0.5514\n",
            "Epoch 18/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.2542 - acc: 0.4604Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 1.1031 - acc: 0.5039\n",
            "Epoch 00018: val_loss did not improve from 1.13327\n",
            "16/16 [==============================] - 4s 250ms/step - loss: 1.2418 - acc: 0.4678 - val_loss: 1.1398 - val_acc: 0.5047\n",
            "Epoch 19/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1452 - acc: 0.4784Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 1.0744 - acc: 0.5273\n",
            "Epoch 00019: val_loss improved from 1.13327 to 1.12064, saving model to model_1_4cl_best.h5\n",
            "16/16 [==============================] - 5s 298ms/step - loss: 1.1437 - acc: 0.4818 - val_loss: 1.1206 - val_acc: 0.5271\n",
            "Epoch 20/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1360 - acc: 0.4912Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 1.1905 - acc: 0.3867\n",
            "Epoch 00020: val_loss did not improve from 1.12064\n",
            "16/16 [==============================] - 5s 297ms/step - loss: 1.1351 - acc: 0.4908 - val_loss: 1.2811 - val_acc: 0.3850\n",
            "Epoch 21/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1632 - acc: 0.4631Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.1068 - acc: 0.5020\n",
            "Epoch 00021: val_loss did not improve from 1.12064\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.1660 - acc: 0.4630 - val_loss: 1.1291 - val_acc: 0.5047\n",
            "Epoch 22/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1071 - acc: 0.5061Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.1306 - acc: 0.4941\n",
            "Epoch 00022: val_loss did not improve from 1.12064\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 1.1170 - acc: 0.4993 - val_loss: 1.1280 - val_acc: 0.4935\n",
            "Epoch 23/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1114 - acc: 0.4981Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.1370 - acc: 0.4883\n",
            "Epoch 00023: val_loss improved from 1.12064 to 1.12016, saving model to model_1_4cl_best.h5\n",
            "16/16 [==============================] - 5s 299ms/step - loss: 1.1071 - acc: 0.4993 - val_loss: 1.1202 - val_acc: 0.4897\n",
            "Epoch 24/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1012 - acc: 0.5042Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0632 - acc: 0.5410\n",
            "Epoch 00024: val_loss improved from 1.12016 to 1.05493, saving model to model_1_4cl_best.h5\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 1.1041 - acc: 0.5029 - val_loss: 1.0549 - val_acc: 0.5364\n",
            "Epoch 25/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1054 - acc: 0.5061Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 1.0449 - acc: 0.5533\n",
            "Epoch 00025: val_loss improved from 1.05493 to 1.04494, saving model to model_1_4cl_best.h5\n",
            "16/16 [==============================] - 5s 288ms/step - loss: 1.1066 - acc: 0.5042 - val_loss: 1.0449 - val_acc: 0.5533\n",
            "Epoch 26/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0527 - acc: 0.5314Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 1.0622 - acc: 0.5009\n",
            "Epoch 00026: val_loss did not improve from 1.04494\n",
            "16/16 [==============================] - 4s 277ms/step - loss: 1.0600 - acc: 0.5288 - val_loss: 1.0622 - val_acc: 0.5009\n",
            "Epoch 27/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1028 - acc: 0.4979Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0502 - acc: 0.5430\n",
            "Epoch 00027: val_loss did not improve from 1.04494\n",
            "16/16 [==============================] - 4s 275ms/step - loss: 1.1006 - acc: 0.4966 - val_loss: 1.0558 - val_acc: 0.5364\n",
            "Epoch 28/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0892 - acc: 0.5162Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 1.0288 - acc: 0.5402\n",
            "Epoch 00028: val_loss improved from 1.04494 to 1.02880, saving model to model_1_4cl_best.h5\n",
            "16/16 [==============================] - 5s 286ms/step - loss: 1.0922 - acc: 0.5152 - val_loss: 1.0288 - val_acc: 0.5402\n",
            "Epoch 29/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0501 - acc: 0.5302Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0336 - acc: 0.5449\n",
            "Epoch 00029: val_loss did not improve from 1.02880\n",
            "16/16 [==============================] - 4s 269ms/step - loss: 1.0501 - acc: 0.5296 - val_loss: 1.0369 - val_acc: 0.5439\n",
            "Epoch 30/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0610 - acc: 0.5089Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9789 - acc: 0.5762\n",
            "Epoch 00030: val_loss improved from 1.02880 to 0.97565, saving model to model_1_4cl_best.h5\n",
            "16/16 [==============================] - 5s 289ms/step - loss: 1.0559 - acc: 0.5107 - val_loss: 0.9756 - val_acc: 0.5720\n",
            "Epoch 31/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0446 - acc: 0.5507Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.9750 - acc: 0.5458\n",
            "Epoch 00031: val_loss improved from 0.97565 to 0.97496, saving model to model_1_4cl_best.h5\n",
            "16/16 [==============================] - 5s 286ms/step - loss: 1.0516 - acc: 0.5484 - val_loss: 0.9750 - val_acc: 0.5458\n",
            "Epoch 32/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0570 - acc: 0.5342Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0063 - acc: 0.5332\n",
            "Epoch 00032: val_loss did not improve from 0.97496\n",
            "16/16 [==============================] - 4s 278ms/step - loss: 1.0477 - acc: 0.5365 - val_loss: 0.9865 - val_acc: 0.5364\n",
            "Epoch 33/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0727 - acc: 0.5279Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0025 - acc: 0.5723\n",
            "Epoch 00033: val_loss did not improve from 0.97496\n",
            "16/16 [==============================] - 5s 283ms/step - loss: 1.0710 - acc: 0.5296 - val_loss: 0.9912 - val_acc: 0.5720\n",
            "Epoch 34/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0300 - acc: 0.5321Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.1394 - acc: 0.4590\n",
            "Epoch 00034: val_loss did not improve from 0.97496\n",
            "16/16 [==============================] - 5s 284ms/step - loss: 1.0246 - acc: 0.5335 - val_loss: 1.1193 - val_acc: 0.4617\n",
            "Epoch 35/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0431 - acc: 0.5347Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.9794 - acc: 0.5664\n",
            "Epoch 00035: val_loss improved from 0.97496 to 0.96431, saving model to model_1_4cl_best.h5\n",
            "16/16 [==============================] - 4s 248ms/step - loss: 1.0367 - acc: 0.5390 - val_loss: 0.9643 - val_acc: 0.5626\n",
            "Epoch 36/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0211 - acc: 0.5464Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 1.0509 - acc: 0.5137\n",
            "Epoch 00036: val_loss did not improve from 0.96431\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 1.0204 - acc: 0.5459 - val_loss: 1.0325 - val_acc: 0.5121\n",
            "Epoch 37/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0239 - acc: 0.5316Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.9993 - acc: 0.5586\n",
            "Epoch 00037: val_loss did not improve from 0.96431\n",
            "16/16 [==============================] - 5s 297ms/step - loss: 1.0268 - acc: 0.5296 - val_loss: 0.9924 - val_acc: 0.5570\n",
            "Epoch 38/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0414 - acc: 0.5395Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9409 - acc: 0.5938\n",
            "Epoch 00038: val_loss improved from 0.96431 to 0.95169, saving model to model_1_4cl_best.h5\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.0401 - acc: 0.5399 - val_loss: 0.9517 - val_acc: 0.5907\n",
            "Epoch 39/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9849 - acc: 0.5578Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9827 - acc: 0.5508\n",
            "Epoch 00039: val_loss did not improve from 0.95169\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 0.9774 - acc: 0.5625 - val_loss: 0.9583 - val_acc: 0.5551\n",
            "Epoch 40/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0054 - acc: 0.5438Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0334 - acc: 0.5352\n",
            "Epoch 00040: val_loss did not improve from 0.95169\n",
            "16/16 [==============================] - 5s 297ms/step - loss: 1.0012 - acc: 0.5450 - val_loss: 1.0240 - val_acc: 0.5346\n",
            "Epoch 41/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0264 - acc: 0.5215Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.9756 - acc: 0.5720\n",
            "Epoch 00041: val_loss did not improve from 0.95169\n",
            "16/16 [==============================] - 5s 294ms/step - loss: 1.0272 - acc: 0.5201 - val_loss: 0.9756 - val_acc: 0.5720\n",
            "Epoch 42/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9587 - acc: 0.5670Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9981 - acc: 0.5781\n",
            "Epoch 00042: val_loss did not improve from 0.95169\n",
            "16/16 [==============================] - 4s 280ms/step - loss: 0.9586 - acc: 0.5698 - val_loss: 0.9722 - val_acc: 0.5832\n",
            "Epoch 43/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0138 - acc: 0.5432Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.9555 - acc: 0.5402\n",
            "Epoch 00043: val_loss did not improve from 0.95169\n",
            "16/16 [==============================] - 5s 287ms/step - loss: 1.0204 - acc: 0.5365 - val_loss: 0.9555 - val_acc: 0.5402\n",
            "Epoch 44/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9880 - acc: 0.5544Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0047 - acc: 0.5508\n",
            "Epoch 00044: val_loss did not improve from 0.95169\n",
            "16/16 [==============================] - 4s 275ms/step - loss: 0.9970 - acc: 0.5514 - val_loss: 0.9671 - val_acc: 0.5589\n",
            "Epoch 45/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9716 - acc: 0.5557Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9634 - acc: 0.5488\n",
            "Epoch 00045: val_loss improved from 0.95169 to 0.92761, saving model to model_1_4cl_best.h5\n",
            "16/16 [==============================] - 5s 291ms/step - loss: 0.9804 - acc: 0.5542 - val_loss: 0.9276 - val_acc: 0.5551\n",
            "Epoch 46/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9594 - acc: 0.5714Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9472 - acc: 0.5684\n",
            "Epoch 00046: val_loss improved from 0.92761 to 0.91247, saving model to model_1_4cl_best.h5\n",
            "16/16 [==============================] - 4s 278ms/step - loss: 0.9554 - acc: 0.5733 - val_loss: 0.9125 - val_acc: 0.5757\n",
            "Epoch 47/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9921 - acc: 0.5666Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0125 - acc: 0.5254\n",
            "Epoch 00047: val_loss did not improve from 0.91247\n",
            "16/16 [==============================] - 4s 269ms/step - loss: 0.9881 - acc: 0.5683 - val_loss: 0.9840 - val_acc: 0.5290\n",
            "Epoch 48/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9956 - acc: 0.5401Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.9366 - acc: 0.5944\n",
            "Epoch 00048: val_loss did not improve from 0.91247\n",
            "16/16 [==============================] - 5s 287ms/step - loss: 0.9964 - acc: 0.5430 - val_loss: 0.9366 - val_acc: 0.5944\n",
            "Epoch 49/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9714 - acc: 0.5671Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9955 - acc: 0.5488\n",
            "Epoch 00049: val_loss did not improve from 0.91247\n",
            "16/16 [==============================] - 4s 274ms/step - loss: 0.9748 - acc: 0.5658 - val_loss: 0.9665 - val_acc: 0.5570\n",
            "Epoch 50/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9465 - acc: 0.5836Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9920 - acc: 0.5410\n",
            "Epoch 00050: val_loss did not improve from 0.91247\n",
            "16/16 [==============================] - 4s 280ms/step - loss: 0.9468 - acc: 0.5832 - val_loss: 0.9481 - val_acc: 0.5477\n",
            "Epoch 51/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9574 - acc: 0.5750Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.9659 - acc: 0.5794\n",
            "Epoch 00051: val_loss did not improve from 0.91247\n",
            "16/16 [==============================] - 5s 282ms/step - loss: 0.9512 - acc: 0.5738 - val_loss: 0.9659 - val_acc: 0.5794\n",
            "Epoch 52/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9824 - acc: 0.5660Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.9744 - acc: 0.5625\n",
            "Epoch 00052: val_loss did not improve from 0.91247\n",
            "16/16 [==============================] - 4s 248ms/step - loss: 0.9930 - acc: 0.5599 - val_loss: 0.9558 - val_acc: 0.5645\n",
            "Epoch 53/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9343 - acc: 0.5740Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.9730 - acc: 0.5645\n",
            "Epoch 00053: val_loss did not improve from 0.91247\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 0.9524 - acc: 0.5658 - val_loss: 0.9585 - val_acc: 0.5682\n",
            "Epoch 54/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9400 - acc: 0.5650Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 1.0970 - acc: 0.4961\n",
            "Epoch 00054: val_loss did not improve from 0.91247\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 0.9526 - acc: 0.5594 - val_loss: 1.0676 - val_acc: 0.5028\n",
            "Epoch 55/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9432 - acc: 0.5724Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9354 - acc: 0.5684\n",
            "Epoch 00055: val_loss improved from 0.91247 to 0.90640, saving model to model_1_4cl_best.h5\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 0.9483 - acc: 0.5698 - val_loss: 0.9064 - val_acc: 0.5757\n",
            "Epoch 56/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9571 - acc: 0.5609Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 1.0402 - acc: 0.5439\n",
            "Epoch 00056: val_loss did not improve from 0.90640\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 0.9534 - acc: 0.5635 - val_loss: 1.0402 - val_acc: 0.5439\n",
            "Epoch 57/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9834 - acc: 0.5570Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9151 - acc: 0.5957\n",
            "Epoch 00057: val_loss did not improve from 0.90640\n",
            "16/16 [==============================] - 5s 299ms/step - loss: 0.9835 - acc: 0.5564 - val_loss: 0.9398 - val_acc: 0.5907\n",
            "Epoch 58/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9046 - acc: 0.5881Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 1.0904 - acc: 0.4935\n",
            "Epoch 00058: val_loss did not improve from 0.90640\n",
            "16/16 [==============================] - 5s 289ms/step - loss: 0.9308 - acc: 0.5779 - val_loss: 1.0904 - val_acc: 0.4935\n",
            "Epoch 59/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9458 - acc: 0.5867Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.9789 - acc: 0.5533\n",
            "Epoch 00059: val_loss did not improve from 0.90640\n",
            "16/16 [==============================] - 5s 287ms/step - loss: 0.9528 - acc: 0.5842 - val_loss: 0.9789 - val_acc: 0.5533\n",
            "Epoch 60/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9541 - acc: 0.5578Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9294 - acc: 0.5820\n",
            "Epoch 00060: val_loss did not improve from 0.90640\n",
            "16/16 [==============================] - 4s 280ms/step - loss: 0.9533 - acc: 0.5591 - val_loss: 0.9532 - val_acc: 0.5776\n",
            "Epoch 61/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9360 - acc: 0.5825Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9256 - acc: 0.5586\n",
            "Epoch 00061: val_loss did not improve from 0.90640\n",
            "16/16 [==============================] - 5s 285ms/step - loss: 0.9366 - acc: 0.5837 - val_loss: 0.9858 - val_acc: 0.5439\n",
            "Epoch 62/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9778 - acc: 0.5623Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9584 - acc: 0.5742\n",
            "Epoch 00062: val_loss did not improve from 0.90640\n",
            "16/16 [==============================] - 4s 280ms/step - loss: 0.9779 - acc: 0.5594 - val_loss: 0.9949 - val_acc: 0.5682\n",
            "Epoch 63/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9406 - acc: 0.5645Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9318 - acc: 0.5527\n",
            "Epoch 00063: val_loss did not improve from 0.90640\n",
            "16/16 [==============================] - 5s 287ms/step - loss: 0.9384 - acc: 0.5708 - val_loss: 0.9843 - val_acc: 0.5458\n",
            "Epoch 64/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9371 - acc: 0.5666Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9782 - acc: 0.5566\n",
            "Epoch 00064: val_loss did not improve from 0.90640\n",
            "16/16 [==============================] - 5s 282ms/step - loss: 0.9304 - acc: 0.5683 - val_loss: 1.0216 - val_acc: 0.5514\n",
            "Epoch 65/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9467 - acc: 0.5851Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0629 - acc: 0.5234\n",
            "Epoch 00065: val_loss did not improve from 0.90640\n",
            "16/16 [==============================] - 4s 280ms/step - loss: 0.9463 - acc: 0.5827 - val_loss: 1.0395 - val_acc: 0.5196\n",
            "Epoch 66/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9212 - acc: 0.5809Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9777 - acc: 0.5977\n",
            "Epoch 00066: val_loss did not improve from 0.90640\n",
            "16/16 [==============================] - 4s 275ms/step - loss: 0.9303 - acc: 0.5787 - val_loss: 0.9496 - val_acc: 0.5981\n",
            "Epoch 67/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9283 - acc: 0.5788Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9509 - acc: 0.5664\n",
            "Epoch 00067: val_loss did not improve from 0.90640\n",
            "16/16 [==============================] - 5s 285ms/step - loss: 0.9249 - acc: 0.5789 - val_loss: 0.9159 - val_acc: 0.5645\n",
            "Epoch 68/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9396 - acc: 0.5677Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9030 - acc: 0.5859\n",
            "Epoch 00068: val_loss improved from 0.90640 to 0.86990, saving model to model_1_4cl_best.h5\n",
            "16/16 [==============================] - 4s 280ms/step - loss: 0.9374 - acc: 0.5708 - val_loss: 0.8699 - val_acc: 0.5869\n",
            "Epoch 69/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9169 - acc: 0.5878Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.9507 - acc: 0.5977\n",
            "Epoch 00069: val_loss did not improve from 0.86990\n",
            "16/16 [==============================] - 4s 257ms/step - loss: 0.9173 - acc: 0.5837 - val_loss: 0.9184 - val_acc: 0.5963\n",
            "Epoch 70/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9466 - acc: 0.5688Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.9208 - acc: 0.5820\n",
            "Epoch 00070: val_loss did not improve from 0.86990\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 0.9460 - acc: 0.5698 - val_loss: 0.8930 - val_acc: 0.5813\n",
            "Epoch 71/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9212 - acc: 0.5822Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 1.1363 - acc: 0.4629\n",
            "Epoch 00071: val_loss did not improve from 0.86990\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 0.9267 - acc: 0.5814 - val_loss: 1.1015 - val_acc: 0.4654\n",
            "Epoch 72/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9321 - acc: 0.5660Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9223 - acc: 0.5840\n",
            "Epoch 00072: val_loss did not improve from 0.86990\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 0.9332 - acc: 0.5673 - val_loss: 0.8834 - val_acc: 0.5832\n",
            "Epoch 73/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9057 - acc: 0.5766Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9298 - acc: 0.5742\n",
            "Epoch 00073: val_loss improved from 0.86990 to 0.86283, saving model to model_1_4cl_best.h5\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 0.9014 - acc: 0.5768 - val_loss: 0.8628 - val_acc: 0.5832\n",
            "Epoch 74/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9255 - acc: 0.5922Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.8404 - acc: 0.5626\n",
            "Epoch 00074: val_loss improved from 0.86283 to 0.84041, saving model to model_1_4cl_best.h5\n",
            "16/16 [==============================] - 5s 297ms/step - loss: 0.9248 - acc: 0.5933 - val_loss: 0.8404 - val_acc: 0.5626\n",
            "Epoch 75/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9216 - acc: 0.5867Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.8337 - acc: 0.6093\n",
            "Epoch 00075: val_loss improved from 0.84041 to 0.83366, saving model to model_1_4cl_best.h5\n",
            "16/16 [==============================] - 5s 294ms/step - loss: 0.9221 - acc: 0.5824 - val_loss: 0.8337 - val_acc: 0.6093\n",
            "Epoch 76/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9066 - acc: 0.5792Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9106 - acc: 0.5605\n",
            "Epoch 00076: val_loss did not improve from 0.83366\n",
            "16/16 [==============================] - 5s 285ms/step - loss: 0.9054 - acc: 0.5806 - val_loss: 0.8424 - val_acc: 0.5682\n",
            "Epoch 77/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9295 - acc: 0.5762Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9005 - acc: 0.5723\n",
            "Epoch 00077: val_loss improved from 0.83366 to 0.83159, saving model to model_1_4cl_best.h5\n",
            "16/16 [==============================] - 5s 283ms/step - loss: 0.9296 - acc: 0.5748 - val_loss: 0.8316 - val_acc: 0.5794\n",
            "Epoch 78/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9278 - acc: 0.5854Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.9315 - acc: 0.5551\n",
            "Epoch 00078: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 5s 289ms/step - loss: 0.9232 - acc: 0.5933 - val_loss: 0.9315 - val_acc: 0.5551\n",
            "Epoch 79/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8936 - acc: 0.5931Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9017 - acc: 0.5762\n",
            "Epoch 00079: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 4s 280ms/step - loss: 0.8978 - acc: 0.5907 - val_loss: 0.9099 - val_acc: 0.5757\n",
            "Epoch 80/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8997 - acc: 0.5905Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9146 - acc: 0.5859\n",
            "Epoch 00080: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 4s 280ms/step - loss: 0.9071 - acc: 0.5887 - val_loss: 0.9670 - val_acc: 0.5794\n",
            "Epoch 81/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9209 - acc: 0.5876Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.9240 - acc: 0.5832\n",
            "Epoch 00081: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 4s 275ms/step - loss: 0.9152 - acc: 0.5880 - val_loss: 0.9240 - val_acc: 0.5832\n",
            "Epoch 82/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9138 - acc: 0.5901Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8800 - acc: 0.5918\n",
            "Epoch 00082: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 5s 292ms/step - loss: 0.9152 - acc: 0.5889 - val_loss: 0.9326 - val_acc: 0.5850\n",
            "Epoch 83/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8996 - acc: 0.5862Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.9464 - acc: 0.5963\n",
            "Epoch 00083: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 5s 282ms/step - loss: 0.9011 - acc: 0.5882 - val_loss: 0.9464 - val_acc: 0.5963\n",
            "Epoch 84/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9107 - acc: 0.5814Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8661 - acc: 0.6055\n",
            "Epoch 00084: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 4s 273ms/step - loss: 0.9086 - acc: 0.5807 - val_loss: 0.9189 - val_acc: 0.5963\n",
            "Epoch 85/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9195 - acc: 0.5920Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8581 - acc: 0.5762\n",
            "Epoch 00085: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 5s 284ms/step - loss: 0.9189 - acc: 0.5887 - val_loss: 0.9048 - val_acc: 0.5682\n",
            "Epoch 86/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9003 - acc: 0.5952Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.9359 - acc: 0.5664\n",
            "Epoch 00086: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 4s 241ms/step - loss: 0.9015 - acc: 0.5931 - val_loss: 0.9796 - val_acc: 0.5607\n",
            "Epoch 87/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8957 - acc: 0.5804Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.9284 - acc: 0.5645\n",
            "Epoch 00087: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 0.8887 - acc: 0.5862 - val_loss: 1.0023 - val_acc: 0.5551\n",
            "Epoch 88/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9019 - acc: 0.5910Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8948 - acc: 0.5879\n",
            "Epoch 00088: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 0.9005 - acc: 0.5892 - val_loss: 0.9121 - val_acc: 0.5813\n",
            "Epoch 89/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9028 - acc: 0.5906Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8799 - acc: 0.6172\n",
            "Epoch 00089: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 0.8976 - acc: 0.5898 - val_loss: 0.8863 - val_acc: 0.6150\n",
            "Epoch 90/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8972 - acc: 0.5827Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8779 - acc: 0.6074\n",
            "Epoch 00090: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 0.8960 - acc: 0.5844 - val_loss: 0.8810 - val_acc: 0.6000\n",
            "Epoch 91/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8857 - acc: 0.5906Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8675 - acc: 0.6035\n",
            "Epoch 00091: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 5s 298ms/step - loss: 0.8804 - acc: 0.5938 - val_loss: 0.8745 - val_acc: 0.5963\n",
            "Epoch 92/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8938 - acc: 0.5973Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9068 - acc: 0.6074\n",
            "Epoch 00092: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 5s 292ms/step - loss: 0.8999 - acc: 0.5971 - val_loss: 0.9309 - val_acc: 0.6000\n",
            "Epoch 93/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8814 - acc: 0.5979Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9213 - acc: 0.5879\n",
            "Epoch 00093: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 5s 293ms/step - loss: 0.8849 - acc: 0.5976 - val_loss: 0.9550 - val_acc: 0.5850\n",
            "Epoch 94/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8945 - acc: 0.5941Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9157 - acc: 0.5820\n",
            "Epoch 00094: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 4s 276ms/step - loss: 0.8939 - acc: 0.5966 - val_loss: 0.9235 - val_acc: 0.5738\n",
            "Epoch 95/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9134 - acc: 0.5885Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8723 - acc: 0.5840\n",
            "Epoch 00095: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 4s 275ms/step - loss: 0.9083 - acc: 0.5869 - val_loss: 0.8862 - val_acc: 0.5738\n",
            "Epoch 96/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8818 - acc: 0.6162Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8750 - acc: 0.5723\n",
            "Epoch 00096: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 4s 276ms/step - loss: 0.8804 - acc: 0.6153 - val_loss: 0.8843 - val_acc: 0.5645\n",
            "Epoch 97/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9169 - acc: 0.5878Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9087 - acc: 0.5918\n",
            "Epoch 00097: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 5s 289ms/step - loss: 0.9063 - acc: 0.5917 - val_loss: 0.9141 - val_acc: 0.5869\n",
            "Epoch 98/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8654 - acc: 0.5969Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.2420 - acc: 0.4219\n",
            "Epoch 00098: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 5s 294ms/step - loss: 0.8674 - acc: 0.5962 - val_loss: 1.2522 - val_acc: 0.4187\n",
            "Epoch 99/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9122 - acc: 0.5926Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9134 - acc: 0.5723\n",
            "Epoch 00099: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 4s 280ms/step - loss: 0.9041 - acc: 0.5986 - val_loss: 0.9310 - val_acc: 0.5682\n",
            "Epoch 100/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8739 - acc: 0.6021Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.8732 - acc: 0.5944\n",
            "Epoch 00100: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 4s 275ms/step - loss: 0.8764 - acc: 0.5991 - val_loss: 0.8732 - val_acc: 0.5944\n",
            "Epoch 101/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8665 - acc: 0.6042Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9596 - acc: 0.5664\n",
            "Epoch 00101: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 5s 287ms/step - loss: 0.8653 - acc: 0.6056 - val_loss: 0.9611 - val_acc: 0.5682\n",
            "Epoch 102/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8800 - acc: 0.5922Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.8826 - acc: 0.5963\n",
            "Epoch 00102: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 4s 275ms/step - loss: 0.8751 - acc: 0.5941 - val_loss: 0.8826 - val_acc: 0.5963\n",
            "Epoch 103/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8814 - acc: 0.6016Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.9205 - acc: 0.5742\n",
            "Epoch 00103: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 4s 243ms/step - loss: 0.8761 - acc: 0.6046 - val_loss: 0.9313 - val_acc: 0.5757\n",
            "Epoch 104/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8613 - acc: 0.5899Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8662 - acc: 0.6055\n",
            "Epoch 00104: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 5s 299ms/step - loss: 0.8634 - acc: 0.5897 - val_loss: 0.8823 - val_acc: 0.6075\n",
            "Epoch 105/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8510 - acc: 0.6159Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8405 - acc: 0.5840\n",
            "Epoch 00105: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 0.8568 - acc: 0.6120 - val_loss: 0.8728 - val_acc: 0.5850\n",
            "Epoch 106/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9007 - acc: 0.6000Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9078 - acc: 0.5703\n",
            "Epoch 00106: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 0.8969 - acc: 0.6006 - val_loss: 0.9354 - val_acc: 0.5701\n",
            "Epoch 107/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8615 - acc: 0.6016Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8542 - acc: 0.6074\n",
            "Epoch 00107: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 0.8580 - acc: 0.6025 - val_loss: 0.8689 - val_acc: 0.6037\n",
            "Epoch 108/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8880 - acc: 0.5914Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8804 - acc: 0.5781\n",
            "Epoch 00108: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 5s 295ms/step - loss: 0.8821 - acc: 0.5920 - val_loss: 0.9171 - val_acc: 0.5776\n",
            "Epoch 109/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8731 - acc: 0.5947Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.8664 - acc: 0.6056\n",
            "Epoch 00109: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 5s 294ms/step - loss: 0.8702 - acc: 0.5981 - val_loss: 0.8664 - val_acc: 0.6056\n",
            "Epoch 110/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8639 - acc: 0.6021Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8682 - acc: 0.5840\n",
            "Epoch 00110: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 5s 291ms/step - loss: 0.8660 - acc: 0.6006 - val_loss: 0.8599 - val_acc: 0.5888\n",
            "Epoch 111/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8431 - acc: 0.6149Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.8610 - acc: 0.5794\n",
            "Epoch 00111: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 5s 287ms/step - loss: 0.8401 - acc: 0.6170 - val_loss: 0.8610 - val_acc: 0.5794\n",
            "Epoch 112/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8878 - acc: 0.5878Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9090 - acc: 0.5684\n",
            "Epoch 00112: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 4s 272ms/step - loss: 0.8878 - acc: 0.5877 - val_loss: 0.8889 - val_acc: 0.5738\n",
            "Epoch 113/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8575 - acc: 0.6191Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8474 - acc: 0.5957\n",
            "Epoch 00113: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 4s 273ms/step - loss: 0.8559 - acc: 0.6190 - val_loss: 0.8434 - val_acc: 0.6019\n",
            "Epoch 114/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8771 - acc: 0.5851Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8754 - acc: 0.5938\n",
            "Epoch 00114: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 5s 282ms/step - loss: 0.8772 - acc: 0.5882 - val_loss: 0.8603 - val_acc: 0.6000\n",
            "Epoch 115/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8659 - acc: 0.6080Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9195 - acc: 0.5547\n",
            "Epoch 00115: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 4s 279ms/step - loss: 0.8701 - acc: 0.6105 - val_loss: 0.9131 - val_acc: 0.5607\n",
            "Epoch 116/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8855 - acc: 0.5862Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8630 - acc: 0.5898\n",
            "Epoch 00116: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 5s 282ms/step - loss: 0.8853 - acc: 0.5902 - val_loss: 0.8487 - val_acc: 0.5981\n",
            "Epoch 117/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8624 - acc: 0.5899Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.8670 - acc: 0.6224\n",
            "Epoch 00117: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 4s 273ms/step - loss: 0.8611 - acc: 0.5912 - val_loss: 0.8670 - val_acc: 0.6224\n",
            "Epoch 118/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8625 - acc: 0.5968Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8768 - acc: 0.5840\n",
            "Epoch 00118: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 4s 280ms/step - loss: 0.8649 - acc: 0.5956 - val_loss: 0.8730 - val_acc: 0.5907\n",
            "Epoch 119/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8548 - acc: 0.6037Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8688 - acc: 0.6211\n",
            "Epoch 00119: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 4s 276ms/step - loss: 0.8621 - acc: 0.6006 - val_loss: 0.8613 - val_acc: 0.6262\n",
            "Epoch 120/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8608 - acc: 0.5968Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.8651 - acc: 0.6094\n",
            "Epoch 00120: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 4s 247ms/step - loss: 0.8654 - acc: 0.5981 - val_loss: 0.8594 - val_acc: 0.6168\n",
            "Epoch 121/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8610 - acc: 0.6027Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8989 - acc: 0.5723\n",
            "Epoch 00121: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 5s 296ms/step - loss: 0.8520 - acc: 0.6066 - val_loss: 0.8892 - val_acc: 0.5813\n",
            "Epoch 122/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8533 - acc: 0.6031Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8951 - acc: 0.5820\n",
            "Epoch 00122: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 5s 300ms/step - loss: 0.8528 - acc: 0.6016 - val_loss: 0.8818 - val_acc: 0.5907\n",
            "Epoch 123/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8594 - acc: 0.5843Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8758 - acc: 0.5820\n",
            "Epoch 00123: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 0.8506 - acc: 0.5930 - val_loss: 0.8805 - val_acc: 0.5888\n",
            "Epoch 124/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8546 - acc: 0.6069Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8630 - acc: 0.5977\n",
            "Epoch 00124: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 0.8552 - acc: 0.6066 - val_loss: 0.8971 - val_acc: 0.5925\n",
            "Epoch 125/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8726 - acc: 0.5963Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8558 - acc: 0.6152\n",
            "Epoch 00125: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 5s 300ms/step - loss: 0.8676 - acc: 0.5966 - val_loss: 0.8775 - val_acc: 0.6093\n",
            "Epoch 126/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8470 - acc: 0.6111Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9240 - acc: 0.5449\n",
            "Epoch 00126: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 5s 286ms/step - loss: 0.8467 - acc: 0.6090 - val_loss: 0.9338 - val_acc: 0.5383\n",
            "Epoch 127/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8539 - acc: 0.6255Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8613 - acc: 0.5957\n",
            "Epoch 00127: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 5s 290ms/step - loss: 0.8507 - acc: 0.6264 - val_loss: 0.8827 - val_acc: 0.5925\n",
            "Epoch 128/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8688 - acc: 0.6032Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8583 - acc: 0.6035\n",
            "Epoch 00128: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 4s 281ms/step - loss: 0.8694 - acc: 0.6011 - val_loss: 0.8809 - val_acc: 0.5981\n",
            "Epoch 129/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8662 - acc: 0.5948Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.9351 - acc: 0.5832\n",
            "Epoch 00129: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 5s 290ms/step - loss: 0.8644 - acc: 0.5967 - val_loss: 0.9351 - val_acc: 0.5832\n",
            "Epoch 130/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8479 - acc: 0.6178Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8689 - acc: 0.6035\n",
            "Epoch 00130: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 4s 271ms/step - loss: 0.8489 - acc: 0.6153 - val_loss: 0.9079 - val_acc: 0.6019\n",
            "Epoch 131/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8305 - acc: 0.6146Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8872 - acc: 0.5742\n",
            "Epoch 00131: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 5s 288ms/step - loss: 0.8344 - acc: 0.6147 - val_loss: 0.9450 - val_acc: 0.5757\n",
            "Epoch 132/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8624 - acc: 0.5963Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8827 - acc: 0.5918\n",
            "Epoch 00132: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 4s 274ms/step - loss: 0.8605 - acc: 0.5996 - val_loss: 0.9220 - val_acc: 0.5888\n",
            "Epoch 133/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8543 - acc: 0.6074Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8739 - acc: 0.5996\n",
            "Epoch 00133: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 5s 286ms/step - loss: 0.8558 - acc: 0.6001 - val_loss: 0.8782 - val_acc: 0.6000\n",
            "Epoch 134/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8402 - acc: 0.6080Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8465 - acc: 0.6094\n",
            "Epoch 00134: val_loss did not improve from 0.83159\n",
            "16/16 [==============================] - 4s 274ms/step - loss: 0.8403 - acc: 0.6080 - val_loss: 0.8570 - val_acc: 0.6150\n",
            "Epoch 135/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8547 - acc: 0.5995Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8520 - acc: 0.6074\n",
            "Epoch 00135: val_loss improved from 0.83159 to 0.81311, saving model to model_1_4cl_best.h5\n",
            "16/16 [==============================] - 5s 285ms/step - loss: 0.8522 - acc: 0.6011 - val_loss: 0.8131 - val_acc: 0.6150\n",
            "Epoch 136/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8608 - acc: 0.5936Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8382 - acc: 0.5938\n",
            "Epoch 00136: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 4s 281ms/step - loss: 0.8600 - acc: 0.5936 - val_loss: 0.8664 - val_acc: 0.5907\n",
            "Epoch 137/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8498 - acc: 0.5942Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.8488 - acc: 0.6094\n",
            "Epoch 00137: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 4s 254ms/step - loss: 0.8454 - acc: 0.5956 - val_loss: 0.8882 - val_acc: 0.6093\n",
            "Epoch 138/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8330 - acc: 0.6042Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8290 - acc: 0.6289\n",
            "Epoch 00138: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 5s 300ms/step - loss: 0.8356 - acc: 0.6056 - val_loss: 0.8876 - val_acc: 0.6280\n",
            "Epoch 139/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8448 - acc: 0.6212Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8703 - acc: 0.5996\n",
            "Epoch 00139: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 0.8434 - acc: 0.6190 - val_loss: 0.9043 - val_acc: 0.5981\n",
            "Epoch 140/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8475 - acc: 0.6069Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8395 - acc: 0.6016\n",
            "Epoch 00140: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 0.8474 - acc: 0.6066 - val_loss: 0.8720 - val_acc: 0.6019\n",
            "Epoch 141/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8472 - acc: 0.6101Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.8861 - acc: 0.5907\n",
            "Epoch 00141: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 0.8439 - acc: 0.6130 - val_loss: 0.8861 - val_acc: 0.5907\n",
            "Epoch 142/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8520 - acc: 0.6010Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.9006 - acc: 0.6019\n",
            "Epoch 00142: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 0.8478 - acc: 0.6055 - val_loss: 0.9006 - val_acc: 0.6019\n",
            "Epoch 143/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8062 - acc: 0.6205Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8974 - acc: 0.5820\n",
            "Epoch 00143: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 5s 284ms/step - loss: 0.8063 - acc: 0.6249 - val_loss: 0.9391 - val_acc: 0.5794\n",
            "Epoch 144/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8534 - acc: 0.5979Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8919 - acc: 0.5742\n",
            "Epoch 00144: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 5s 283ms/step - loss: 0.8549 - acc: 0.5961 - val_loss: 0.9088 - val_acc: 0.5757\n",
            "Epoch 145/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8431 - acc: 0.6089Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.8853 - acc: 0.6019\n",
            "Epoch 00145: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 5s 290ms/step - loss: 0.8597 - acc: 0.6040 - val_loss: 0.8853 - val_acc: 0.6019\n",
            "Epoch 146/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8141 - acc: 0.6191Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.9501 - acc: 0.5589\n",
            "Epoch 00146: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 4s 277ms/step - loss: 0.8182 - acc: 0.6190 - val_loss: 0.9501 - val_acc: 0.5589\n",
            "Epoch 147/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8632 - acc: 0.5989Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9134 - acc: 0.5684\n",
            "Epoch 00147: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 4s 268ms/step - loss: 0.8602 - acc: 0.6036 - val_loss: 0.9703 - val_acc: 0.5664\n",
            "Epoch 148/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8419 - acc: 0.6172Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8634 - acc: 0.5957\n",
            "Epoch 00148: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 4s 280ms/step - loss: 0.8380 - acc: 0.6172 - val_loss: 0.8378 - val_acc: 0.5944\n",
            "Epoch 149/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8482 - acc: 0.6011Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8975 - acc: 0.5684\n",
            "Epoch 00149: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 4s 277ms/step - loss: 0.8463 - acc: 0.5996 - val_loss: 0.8602 - val_acc: 0.5720\n",
            "Epoch 150/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8090 - acc: 0.6249Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 6s - loss: 0.8398 - acc: 0.6055\n",
            "Epoch 00150: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 5s 332ms/step - loss: 0.8083 - acc: 0.6254 - val_loss: 0.8621 - val_acc: 0.6019\n",
            "Epoch 151/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8394 - acc: 0.6032Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8392 - acc: 0.6016\n",
            "Epoch 00151: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 4s 281ms/step - loss: 0.8389 - acc: 0.6021 - val_loss: 0.8365 - val_acc: 0.6000\n",
            "Epoch 152/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8331 - acc: 0.6138Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.8577 - acc: 0.5794\n",
            "Epoch 00152: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 5s 288ms/step - loss: 0.8288 - acc: 0.6170 - val_loss: 0.8577 - val_acc: 0.5794\n",
            "Epoch 153/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8283 - acc: 0.6074Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.8348 - acc: 0.5907\n",
            "Epoch 00153: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 4s 279ms/step - loss: 0.8292 - acc: 0.6076 - val_loss: 0.8348 - val_acc: 0.5907\n",
            "Epoch 154/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8522 - acc: 0.6016Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.8545 - acc: 0.5918\n",
            "Epoch 00154: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 4s 250ms/step - loss: 0.8499 - acc: 0.6006 - val_loss: 0.8366 - val_acc: 0.5925\n",
            "Epoch 155/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8168 - acc: 0.6177Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8403 - acc: 0.6074\n",
            "Epoch 00155: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 0.8190 - acc: 0.6162 - val_loss: 0.8384 - val_acc: 0.6075\n",
            "Epoch 156/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8350 - acc: 0.6146Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8362 - acc: 0.6211\n",
            "Epoch 00156: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 0.8375 - acc: 0.6143 - val_loss: 0.8309 - val_acc: 0.6168\n",
            "Epoch 157/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8203 - acc: 0.6196Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8698 - acc: 0.6035\n",
            "Epoch 00157: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 0.8299 - acc: 0.6140 - val_loss: 0.8637 - val_acc: 0.6019\n",
            "Epoch 158/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8140 - acc: 0.6154Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8564 - acc: 0.6094\n",
            "Epoch 00158: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 0.8137 - acc: 0.6155 - val_loss: 0.9620 - val_acc: 0.6075\n",
            "Epoch 159/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8561 - acc: 0.6122Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8934 - acc: 0.6035\n",
            "Epoch 00159: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 5s 297ms/step - loss: 0.8566 - acc: 0.6130 - val_loss: 0.8483 - val_acc: 0.6056\n",
            "Epoch 160/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8019 - acc: 0.6240Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8864 - acc: 0.5801\n",
            "Epoch 00160: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 5s 292ms/step - loss: 0.8052 - acc: 0.6230 - val_loss: 0.8299 - val_acc: 0.5813\n",
            "Epoch 161/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8335 - acc: 0.6211Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8716 - acc: 0.5957\n",
            "Epoch 00161: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 5s 283ms/step - loss: 0.8311 - acc: 0.6188 - val_loss: 0.8184 - val_acc: 0.6037\n",
            "Epoch 162/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8477 - acc: 0.6156Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.8240 - acc: 0.6168\n",
            "Epoch 00162: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 5s 287ms/step - loss: 0.8527 - acc: 0.6145 - val_loss: 0.8240 - val_acc: 0.6168\n",
            "Epoch 163/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8336 - acc: 0.6193Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.8841 - acc: 0.5963\n",
            "Epoch 00163: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 5s 285ms/step - loss: 0.8326 - acc: 0.6201 - val_loss: 0.8841 - val_acc: 0.5963\n",
            "Epoch 164/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8423 - acc: 0.6186Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8564 - acc: 0.6289\n",
            "Epoch 00164: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 5s 287ms/step - loss: 0.8429 - acc: 0.6140 - val_loss: 0.8335 - val_acc: 0.6299\n",
            "Epoch 165/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8019 - acc: 0.6164Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8568 - acc: 0.5820\n",
            "Epoch 00165: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 4s 271ms/step - loss: 0.7933 - acc: 0.6183 - val_loss: 0.8625 - val_acc: 0.5850\n",
            "Epoch 166/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8284 - acc: 0.6328Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8426 - acc: 0.6289\n",
            "Epoch 00166: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 5s 289ms/step - loss: 0.8295 - acc: 0.6323 - val_loss: 0.8320 - val_acc: 0.6318\n",
            "Epoch 167/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8354 - acc: 0.5989Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8587 - acc: 0.5801\n",
            "Epoch 00167: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 4s 281ms/step - loss: 0.8327 - acc: 0.6026 - val_loss: 0.8639 - val_acc: 0.5813\n",
            "Epoch 168/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8326 - acc: 0.6117Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8410 - acc: 0.6016\n",
            "Epoch 00168: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 4s 276ms/step - loss: 0.8325 - acc: 0.6110 - val_loss: 0.8350 - val_acc: 0.6056\n",
            "Epoch 169/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8195 - acc: 0.6233Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8347 - acc: 0.6133\n",
            "Epoch 00169: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 4s 274ms/step - loss: 0.8169 - acc: 0.6230 - val_loss: 0.8504 - val_acc: 0.6112\n",
            "Epoch 170/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8267 - acc: 0.6095Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8536 - acc: 0.6094\n",
            "Epoch 00170: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 4s 277ms/step - loss: 0.8253 - acc: 0.6090 - val_loss: 0.8472 - val_acc: 0.6112\n",
            "Epoch 171/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8165 - acc: 0.6265Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.8810 - acc: 0.5801\n",
            "Epoch 00171: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 4s 249ms/step - loss: 0.8178 - acc: 0.6244 - val_loss: 0.9306 - val_acc: 0.5832\n",
            "Epoch 172/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8294 - acc: 0.6117Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8504 - acc: 0.6133\n",
            "Epoch 00172: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 0.8308 - acc: 0.6085 - val_loss: 0.8294 - val_acc: 0.6150\n",
            "Epoch 173/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8177 - acc: 0.6276Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8457 - acc: 0.5938\n",
            "Epoch 00173: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 0.8195 - acc: 0.6230 - val_loss: 0.8491 - val_acc: 0.5944\n",
            "Epoch 174/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8171 - acc: 0.6120Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8495 - acc: 0.5898\n",
            "Epoch 00174: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 0.8103 - acc: 0.6138 - val_loss: 0.8360 - val_acc: 0.5963\n",
            "Epoch 175/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8533 - acc: 0.5968Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.8571 - acc: 0.6262\n",
            "Epoch 00175: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 0.8511 - acc: 0.5986 - val_loss: 0.8571 - val_acc: 0.6262\n",
            "Epoch 176/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7849 - acc: 0.6435Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8713 - acc: 0.6191\n",
            "Epoch 00176: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 0.7905 - acc: 0.6374 - val_loss: 0.8723 - val_acc: 0.6187\n",
            "Epoch 177/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8353 - acc: 0.6062Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8648 - acc: 0.6172\n",
            "Epoch 00177: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 5s 290ms/step - loss: 0.8371 - acc: 0.6094 - val_loss: 0.8609 - val_acc: 0.6206\n",
            "Epoch 178/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8481 - acc: 0.6037Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8522 - acc: 0.5762\n",
            "Epoch 00178: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 5s 290ms/step - loss: 0.8402 - acc: 0.6080 - val_loss: 0.8554 - val_acc: 0.5776\n",
            "Epoch 179/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8092 - acc: 0.6074Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.8398 - acc: 0.6075\n",
            "Epoch 00179: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 5s 285ms/step - loss: 0.8113 - acc: 0.6046 - val_loss: 0.8398 - val_acc: 0.6075\n",
            "Epoch 180/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8091 - acc: 0.6090Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.8207 - acc: 0.6299\n",
            "Epoch 00180: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 5s 282ms/step - loss: 0.8085 - acc: 0.6090 - val_loss: 0.8207 - val_acc: 0.6299\n",
            "Epoch 181/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8241 - acc: 0.6350Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.8667 - acc: 0.5832\n",
            "Epoch 00181: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 4s 274ms/step - loss: 0.8206 - acc: 0.6334 - val_loss: 0.8667 - val_acc: 0.5832\n",
            "Epoch 182/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8208 - acc: 0.6106Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8635 - acc: 0.6152\n",
            "Epoch 00182: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 5s 289ms/step - loss: 0.8245 - acc: 0.6125 - val_loss: 0.8359 - val_acc: 0.6187\n",
            "Epoch 183/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7981 - acc: 0.6265Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8541 - acc: 0.5977\n",
            "Epoch 00183: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 5s 287ms/step - loss: 0.8008 - acc: 0.6264 - val_loss: 0.8228 - val_acc: 0.5925\n",
            "Epoch 184/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8173 - acc: 0.6265Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.8648 - acc: 0.6000\n",
            "Epoch 00184: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 5s 282ms/step - loss: 0.8254 - acc: 0.6239 - val_loss: 0.8648 - val_acc: 0.6000\n",
            "Epoch 185/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8056 - acc: 0.6175Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8523 - acc: 0.6211\n",
            "Epoch 00185: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 4s 281ms/step - loss: 0.8094 - acc: 0.6140 - val_loss: 0.8255 - val_acc: 0.6131\n",
            "Epoch 186/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8141 - acc: 0.6244Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9015 - acc: 0.5723\n",
            "Epoch 00186: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 5s 287ms/step - loss: 0.8136 - acc: 0.6210 - val_loss: 0.8502 - val_acc: 0.5794\n",
            "Epoch 187/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8106 - acc: 0.6244Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8617 - acc: 0.5723\n",
            "Epoch 00187: val_loss did not improve from 0.81311\n",
            "16/16 [==============================] - 4s 280ms/step - loss: 0.8166 - acc: 0.6190 - val_loss: 0.9241 - val_acc: 0.5701\n",
            "Epoch 188/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7957 - acc: 0.6313Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.8522 - acc: 0.6211\n",
            "Epoch 00188: val_loss improved from 0.81311 to 0.80344, saving model to model_1_4cl_best.h5\n",
            "16/16 [==============================] - 4s 252ms/step - loss: 0.7980 - acc: 0.6279 - val_loss: 0.8034 - val_acc: 0.6262\n",
            "Epoch 189/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7989 - acc: 0.6187Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8993 - acc: 0.5664\n",
            "Epoch 00189: val_loss did not improve from 0.80344\n",
            "16/16 [==============================] - 5s 297ms/step - loss: 0.8065 - acc: 0.6175 - val_loss: 0.9470 - val_acc: 0.5720\n",
            "Epoch 190/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8404 - acc: 0.6111Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8363 - acc: 0.6035\n",
            "Epoch 00190: val_loss did not improve from 0.80344\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 0.8416 - acc: 0.6085 - val_loss: 0.8681 - val_acc: 0.6019\n",
            "Epoch 191/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8059 - acc: 0.6223Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8172 - acc: 0.6055\n",
            "Epoch 00191: val_loss did not improve from 0.80344\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 0.8108 - acc: 0.6205 - val_loss: 0.8415 - val_acc: 0.6056\n",
            "Epoch 192/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7974 - acc: 0.6334Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8213 - acc: 0.6211\n",
            "Epoch 00192: val_loss did not improve from 0.80344\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 0.8003 - acc: 0.6334 - val_loss: 0.8704 - val_acc: 0.6168\n",
            "Epoch 193/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8298 - acc: 0.5942Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.8561 - acc: 0.6112\n",
            "Epoch 00193: val_loss did not improve from 0.80344\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 0.8251 - acc: 0.5951 - val_loss: 0.8561 - val_acc: 0.6112\n",
            "Epoch 194/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8051 - acc: 0.6219Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8551 - acc: 0.6055\n",
            "Epoch 00194: val_loss did not improve from 0.80344\n",
            "16/16 [==============================] - 5s 296ms/step - loss: 0.8031 - acc: 0.6230 - val_loss: 0.8775 - val_acc: 0.6019\n",
            "Epoch 195/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8066 - acc: 0.6135Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8494 - acc: 0.6191\n",
            "Epoch 00195: val_loss did not improve from 0.80344\n",
            "16/16 [==============================] - 5s 287ms/step - loss: 0.8020 - acc: 0.6148 - val_loss: 0.8829 - val_acc: 0.6187\n",
            "Epoch 196/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7743 - acc: 0.6297Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8548 - acc: 0.6309\n",
            "Epoch 00196: val_loss did not improve from 0.80344\n",
            "16/16 [==============================] - 5s 284ms/step - loss: 0.7818 - acc: 0.6250 - val_loss: 0.8942 - val_acc: 0.6262\n",
            "Epoch 197/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8352 - acc: 0.6178Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8411 - acc: 0.5938\n",
            "Epoch 00197: val_loss did not improve from 0.80344\n",
            "16/16 [==============================] - 5s 282ms/step - loss: 0.8294 - acc: 0.6203 - val_loss: 0.9232 - val_acc: 0.5907\n",
            "Epoch 198/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8009 - acc: 0.6240Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8417 - acc: 0.6230\n",
            "Epoch 00198: val_loss did not improve from 0.80344\n",
            "16/16 [==============================] - 5s 283ms/step - loss: 0.7951 - acc: 0.6279 - val_loss: 0.9143 - val_acc: 0.6187\n",
            "Epoch 199/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7912 - acc: 0.6281Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8271 - acc: 0.6406\n",
            "Epoch 00199: val_loss did not improve from 0.80344\n",
            "16/16 [==============================] - 4s 279ms/step - loss: 0.7914 - acc: 0.6299 - val_loss: 0.8770 - val_acc: 0.6374\n",
            "Epoch 200/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8275 - acc: 0.6143Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9041 - acc: 0.6016\n",
            "Epoch 00200: val_loss did not improve from 0.80344\n",
            "16/16 [==============================] - 5s 282ms/step - loss: 0.8298 - acc: 0.6130 - val_loss: 0.8644 - val_acc: 0.6019\n",
            "Epoch 201/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8174 - acc: 0.5979Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.8657 - acc: 0.5794\n",
            "Epoch 00201: val_loss did not improve from 0.80344\n",
            "16/16 [==============================] - 5s 293ms/step - loss: 0.8218 - acc: 0.5941 - val_loss: 0.8657 - val_acc: 0.5794\n",
            "Epoch 202/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8075 - acc: 0.6249Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8604 - acc: 0.6113\n",
            "Epoch 00202: val_loss did not improve from 0.80344\n",
            "16/16 [==============================] - 5s 282ms/step - loss: 0.8054 - acc: 0.6279 - val_loss: 0.8190 - val_acc: 0.6093\n",
            "Epoch 203/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7966 - acc: 0.6233Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8438 - acc: 0.6270\n",
            "Epoch 00203: val_loss improved from 0.80344 to 0.80100, saving model to model_1_4cl_best.h5\n",
            "16/16 [==============================] - 5s 288ms/step - loss: 0.7936 - acc: 0.6239 - val_loss: 0.8010 - val_acc: 0.6243\n",
            "Epoch 204/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8097 - acc: 0.6180Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8721 - acc: 0.5918\n",
            "Epoch 00204: val_loss did not improve from 0.80100\n",
            "16/16 [==============================] - 5s 285ms/step - loss: 0.8115 - acc: 0.6170 - val_loss: 0.8228 - val_acc: 0.5963\n",
            "Epoch 205/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8066 - acc: 0.6370Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.8701 - acc: 0.6289\n",
            "Epoch 00205: val_loss did not improve from 0.80100\n",
            "16/16 [==============================] - 4s 257ms/step - loss: 0.8055 - acc: 0.6367 - val_loss: 0.8269 - val_acc: 0.6299\n",
            "Epoch 206/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7933 - acc: 0.6259Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8172 - acc: 0.6211\n",
            "Epoch 00206: val_loss did not improve from 0.80100\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 0.8005 - acc: 0.6229 - val_loss: 0.8526 - val_acc: 0.6168\n",
            "Epoch 207/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8060 - acc: 0.6377Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8323 - acc: 0.6074\n",
            "Epoch 00207: val_loss did not improve from 0.80100\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 0.8053 - acc: 0.6309 - val_loss: 0.8069 - val_acc: 0.6093\n",
            "Epoch 208/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8139 - acc: 0.6265Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8202 - acc: 0.6270\n",
            "Epoch 00208: val_loss improved from 0.80100 to 0.77086, saving model to model_1_4cl_best.h5\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 0.8180 - acc: 0.6289 - val_loss: 0.7709 - val_acc: 0.6355\n",
            "Epoch 209/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7999 - acc: 0.6281Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8744 - acc: 0.5723\n",
            "Epoch 00209: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 0.8054 - acc: 0.6269 - val_loss: 0.8490 - val_acc: 0.5701\n",
            "Epoch 210/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7956 - acc: 0.6333Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.8152 - acc: 0.6206\n",
            "Epoch 00210: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 0.8003 - acc: 0.6294 - val_loss: 0.8152 - val_acc: 0.6206\n",
            "Epoch 211/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8012 - acc: 0.6114Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8703 - acc: 0.5898\n",
            "Epoch 00211: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 295ms/step - loss: 0.7953 - acc: 0.6143 - val_loss: 0.8027 - val_acc: 0.5925\n",
            "Epoch 212/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8042 - acc: 0.6438Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.8168 - acc: 0.6019\n",
            "Epoch 00212: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 294ms/step - loss: 0.8060 - acc: 0.6401 - val_loss: 0.8168 - val_acc: 0.6019\n",
            "Epoch 213/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8086 - acc: 0.6178Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8768 - acc: 0.5996\n",
            "Epoch 00213: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 283ms/step - loss: 0.8023 - acc: 0.6244 - val_loss: 0.8282 - val_acc: 0.6019\n",
            "Epoch 214/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8211 - acc: 0.6255Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.8290 - acc: 0.6075\n",
            "Epoch 00214: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 288ms/step - loss: 0.8220 - acc: 0.6274 - val_loss: 0.8290 - val_acc: 0.6075\n",
            "Epoch 215/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7946 - acc: 0.6276Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8858 - acc: 0.6172\n",
            "Epoch 00215: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 4s 276ms/step - loss: 0.7891 - acc: 0.6325 - val_loss: 0.8275 - val_acc: 0.6206\n",
            "Epoch 216/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8233 - acc: 0.6080Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.8296 - acc: 0.6224\n",
            "Epoch 00216: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 282ms/step - loss: 0.8251 - acc: 0.6090 - val_loss: 0.8296 - val_acc: 0.6224\n",
            "Epoch 217/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7841 - acc: 0.6370Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8327 - acc: 0.6230\n",
            "Epoch 00217: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 288ms/step - loss: 0.7858 - acc: 0.6367 - val_loss: 0.7808 - val_acc: 0.6243\n",
            "Epoch 218/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7776 - acc: 0.6345Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8522 - acc: 0.6211\n",
            "Epoch 00218: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 4s 276ms/step - loss: 0.7800 - acc: 0.6299 - val_loss: 0.7946 - val_acc: 0.6224\n",
            "Epoch 219/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8081 - acc: 0.6276Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.8644 - acc: 0.6243\n",
            "Epoch 00219: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 286ms/step - loss: 0.8062 - acc: 0.6294 - val_loss: 0.8644 - val_acc: 0.6243\n",
            "Epoch 220/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7879 - acc: 0.6414Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8698 - acc: 0.6094\n",
            "Epoch 00220: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 287ms/step - loss: 0.7957 - acc: 0.6369 - val_loss: 0.8893 - val_acc: 0.6112\n",
            "Epoch 221/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7940 - acc: 0.6419Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8191 - acc: 0.6172\n",
            "Epoch 00221: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 4s 281ms/step - loss: 0.7938 - acc: 0.6393 - val_loss: 0.8237 - val_acc: 0.6187\n",
            "Epoch 222/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8013 - acc: 0.6191Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.8506 - acc: 0.6113\n",
            "Epoch 00222: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 4s 253ms/step - loss: 0.8043 - acc: 0.6180 - val_loss: 0.8336 - val_acc: 0.6112\n",
            "Epoch 223/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7845 - acc: 0.6318Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8289 - acc: 0.5996\n",
            "Epoch 00223: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 0.7865 - acc: 0.6304 - val_loss: 0.8328 - val_acc: 0.5944\n",
            "Epoch 224/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8146 - acc: 0.6212Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8686 - acc: 0.6250\n",
            "Epoch 00224: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 0.8178 - acc: 0.6195 - val_loss: 0.8847 - val_acc: 0.6206\n",
            "Epoch 225/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7885 - acc: 0.6324Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8278 - acc: 0.6270\n",
            "Epoch 00225: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 0.7935 - acc: 0.6294 - val_loss: 0.8216 - val_acc: 0.6243\n",
            "Epoch 226/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7874 - acc: 0.6318Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8355 - acc: 0.6211\n",
            "Epoch 00226: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 0.7914 - acc: 0.6324 - val_loss: 0.8438 - val_acc: 0.6150\n",
            "Epoch 227/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7722 - acc: 0.6354Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8613 - acc: 0.6230\n",
            "Epoch 00227: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 0.7742 - acc: 0.6362 - val_loss: 0.8632 - val_acc: 0.6168\n",
            "Epoch 228/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7984 - acc: 0.6400Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.8231 - acc: 0.6112\n",
            "Epoch 00228: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 298ms/step - loss: 0.7983 - acc: 0.6400 - val_loss: 0.8231 - val_acc: 0.6112\n",
            "Epoch 229/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7934 - acc: 0.6218Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8486 - acc: 0.6289\n",
            "Epoch 00229: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 284ms/step - loss: 0.8028 - acc: 0.6180 - val_loss: 0.8482 - val_acc: 0.6280\n",
            "Epoch 230/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8060 - acc: 0.6255Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.8739 - acc: 0.5907\n",
            "Epoch 00230: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 294ms/step - loss: 0.8055 - acc: 0.6265 - val_loss: 0.8739 - val_acc: 0.5907\n",
            "Epoch 231/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7894 - acc: 0.6387Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8910 - acc: 0.5840\n",
            "Epoch 00231: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 4s 280ms/step - loss: 0.7905 - acc: 0.6374 - val_loss: 0.9223 - val_acc: 0.5850\n",
            "Epoch 232/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8165 - acc: 0.6228Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8496 - acc: 0.6035\n",
            "Epoch 00232: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 282ms/step - loss: 0.8159 - acc: 0.6254 - val_loss: 0.9003 - val_acc: 0.5963\n",
            "Epoch 233/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7605 - acc: 0.6416Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8620 - acc: 0.6016\n",
            "Epoch 00233: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 4s 279ms/step - loss: 0.7676 - acc: 0.6370 - val_loss: 0.9128 - val_acc: 0.5963\n",
            "Epoch 234/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8004 - acc: 0.6240Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.8530 - acc: 0.6168\n",
            "Epoch 00234: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 282ms/step - loss: 0.8018 - acc: 0.6201 - val_loss: 0.8530 - val_acc: 0.6168\n",
            "Epoch 235/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8062 - acc: 0.6281Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8035 - acc: 0.6367\n",
            "Epoch 00235: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 282ms/step - loss: 0.8071 - acc: 0.6264 - val_loss: 0.8343 - val_acc: 0.6374\n",
            "Epoch 236/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7863 - acc: 0.6340Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8431 - acc: 0.6211\n",
            "Epoch 00236: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 282ms/step - loss: 0.7814 - acc: 0.6364 - val_loss: 0.8528 - val_acc: 0.6224\n",
            "Epoch 237/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8083 - acc: 0.6202Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8559 - acc: 0.6133\n",
            "Epoch 00237: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 282ms/step - loss: 0.8109 - acc: 0.6215 - val_loss: 0.8684 - val_acc: 0.6168\n",
            "Epoch 238/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7916 - acc: 0.6329Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8384 - acc: 0.6191\n",
            "Epoch 00238: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 282ms/step - loss: 0.7924 - acc: 0.6294 - val_loss: 0.8614 - val_acc: 0.6168\n",
            "Epoch 239/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7927 - acc: 0.6208Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.8560 - acc: 0.5840\n",
            "Epoch 00239: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 4s 247ms/step - loss: 0.7882 - acc: 0.6255 - val_loss: 0.8704 - val_acc: 0.5888\n",
            "Epoch 240/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8002 - acc: 0.6249Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8367 - acc: 0.6113\n",
            "Epoch 00240: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 300ms/step - loss: 0.7993 - acc: 0.6234 - val_loss: 0.8834 - val_acc: 0.6168\n",
            "Epoch 241/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7890 - acc: 0.6345Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8137 - acc: 0.6094\n",
            "Epoch 00241: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 0.7890 - acc: 0.6329 - val_loss: 0.8377 - val_acc: 0.6150\n",
            "Epoch 242/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7910 - acc: 0.6233Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8277 - acc: 0.6211\n",
            "Epoch 00242: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 0.7905 - acc: 0.6210 - val_loss: 0.8495 - val_acc: 0.6224\n",
            "Epoch 243/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8029 - acc: 0.6354Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8423 - acc: 0.6113\n",
            "Epoch 00243: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 0.7997 - acc: 0.6362 - val_loss: 0.8707 - val_acc: 0.6131\n",
            "Epoch 244/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7842 - acc: 0.6389Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8459 - acc: 0.6230\n",
            "Epoch 00244: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 0.7962 - acc: 0.6294 - val_loss: 0.8711 - val_acc: 0.6262\n",
            "Epoch 245/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7915 - acc: 0.6345Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8341 - acc: 0.6211\n",
            "Epoch 00245: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 299ms/step - loss: 0.7946 - acc: 0.6319 - val_loss: 0.8677 - val_acc: 0.6243\n",
            "Epoch 246/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8052 - acc: 0.6318Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8373 - acc: 0.6484\n",
            "Epoch 00246: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 288ms/step - loss: 0.8031 - acc: 0.6329 - val_loss: 0.8597 - val_acc: 0.6486\n",
            "Epoch 247/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7745 - acc: 0.6385Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.8676 - acc: 0.6112\n",
            "Epoch 00247: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 286ms/step - loss: 0.7715 - acc: 0.6401 - val_loss: 0.8676 - val_acc: 0.6112\n",
            "Epoch 248/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7884 - acc: 0.6249Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8497 - acc: 0.6152\n",
            "Epoch 00248: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 282ms/step - loss: 0.7923 - acc: 0.6225 - val_loss: 0.8530 - val_acc: 0.6168\n",
            "Epoch 249/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7751 - acc: 0.6462Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8495 - acc: 0.5859\n",
            "Epoch 00249: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 4s 274ms/step - loss: 0.7669 - acc: 0.6483 - val_loss: 0.8754 - val_acc: 0.5907\n",
            "Epoch 250/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8042 - acc: 0.6259Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8366 - acc: 0.6309\n",
            "Epoch 00250: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 4s 279ms/step - loss: 0.8058 - acc: 0.6244 - val_loss: 0.8539 - val_acc: 0.6355\n",
            "Epoch 251/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7834 - acc: 0.6380Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8577 - acc: 0.6250\n",
            "Epoch 00251: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 294ms/step - loss: 0.7769 - acc: 0.6382 - val_loss: 0.8749 - val_acc: 0.6280\n",
            "Epoch 252/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7739 - acc: 0.6334Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8300 - acc: 0.6230\n",
            "Epoch 00252: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 4s 275ms/step - loss: 0.7763 - acc: 0.6334 - val_loss: 0.8834 - val_acc: 0.6262\n",
            "Epoch 253/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8017 - acc: 0.6154Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8409 - acc: 0.6113\n",
            "Epoch 00253: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 292ms/step - loss: 0.8030 - acc: 0.6140 - val_loss: 0.8683 - val_acc: 0.6150\n",
            "Epoch 254/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7970 - acc: 0.6149Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8487 - acc: 0.6230\n",
            "Epoch 00254: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 282ms/step - loss: 0.8045 - acc: 0.6120 - val_loss: 0.8277 - val_acc: 0.6262\n",
            "Epoch 255/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7744 - acc: 0.6462Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8617 - acc: 0.6113\n",
            "Epoch 00255: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 282ms/step - loss: 0.7711 - acc: 0.6503 - val_loss: 0.8155 - val_acc: 0.6131\n",
            "Epoch 256/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7851 - acc: 0.6233Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.8237 - acc: 0.6387\n",
            "Epoch 00256: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 4s 253ms/step - loss: 0.7823 - acc: 0.6234 - val_loss: 0.8084 - val_acc: 0.6393\n",
            "Epoch 257/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7943 - acc: 0.6286Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8414 - acc: 0.6113\n",
            "Epoch 00257: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 0.7913 - acc: 0.6304 - val_loss: 0.7931 - val_acc: 0.6112\n",
            "Epoch 258/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7959 - acc: 0.6249Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8185 - acc: 0.6270\n",
            "Epoch 00258: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 0.7928 - acc: 0.6279 - val_loss: 0.8055 - val_acc: 0.6299\n",
            "Epoch 259/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7816 - acc: 0.6308Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8511 - acc: 0.6074\n",
            "Epoch 00259: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 0.7809 - acc: 0.6309 - val_loss: 0.8279 - val_acc: 0.6075\n",
            "Epoch 260/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7696 - acc: 0.6308Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8894 - acc: 0.6094\n",
            "Epoch 00260: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 0.7678 - acc: 0.6344 - val_loss: 0.8785 - val_acc: 0.6093\n",
            "Epoch 261/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7913 - acc: 0.6371Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8611 - acc: 0.6094\n",
            "Epoch 00261: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 300ms/step - loss: 0.7867 - acc: 0.6374 - val_loss: 0.8180 - val_acc: 0.6112\n",
            "Epoch 262/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7907 - acc: 0.6260Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.8302 - acc: 0.6075\n",
            "Epoch 00262: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 295ms/step - loss: 0.7926 - acc: 0.6249 - val_loss: 0.8302 - val_acc: 0.6075\n",
            "Epoch 263/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7765 - acc: 0.6228Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8515 - acc: 0.6328\n",
            "Epoch 00263: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 289ms/step - loss: 0.7743 - acc: 0.6264 - val_loss: 0.7954 - val_acc: 0.6299\n",
            "Epoch 264/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7891 - acc: 0.6292Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8422 - acc: 0.6309\n",
            "Epoch 00264: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 290ms/step - loss: 0.7848 - acc: 0.6309 - val_loss: 0.8068 - val_acc: 0.6280\n",
            "Epoch 265/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8010 - acc: 0.6400Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8237 - acc: 0.6270\n",
            "Epoch 00265: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 4s 278ms/step - loss: 0.7983 - acc: 0.6365 - val_loss: 0.7986 - val_acc: 0.6262\n",
            "Epoch 266/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7809 - acc: 0.6557Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8195 - acc: 0.6387\n",
            "Epoch 00266: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 293ms/step - loss: 0.7757 - acc: 0.6572 - val_loss: 0.8463 - val_acc: 0.6355\n",
            "Epoch 267/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7795 - acc: 0.6223Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8195 - acc: 0.6270\n",
            "Epoch 00267: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 283ms/step - loss: 0.7776 - acc: 0.6244 - val_loss: 0.8502 - val_acc: 0.6224\n",
            "Epoch 268/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7821 - acc: 0.6313Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8290 - acc: 0.6348\n",
            "Epoch 00268: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 4s 275ms/step - loss: 0.7769 - acc: 0.6334 - val_loss: 0.8538 - val_acc: 0.6299\n",
            "Epoch 269/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7663 - acc: 0.6398Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8159 - acc: 0.6348\n",
            "Epoch 00269: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 285ms/step - loss: 0.7638 - acc: 0.6398 - val_loss: 0.8563 - val_acc: 0.6318\n",
            "Epoch 270/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7859 - acc: 0.6366Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8551 - acc: 0.6504\n",
            "Epoch 00270: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 293ms/step - loss: 0.7776 - acc: 0.6408 - val_loss: 0.8400 - val_acc: 0.6449\n",
            "Epoch 271/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8041 - acc: 0.6207Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.8173 - acc: 0.6355\n",
            "Epoch 00271: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 287ms/step - loss: 0.8053 - acc: 0.6205 - val_loss: 0.8173 - val_acc: 0.6355\n",
            "Epoch 272/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7855 - acc: 0.6292Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8481 - acc: 0.6348\n",
            "Epoch 00272: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 4s 279ms/step - loss: 0.7862 - acc: 0.6254 - val_loss: 0.8317 - val_acc: 0.6299\n",
            "Epoch 273/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7757 - acc: 0.6456Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.8601 - acc: 0.6152\n",
            "Epoch 00273: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 4s 243ms/step - loss: 0.7748 - acc: 0.6433 - val_loss: 0.8409 - val_acc: 0.6093\n",
            "Epoch 274/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7701 - acc: 0.6635Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8310 - acc: 0.6426\n",
            "Epoch 00274: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 300ms/step - loss: 0.7713 - acc: 0.6611 - val_loss: 0.8216 - val_acc: 0.6393\n",
            "Epoch 275/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7982 - acc: 0.6308Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8630 - acc: 0.6289\n",
            "Epoch 00275: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 0.7905 - acc: 0.6299 - val_loss: 0.8449 - val_acc: 0.6187\n",
            "Epoch 276/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7837 - acc: 0.6324Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8553 - acc: 0.6426\n",
            "Epoch 00276: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 0.7773 - acc: 0.6334 - val_loss: 0.8434 - val_acc: 0.6336\n",
            "Epoch 277/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7582 - acc: 0.6562Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.8415 - acc: 0.6262\n",
            "Epoch 00277: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 0.7579 - acc: 0.6538 - val_loss: 0.8415 - val_acc: 0.6262\n",
            "Epoch 278/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7874 - acc: 0.6319Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.8520 - acc: 0.6131\n",
            "Epoch 00278: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 304ms/step - loss: 0.7890 - acc: 0.6309 - val_loss: 0.8520 - val_acc: 0.6131\n",
            "Epoch 279/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7652 - acc: 0.6417Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8574 - acc: 0.6309\n",
            "Epoch 00279: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 296ms/step - loss: 0.7596 - acc: 0.6448 - val_loss: 0.8955 - val_acc: 0.6280\n",
            "Epoch 280/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7875 - acc: 0.6255Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8306 - acc: 0.6230\n",
            "Epoch 00280: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 283ms/step - loss: 0.7866 - acc: 0.6284 - val_loss: 0.8527 - val_acc: 0.6224\n",
            "Epoch 281/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7786 - acc: 0.6255Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.8670 - acc: 0.6093\n",
            "Epoch 00281: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 292ms/step - loss: 0.7717 - acc: 0.6274 - val_loss: 0.8670 - val_acc: 0.6093\n",
            "Epoch 282/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7825 - acc: 0.6259Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.8627 - acc: 0.6280\n",
            "Epoch 00282: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 4s 274ms/step - loss: 0.7796 - acc: 0.6284 - val_loss: 0.8627 - val_acc: 0.6280\n",
            "Epoch 283/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7584 - acc: 0.6510Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8450 - acc: 0.6230\n",
            "Epoch 00283: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 284ms/step - loss: 0.7599 - acc: 0.6509 - val_loss: 0.8590 - val_acc: 0.6262\n",
            "Epoch 284/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7716 - acc: 0.6366Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8332 - acc: 0.6172\n",
            "Epoch 00284: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 283ms/step - loss: 0.7743 - acc: 0.6359 - val_loss: 0.8376 - val_acc: 0.6131\n",
            "Epoch 285/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7823 - acc: 0.6302Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8544 - acc: 0.5977\n",
            "Epoch 00285: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 4s 271ms/step - loss: 0.7822 - acc: 0.6299 - val_loss: 0.8586 - val_acc: 0.5944\n",
            "Epoch 286/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7828 - acc: 0.6334Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8450 - acc: 0.6348\n",
            "Epoch 00286: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 288ms/step - loss: 0.7772 - acc: 0.6359 - val_loss: 0.8763 - val_acc: 0.6355\n",
            "Epoch 287/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7843 - acc: 0.6345Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8335 - acc: 0.6367\n",
            "Epoch 00287: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 293ms/step - loss: 0.7882 - acc: 0.6324 - val_loss: 0.8607 - val_acc: 0.6336\n",
            "Epoch 288/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7648 - acc: 0.6249Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.8367 - acc: 0.6280\n",
            "Epoch 00288: val_loss did not improve from 0.77086\n",
            "16/16 [==============================] - 5s 285ms/step - loss: 0.7604 - acc: 0.6269 - val_loss: 0.8367 - val_acc: 0.6280\n",
            "Epoch 00288: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hYD0cj0FIlv",
        "colab_type": "code",
        "outputId": "6478afb6-d5d7-43b3-ac56-de69e2f4e3d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "# History of accuracy and loss\n",
        "tra_loss_1 = history_1.history['loss']\n",
        "tra_acc_1 = history_1.history['acc']\n",
        "val_loss_1 = history_1.history['val_loss']\n",
        "val_acc_1 = history_1.history['val_acc']\n",
        "\n",
        "# Total number of epochs training\n",
        "epochs_1 = range(1, len(tra_acc_1)+1)\n",
        "end_epoch_1 = len(tra_acc_1)\n",
        "\n",
        "# Epoch when reached the validation loss minimum\n",
        "opt_epoch_1 = val_loss_1.index(min(val_loss_1)) + 1\n",
        "\n",
        "# Loss and accuracy on the validation set\n",
        "end_val_loss_1 = val_loss_1[-1]\n",
        "end_val_acc_1 = val_acc_1[-1]\n",
        "opt_val_loss_1 = val_loss_1[opt_epoch_1-1]\n",
        "opt_val_acc_1 = val_acc_1[opt_epoch_1-1]\n",
        "\n",
        "# Loss and accuracy on the test set\n",
        "opt_model_1 = models.load_model('model_1_4cl_best.h5')\n",
        "test_loss_1, test_acc_1 = model_1.evaluate(test_images, test_labels, verbose=False)\n",
        "opt_test_loss_1, opt_test_acc_1 = opt_model_1.evaluate(test_images, test_labels, verbose=False)\n",
        "opt_pred_1 = opt_model_1.predict([test_images, test_labels])\n",
        "pred_classes_1 = np.rint(opt_pred_1)\n",
        "\n",
        "print(\"Model 1\\n\")\n",
        "\n",
        "print(\"Epoch [end]: %d\" % end_epoch_1)\n",
        "print(\"Epoch [opt]: %d\" % opt_epoch_1)\n",
        "print(\"Valid accuracy [end]: %.4f\" % end_val_acc_1)\n",
        "print(\"Valid accuracy [opt]: %.4f\" % opt_val_acc_1)\n",
        "print(\"Test accuracy [end]:  %.4f\" % test_acc_1)\n",
        "print(\"Test accuracy [opt]:  %.4f\" % opt_test_acc_1)\n",
        "print(\"Valid loss [end]: %.4f\" % end_val_loss_1)\n",
        "print(\"Valid loss [opt]: %.4f\" % opt_val_loss_1)\n",
        "print(\"Test loss [end]:  %.4f\" % test_loss_1)\n",
        "print(\"Test loss [opt]:  %.4f\" % opt_test_loss_1)\n",
        "\n",
        "print(classification_report(test_labels, pred_classes_1, digits=4))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 1\n",
            "\n",
            "Epoch [end]: 288\n",
            "Epoch [opt]: 208\n",
            "Valid accuracy [end]: 0.6280\n",
            "Valid accuracy [opt]: 0.6355\n",
            "Test accuracy [end]:  0.5893\n",
            "Test accuracy [opt]:  0.5774\n",
            "Valid loss [end]: 0.8367\n",
            "Valid loss [opt]: 0.7709\n",
            "Test loss [end]:  0.9490\n",
            "Test loss [opt]:  0.9402\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6812    0.4159    0.5165       113\n",
            "           1     0.4750    0.2879    0.3585        66\n",
            "           2     0.7500    0.6226    0.6804       106\n",
            "           3     0.4783    0.4314    0.4536        51\n",
            "\n",
            "   micro avg     0.6337    0.4583    0.5320       336\n",
            "   macro avg     0.5961    0.4395    0.5022       336\n",
            "weighted avg     0.6316    0.4583    0.5276       336\n",
            " samples avg     0.4583    0.4583    0.4583       336\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djXJO9l1FX5E",
        "colab_type": "code",
        "outputId": "e87024b1-e064-4230-a7fa-5f834ebfd388",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 991
        }
      },
      "source": [
        "# Model accuracy\n",
        "plt.figure(figsize=(7, 7), dpi=80, facecolor='w', edgecolor='k')\n",
        "plt.title('Model 1 accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.plot(epochs_1, tra_acc_1, 'r', label='Training set')\n",
        "plt.plot(epochs_1, val_acc_1, 'g', label='Validation set')\n",
        "plt.plot(opt_epoch_1, val_acc_1[opt_epoch_1-1], 'go')\n",
        "plt.vlines(opt_epoch_1, min(val_acc_1), opt_val_acc_1, linestyle=\"dashed\", color='g', linewidth=1)\n",
        "plt.hlines(opt_val_acc_1, 1, opt_epoch_1, linestyle=\"dashed\", color='g', linewidth=1)\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "# Model loss\n",
        "plt.figure(figsize=(7, 7), dpi=80, facecolor='w', edgecolor='k')\n",
        "plt.title('Model 1 loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.plot(epochs_1, tra_loss_1, 'r', label='Training set')\n",
        "plt.plot(epochs_1, val_loss_1, 'g', label='Validation set')\n",
        "plt.plot(opt_epoch_1, val_loss_1[opt_epoch_1-1], 'go')\n",
        "plt.vlines(opt_epoch_1, min(val_loss_1), opt_val_loss_1, linestyle=\"dashed\", color='g', linewidth=1)\n",
        "plt.hlines(opt_val_loss_1, 1, opt_epoch_1, linestyle=\"dashed\", color='g', linewidth=1)\n",
        "plt.legend();"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfgAAAHnCAYAAABUqE8xAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+PjYTWgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 560x560 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfEAAAHnCAYAAACovWT7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncSIiIp9iiBMREfkUQ5yIiMin/gGsIwxKQgvH8QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 560x560 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1210CcFGLct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Htb-Iic8Gk4c",
        "colab_type": "code",
        "outputId": "837d0070-c59a-48e9-b8c9-a4bfb7802f0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "source": [
        "pred_1_classes = opt_model_1.predict_classes(test_images)\n",
        "confusion_mtx = confusion_matrix(test_labels_raw, pred_1_classes) \n",
        "plot_confusion_matrix(confusion_mtx, classes=range(4), title='Model 1 confusion matrix')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUUAAAEmCAYAAAD1FIKpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqmO_dPVJQ_-",
        "colab_type": "text"
      },
      "source": [
        "**Result**: the network obtained a 57.7% accuracy on the test set. This value is significantly lower than the almost 88% achieved in the 2-class classification task, but it is an obvious consequence of the increased number of classes. Now it is sufficient to mispredict the type OR the malignancy to consider that sample classified wrong. \n",
        "The confusion matrix provides very useful information here. Remembering how the labels were mapped to classes (documented [here](https://colab.research.google.com/drive/1frEEh7C_EQSmSiFS7FygFKI0eqybFmNb#scrollTo=u_Q0cPtr3jJt&line=11&uniqifier=1)), one may observe that 44 images were assigned the wrong type (mass/calc), that is corresponds 13.1% of the samples. In other words, ignoring the malignancy, that corresponds to a 86.3% accuracy, in line with the results achieved by the pure 2-class classifier.\n",
        "It is worth to point out that most of the mistakes are indeed due to benign/malignant misclassification, rather than mass/calcification swapping.\n",
        "Apparently, the task of predicting the harmfulness is inherently a more difficult task than identifying the type of abnormality.\n",
        "Finally, a moderate overfitting is noticeable at the end of the training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Oep0He--M5sB"
      },
      "source": [
        "## Experiment 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tvCCSTvHM5sK"
      },
      "source": [
        "The second model is shallower, but with twice the filters than before in the corresponding layers.\n",
        "Alternatively, it can be seen as \n",
        "a clone of the previous where the first conv block has been skipped.\n",
        "The hypothesis to verify is that more filters in early convolutional stages can help achieving a better accuracy.\n",
        "\n",
        "Specifically:\n",
        "\n",
        "*   Three conv2D layer with 64, 128, 256 filters\n",
        "*   The last FC layer has few more neurons (64, previously was 48) to cope with the increased filters\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "08ebf9f4-7fa4-4815-ecd9-b9275595a325",
        "id": "DnPEZzWsM5sM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "# Model 2\n",
        "\n",
        "model_2 = models.Sequential()\n",
        "model_2.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(150, 150, 1)))\n",
        "model_2.add(layers.MaxPooling2D((2, 2)))\n",
        "model_2.add(layers.Conv2D(128, (3, 3), activation='relu')\n",
        "model_2.add(layers.MaxPooling2D((2, 2)))\n",
        "model_2.add(layers.Conv2D(256, (3, 3), activation='relu')\n",
        "model_2.add(layers.MaxPooling2D((2, 2)))\n",
        "model_2.add(layers.Flatten())\n",
        "model_2.add(layers.Dense(64, activation='relu'))\n",
        "model_2.add(layers.Dropout(0.5))\n",
        "model_2.add(layers.Dense(4, activation='softmax'))\n",
        "\n",
        "model_2.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_16 (Conv2D)           (None, 148, 148, 64)      640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 74, 74, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 72, 72, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 36, 36, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 34, 34, 256)       295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 17, 17, 256)       0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 73984)             0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 64)                4735040   \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 4)                 260       \n",
            "=================================================================\n",
            "Total params: 5,104,964\n",
            "Trainable params: 5,104,964\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cR489mF0NVXN",
        "colab_type": "code",
        "outputId": "93c2f203-cf9d-459d-f49f-2d1c07735f36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Early stopping (stop training after the validation loss reaches the minimum)\n",
        "earlystopping = EarlyStopping(monitor='val_loss', mode='min', patience=80, verbose=1)\n",
        "\n",
        "# Callback for checkpointing\n",
        "checkpoint = ModelCheckpoint('model_2_4cl_best.h5', \n",
        "        monitor='val_loss', mode='min', verbose=1, \n",
        "        save_best_only=True, save_freq='epoch'\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model_2.compile(optimizer=RMSprop(learning_rate=0.001, decay=5e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "history_2 = model_2.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=int(0.8*n_train_img) // 128,\n",
        "        epochs=500,\n",
        "        validation_data=validation_generator,\n",
        "        callbacks=[checkpoint, earlystopping],\n",
        "        shuffle=True,\n",
        "        verbose=1,\n",
        "        initial_epoch=0\n",
        ")\n",
        "\n",
        "# Save\n",
        "models.save_model(model_2, 'model_2_4cl_end.h5')\n",
        "!cp model* \"/content/gdrive/My Drive/models/\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 2.1200 - acc: 0.3225Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 1.9218 - acc: 0.3477\n",
            "Epoch 00001: val_loss improved from inf to 1.89228, saving model to model_2_4cl_best.h5\n",
            "16/16 [==============================] - 7s 445ms/step - loss: 2.0709 - acc: 0.3299 - val_loss: 1.8923 - val_acc: 0.3514\n",
            "Epoch 2/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.4331 - acc: 0.3292Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 1.3677 - acc: 0.3477\n",
            "Epoch 00002: val_loss improved from 1.89228 to 1.36348, saving model to model_2_4cl_best.h5\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 1.4298 - acc: 0.3315 - val_loss: 1.3635 - val_acc: 0.3514\n",
            "Epoch 3/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.3667 - acc: 0.3589Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 1.3633 - acc: 0.3477\n",
            "Epoch 00003: val_loss improved from 1.36348 to 1.35604, saving model to model_2_4cl_best.h5\n",
            "16/16 [==============================] - 6s 361ms/step - loss: 1.3701 - acc: 0.3559 - val_loss: 1.3560 - val_acc: 0.3514\n",
            "Epoch 4/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.3734 - acc: 0.3401Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.3573 - acc: 0.3477\n",
            "Epoch 00004: val_loss improved from 1.35604 to 1.34552, saving model to model_2_4cl_best.h5\n",
            "16/16 [==============================] - 6s 365ms/step - loss: 1.3723 - acc: 0.3423 - val_loss: 1.3455 - val_acc: 0.3514\n",
            "Epoch 5/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.4100 - acc: 0.3565Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.3689 - acc: 0.3457\n",
            "Epoch 00005: val_loss did not improve from 1.34552\n",
            "16/16 [==============================] - 6s 374ms/step - loss: 1.4083 - acc: 0.3547 - val_loss: 1.3644 - val_acc: 0.3495\n",
            "Epoch 6/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.3921 - acc: 0.3438Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.3694 - acc: 0.3555\n",
            "Epoch 00006: val_loss did not improve from 1.34552\n",
            "16/16 [==============================] - 6s 377ms/step - loss: 1.3932 - acc: 0.3384 - val_loss: 1.3668 - val_acc: 0.3551\n",
            "Epoch 7/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.3712 - acc: 0.3422Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.3572 - acc: 0.3496\n",
            "Epoch 00007: val_loss did not improve from 1.34552\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 1.3703 - acc: 0.3433 - val_loss: 1.3472 - val_acc: 0.3533\n",
            "Epoch 8/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.3594 - acc: 0.3756Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.3554 - acc: 0.3457\n",
            "Epoch 00008: val_loss did not improve from 1.34552\n",
            "16/16 [==============================] - 6s 364ms/step - loss: 1.3604 - acc: 0.3726 - val_loss: 1.3477 - val_acc: 0.3495\n",
            "Epoch 9/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.3630 - acc: 0.3344Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.3527 - acc: 0.3535\n",
            "Epoch 00009: val_loss improved from 1.34552 to 1.33973, saving model to model_2_4cl_best.h5\n",
            "16/16 [==============================] - 6s 376ms/step - loss: 1.3624 - acc: 0.3306 - val_loss: 1.3397 - val_acc: 0.3570\n",
            "Epoch 10/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.3440 - acc: 0.3676Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.3448 - acc: 0.3535\n",
            "Epoch 00010: val_loss improved from 1.33973 to 1.33630, saving model to model_2_4cl_best.h5\n",
            "16/16 [==============================] - 6s 369ms/step - loss: 1.3575 - acc: 0.3577 - val_loss: 1.3363 - val_acc: 0.3570\n",
            "Epoch 11/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.3324 - acc: 0.3634Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.3294 - acc: 0.3555\n",
            "Epoch 00011: val_loss improved from 1.33630 to 1.31141, saving model to model_2_4cl_best.h5\n",
            "16/16 [==============================] - 6s 366ms/step - loss: 1.3326 - acc: 0.3631 - val_loss: 1.3114 - val_acc: 0.3589\n",
            "Epoch 12/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.3390 - acc: 0.3671Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.3399 - acc: 0.3496\n",
            "Epoch 00012: val_loss improved from 1.31141 to 1.29770, saving model to model_2_4cl_best.h5\n",
            "16/16 [==============================] - 6s 357ms/step - loss: 1.3360 - acc: 0.3676 - val_loss: 1.2977 - val_acc: 0.3551\n",
            "Epoch 13/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.3158 - acc: 0.3611Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.2810 - acc: 0.3750\n",
            "Epoch 00013: val_loss improved from 1.29770 to 1.25822, saving model to model_2_4cl_best.h5\n",
            "16/16 [==============================] - 6s 359ms/step - loss: 1.3145 - acc: 0.3635 - val_loss: 1.2582 - val_acc: 0.3813\n",
            "Epoch 14/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.3318 - acc: 0.3755Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.3079 - acc: 0.3633\n",
            "Epoch 00014: val_loss did not improve from 1.25822\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 1.3266 - acc: 0.3809 - val_loss: 1.2927 - val_acc: 0.3701\n",
            "Epoch 15/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.3025 - acc: 0.3804Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.2573 - acc: 0.3945\n",
            "Epoch 00015: val_loss improved from 1.25822 to 1.25452, saving model to model_2_4cl_best.h5\n",
            "16/16 [==============================] - 6s 361ms/step - loss: 1.3048 - acc: 0.3770 - val_loss: 1.2545 - val_acc: 0.3944\n",
            "Epoch 16/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.2991 - acc: 0.4016Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.2748 - acc: 0.4766\n",
            "Epoch 00016: val_loss did not improve from 1.25452\n",
            "16/16 [==============================] - 6s 352ms/step - loss: 1.2967 - acc: 0.3989 - val_loss: 1.2662 - val_acc: 0.4804\n",
            "Epoch 17/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.2657 - acc: 0.4308Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.2628 - acc: 0.4785\n",
            "Epoch 00017: val_loss improved from 1.25452 to 1.25433, saving model to model_2_4cl_best.h5\n",
            "16/16 [==============================] - 6s 351ms/step - loss: 1.2680 - acc: 0.4287 - val_loss: 1.2543 - val_acc: 0.4785\n",
            "Epoch 18/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.2434 - acc: 0.4224Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 1.2369 - acc: 0.3867\n",
            "Epoch 00018: val_loss improved from 1.25433 to 1.22296, saving model to model_2_4cl_best.h5\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 1.2391 - acc: 0.4247 - val_loss: 1.2230 - val_acc: 0.3907\n",
            "Epoch 19/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.2104 - acc: 0.4610Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 1.2205 - acc: 0.4414\n",
            "Epoch 00019: val_loss improved from 1.22296 to 1.21546, saving model to model_2_4cl_best.h5\n",
            "16/16 [==============================] - 6s 348ms/step - loss: 1.2152 - acc: 0.4570 - val_loss: 1.2155 - val_acc: 0.4411\n",
            "Epoch 20/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.2359 - acc: 0.4403Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 1.2206 - acc: 0.4648\n",
            "Epoch 00020: val_loss did not improve from 1.21546\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 1.2389 - acc: 0.4372 - val_loss: 1.2156 - val_acc: 0.4598\n",
            "Epoch 21/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1918 - acc: 0.4615Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.1836 - acc: 0.4160\n",
            "Epoch 00021: val_loss improved from 1.21546 to 1.17040, saving model to model_2_4cl_best.h5\n",
            "16/16 [==============================] - 6s 374ms/step - loss: 1.1897 - acc: 0.4670 - val_loss: 1.1704 - val_acc: 0.4168\n",
            "Epoch 22/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1783 - acc: 0.4583Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.1518 - acc: 0.4551\n",
            "Epoch 00022: val_loss did not improve from 1.17040\n",
            "16/16 [==============================] - 6s 373ms/step - loss: 1.1788 - acc: 0.4575 - val_loss: 1.1857 - val_acc: 0.4505\n",
            "Epoch 23/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1939 - acc: 0.4786Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.1429 - acc: 0.4648\n",
            "Epoch 00023: val_loss did not improve from 1.17040\n",
            "16/16 [==============================] - 6s 374ms/step - loss: 1.1900 - acc: 0.4775 - val_loss: 1.1735 - val_acc: 0.4617\n",
            "Epoch 24/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1755 - acc: 0.4654Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.1429 - acc: 0.5156\n",
            "Epoch 00024: val_loss did not improve from 1.17040\n",
            "16/16 [==============================] - 6s 368ms/step - loss: 1.1780 - acc: 0.4631 - val_loss: 1.1960 - val_acc: 0.5103\n",
            "Epoch 25/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1784 - acc: 0.4658Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0818 - acc: 0.5332\n",
            "Epoch 00025: val_loss improved from 1.17040 to 1.10237, saving model to model_2_4cl_best.h5\n",
            "16/16 [==============================] - 6s 366ms/step - loss: 1.1743 - acc: 0.4670 - val_loss: 1.1024 - val_acc: 0.5290\n",
            "Epoch 26/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1349 - acc: 0.4984Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.1469 - acc: 0.5000\n",
            "Epoch 00026: val_loss did not improve from 1.10237\n",
            "16/16 [==============================] - 6s 369ms/step - loss: 1.1360 - acc: 0.4976 - val_loss: 1.1712 - val_acc: 0.5009\n",
            "Epoch 27/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1764 - acc: 0.4684Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.1092 - acc: 0.5098\n",
            "Epoch 00027: val_loss did not improve from 1.10237\n",
            "16/16 [==============================] - 6s 364ms/step - loss: 1.1694 - acc: 0.4690 - val_loss: 1.1407 - val_acc: 0.5065\n",
            "Epoch 28/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1216 - acc: 0.4976Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.1761 - acc: 0.5059\n",
            "Epoch 00028: val_loss did not improve from 1.10237\n",
            "16/16 [==============================] - 6s 363ms/step - loss: 1.1213 - acc: 0.4943 - val_loss: 1.2233 - val_acc: 0.4953\n",
            "Epoch 29/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1729 - acc: 0.4780Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.1151 - acc: 0.5078\n",
            "Epoch 00029: val_loss improved from 1.10237 to 1.07209, saving model to model_2_4cl_best.h5\n",
            "16/16 [==============================] - 6s 374ms/step - loss: 1.1708 - acc: 0.4769 - val_loss: 1.0721 - val_acc: 0.5159\n",
            "Epoch 30/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1211 - acc: 0.5024Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.1238 - acc: 0.5098\n",
            "Epoch 00030: val_loss did not improve from 1.07209\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 1.1250 - acc: 0.4983 - val_loss: 1.1019 - val_acc: 0.5121\n",
            "Epoch 31/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1413 - acc: 0.4881Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0773 - acc: 0.5117\n",
            "Epoch 00031: val_loss did not improve from 1.07209\n",
            "16/16 [==============================] - 6s 357ms/step - loss: 1.1360 - acc: 0.4898 - val_loss: 1.0928 - val_acc: 0.5159\n",
            "Epoch 32/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1011 - acc: 0.4923Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.1558 - acc: 0.4375\n",
            "Epoch 00032: val_loss did not improve from 1.07209\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 1.1055 - acc: 0.4893 - val_loss: 1.1666 - val_acc: 0.4430\n",
            "Epoch 33/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1171 - acc: 0.4865Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0850 - acc: 0.5117\n",
            "Epoch 00033: val_loss did not improve from 1.07209\n",
            "16/16 [==============================] - 6s 352ms/step - loss: 1.1109 - acc: 0.4878 - val_loss: 1.0803 - val_acc: 0.5140\n",
            "Epoch 34/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1759 - acc: 0.4859Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0746 - acc: 0.5117\n",
            "Epoch 00034: val_loss improved from 1.07209 to 1.02610, saving model to model_2_4cl_best.h5\n",
            "16/16 [==============================] - 6s 353ms/step - loss: 1.1655 - acc: 0.4888 - val_loss: 1.0261 - val_acc: 0.5159\n",
            "Epoch 35/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0880 - acc: 0.4981Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 1.0680 - acc: 0.5059\n",
            "Epoch 00035: val_loss did not improve from 1.02610\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 1.0932 - acc: 0.4958 - val_loss: 1.0935 - val_acc: 0.5084\n",
            "Epoch 36/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1219 - acc: 0.4891Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 1.0170 - acc: 0.5371\n",
            "Epoch 00036: val_loss improved from 1.02610 to 1.01067, saving model to model_2_4cl_best.h5\n",
            "16/16 [==============================] - 6s 359ms/step - loss: 1.1228 - acc: 0.4918 - val_loss: 1.0107 - val_acc: 0.5383\n",
            "Epoch 37/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1110 - acc: 0.5115Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 1.1062 - acc: 0.4590\n",
            "Epoch 00037: val_loss did not improve from 1.01067\n",
            "16/16 [==============================] - 6s 356ms/step - loss: 1.1061 - acc: 0.5142 - val_loss: 1.0979 - val_acc: 0.4617\n",
            "Epoch 38/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1349 - acc: 0.4950Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0420 - acc: 0.5410\n",
            "Epoch 00038: val_loss did not improve from 1.01067\n",
            "16/16 [==============================] - 6s 361ms/step - loss: 1.1322 - acc: 0.4938 - val_loss: 1.0291 - val_acc: 0.5439\n",
            "Epoch 39/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0798 - acc: 0.5094Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0868 - acc: 0.5352\n",
            "Epoch 00039: val_loss did not improve from 1.01067\n",
            "16/16 [==============================] - 6s 375ms/step - loss: 1.0832 - acc: 0.5078 - val_loss: 1.0582 - val_acc: 0.5383\n",
            "Epoch 40/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1324 - acc: 0.5027Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.1043 - acc: 0.4648\n",
            "Epoch 00040: val_loss did not improve from 1.01067\n",
            "16/16 [==============================] - 6s 365ms/step - loss: 1.1327 - acc: 0.5035 - val_loss: 1.1146 - val_acc: 0.4710\n",
            "Epoch 41/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1111 - acc: 0.4960Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0204 - acc: 0.5391\n",
            "Epoch 00041: val_loss did not improve from 1.01067\n",
            "16/16 [==============================] - 6s 368ms/step - loss: 1.1148 - acc: 0.4913 - val_loss: 1.0336 - val_acc: 0.5402\n",
            "Epoch 42/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0727 - acc: 0.5271Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0985 - acc: 0.5254\n",
            "Epoch 00042: val_loss did not improve from 1.01067\n",
            "16/16 [==============================] - 6s 373ms/step - loss: 1.0888 - acc: 0.5171 - val_loss: 1.1045 - val_acc: 0.5271\n",
            "Epoch 43/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1224 - acc: 0.4903Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.1132 - acc: 0.4961\n",
            "Epoch 00043: val_loss did not improve from 1.01067\n",
            "16/16 [==============================] - 6s 362ms/step - loss: 1.1108 - acc: 0.4949 - val_loss: 1.1805 - val_acc: 0.4972\n",
            "Epoch 44/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1018 - acc: 0.5167Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0588 - acc: 0.5176\n",
            "Epoch 00044: val_loss did not improve from 1.01067\n",
            "16/16 [==============================] - 6s 365ms/step - loss: 1.1036 - acc: 0.5142 - val_loss: 1.0568 - val_acc: 0.5196\n",
            "Epoch 45/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1007 - acc: 0.5240Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0646 - acc: 0.5176\n",
            "Epoch 00045: val_loss did not improve from 1.01067\n",
            "16/16 [==============================] - 6s 369ms/step - loss: 1.1030 - acc: 0.5220 - val_loss: 1.0648 - val_acc: 0.5215\n",
            "Epoch 46/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0869 - acc: 0.5268Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9946 - acc: 0.5625\n",
            "Epoch 00046: val_loss improved from 1.01067 to 0.99793, saving model to model_2_4cl_best.h5\n",
            "16/16 [==============================] - 6s 364ms/step - loss: 1.0874 - acc: 0.5266 - val_loss: 0.9979 - val_acc: 0.5607\n",
            "Epoch 47/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0623 - acc: 0.5241Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.1090 - acc: 0.5176\n",
            "Epoch 00047: val_loss did not improve from 0.99793\n",
            "16/16 [==============================] - 6s 356ms/step - loss: 1.0679 - acc: 0.5186 - val_loss: 1.1216 - val_acc: 0.5196\n",
            "Epoch 48/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0951 - acc: 0.5114Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0147 - acc: 0.5195\n",
            "Epoch 00048: val_loss did not improve from 0.99793\n",
            "16/16 [==============================] - 6s 352ms/step - loss: 1.0896 - acc: 0.5142 - val_loss: 1.0196 - val_acc: 0.5234\n",
            "Epoch 49/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0935 - acc: 0.5263Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0355 - acc: 0.5312\n",
            "Epoch 00049: val_loss did not improve from 0.99793\n",
            "16/16 [==============================] - 6s 353ms/step - loss: 1.0959 - acc: 0.5236 - val_loss: 1.0315 - val_acc: 0.5327\n",
            "Epoch 50/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0816 - acc: 0.5019Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0135 - acc: 0.5176\n",
            "Epoch 00050: val_loss did not improve from 0.99793\n",
            "16/16 [==============================] - 6s 351ms/step - loss: 1.0772 - acc: 0.5037 - val_loss: 1.0255 - val_acc: 0.5196\n",
            "Epoch 51/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0712 - acc: 0.5151Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0162 - acc: 0.5176\n",
            "Epoch 00051: val_loss did not improve from 0.99793\n",
            "16/16 [==============================] - 6s 347ms/step - loss: 1.0660 - acc: 0.5181 - val_loss: 1.0450 - val_acc: 0.5215\n",
            "Epoch 52/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0660 - acc: 0.5114Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 1.0318 - acc: 0.5176\n",
            "Epoch 00052: val_loss improved from 0.99793 to 0.97854, saving model to model_2_4cl_best.h5\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 1.0688 - acc: 0.5137 - val_loss: 0.9785 - val_acc: 0.5290\n",
            "Epoch 53/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1255 - acc: 0.5141Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 1.0540 - acc: 0.5254\n",
            "Epoch 00053: val_loss did not improve from 0.97854\n",
            "16/16 [==============================] - 6s 347ms/step - loss: 1.1264 - acc: 0.5107 - val_loss: 1.0340 - val_acc: 0.5290\n",
            "Epoch 54/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0476 - acc: 0.5300Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 1.0456 - acc: 0.5176\n",
            "Epoch 00054: val_loss did not improve from 0.97854\n",
            "16/16 [==============================] - 6s 360ms/step - loss: 1.0557 - acc: 0.5281 - val_loss: 1.0371 - val_acc: 0.5196\n",
            "Epoch 55/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0641 - acc: 0.5363Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9995 - acc: 0.5566\n",
            "Epoch 00055: val_loss improved from 0.97854 to 0.96246, saving model to model_2_4cl_best.h5\n",
            "16/16 [==============================] - 6s 375ms/step - loss: 1.0620 - acc: 0.5365 - val_loss: 0.9625 - val_acc: 0.5589\n",
            "Epoch 56/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0673 - acc: 0.5178Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9831 - acc: 0.5547\n",
            "Epoch 00056: val_loss did not improve from 0.96246\n",
            "16/16 [==============================] - 6s 379ms/step - loss: 1.0698 - acc: 0.5181 - val_loss: 0.9761 - val_acc: 0.5514\n",
            "Epoch 57/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0445 - acc: 0.5332Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0383 - acc: 0.5039\n",
            "Epoch 00057: val_loss did not improve from 0.96246\n",
            "16/16 [==============================] - 6s 365ms/step - loss: 1.0466 - acc: 0.5315 - val_loss: 0.9997 - val_acc: 0.5047\n",
            "Epoch 58/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0641 - acc: 0.5210Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0786 - acc: 0.4980\n",
            "Epoch 00058: val_loss did not improve from 0.96246\n",
            "16/16 [==============================] - 6s 373ms/step - loss: 1.0638 - acc: 0.5241 - val_loss: 1.0454 - val_acc: 0.4991\n",
            "Epoch 59/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0341 - acc: 0.5401Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9844 - acc: 0.5254\n",
            "Epoch 00059: val_loss did not improve from 0.96246\n",
            "16/16 [==============================] - 6s 366ms/step - loss: 1.0391 - acc: 0.5425 - val_loss: 0.9904 - val_acc: 0.5252\n",
            "Epoch 60/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0413 - acc: 0.5328Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0637 - acc: 0.5430\n",
            "Epoch 00060: val_loss did not improve from 0.96246\n",
            "16/16 [==============================] - 6s 369ms/step - loss: 1.0482 - acc: 0.5264 - val_loss: 1.0519 - val_acc: 0.5421\n",
            "Epoch 61/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0614 - acc: 0.5353Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9782 - acc: 0.5352\n",
            "Epoch 00061: val_loss improved from 0.96246 to 0.96096, saving model to model_2_4cl_best.h5\n",
            "16/16 [==============================] - 6s 367ms/step - loss: 1.0543 - acc: 0.5370 - val_loss: 0.9610 - val_acc: 0.5346\n",
            "Epoch 62/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0452 - acc: 0.5485Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0282 - acc: 0.5508\n",
            "Epoch 00062: val_loss did not improve from 0.96096\n",
            "16/16 [==============================] - 6s 361ms/step - loss: 1.0362 - acc: 0.5504 - val_loss: 1.0237 - val_acc: 0.5514\n",
            "Epoch 63/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0469 - acc: 0.5337Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0026 - acc: 0.5293\n",
            "Epoch 00063: val_loss did not improve from 0.96096\n",
            "16/16 [==============================] - 6s 368ms/step - loss: 1.0450 - acc: 0.5340 - val_loss: 0.9800 - val_acc: 0.5327\n",
            "Epoch 64/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0981 - acc: 0.5279Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0082 - acc: 0.5273\n",
            "Epoch 00064: val_loss did not improve from 0.96096\n",
            "16/16 [==============================] - 6s 351ms/step - loss: 1.0938 - acc: 0.5291 - val_loss: 1.0026 - val_acc: 0.5290\n",
            "Epoch 65/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0177 - acc: 0.5517Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0144 - acc: 0.5273\n",
            "Epoch 00065: val_loss did not improve from 0.96096\n",
            "16/16 [==============================] - 6s 356ms/step - loss: 1.0289 - acc: 0.5450 - val_loss: 1.0062 - val_acc: 0.5252\n",
            "Epoch 66/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0188 - acc: 0.5454Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9893 - acc: 0.5566\n",
            "Epoch 00066: val_loss did not improve from 0.96096\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 1.0221 - acc: 0.5464 - val_loss: 0.9884 - val_acc: 0.5533\n",
            "Epoch 67/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9892 - acc: 0.5660Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0584 - acc: 0.5098\n",
            "Epoch 00067: val_loss did not improve from 0.96096\n",
            "16/16 [==============================] - 6s 345ms/step - loss: 0.9923 - acc: 0.5638 - val_loss: 1.0835 - val_acc: 0.5065\n",
            "Epoch 68/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0500 - acc: 0.5279Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9676 - acc: 0.5918\n",
            "Epoch 00068: val_loss did not improve from 0.96096\n",
            "16/16 [==============================] - 6s 345ms/step - loss: 1.0503 - acc: 0.5301 - val_loss: 0.9939 - val_acc: 0.5850\n",
            "Epoch 69/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0076 - acc: 0.5594Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 1.0066 - acc: 0.5469\n",
            "Epoch 00069: val_loss did not improve from 0.96096\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 1.0102 - acc: 0.5574 - val_loss: 1.0264 - val_acc: 0.5439\n",
            "Epoch 70/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0226 - acc: 0.5464Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 1.0102 - acc: 0.5391\n",
            "Epoch 00070: val_loss did not improve from 0.96096\n",
            "16/16 [==============================] - 6s 357ms/step - loss: 1.0183 - acc: 0.5479 - val_loss: 1.0207 - val_acc: 0.5346\n",
            "Epoch 71/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0193 - acc: 0.5549Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.9819 - acc: 0.5547\n",
            "Epoch 00071: val_loss did not improve from 0.96096\n",
            "16/16 [==============================] - 6s 369ms/step - loss: 1.0097 - acc: 0.5633 - val_loss: 0.9942 - val_acc: 0.5551\n",
            "Epoch 72/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0443 - acc: 0.5453Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9750 - acc: 0.5449\n",
            "Epoch 00072: val_loss did not improve from 0.96096\n",
            "16/16 [==============================] - 6s 371ms/step - loss: 1.0444 - acc: 0.5464 - val_loss: 1.0022 - val_acc: 0.5402\n",
            "Epoch 73/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0021 - acc: 0.5378Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.9693 - acc: 0.3828\n",
            "Epoch 00073: val_loss did not improve from 0.96096\n",
            "16/16 [==============================] - 6s 370ms/step - loss: 0.9965 - acc: 0.5415 - val_loss: 2.0367 - val_acc: 0.3813\n",
            "Epoch 74/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0868 - acc: 0.5307Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9384 - acc: 0.5723\n",
            "Epoch 00074: val_loss did not improve from 0.96096\n",
            "16/16 [==============================] - 6s 371ms/step - loss: 1.0811 - acc: 0.5317 - val_loss: 0.9821 - val_acc: 0.5664\n",
            "Epoch 75/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9871 - acc: 0.5508Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9276 - acc: 0.5566\n",
            "Epoch 00075: val_loss improved from 0.96096 to 0.94733, saving model to model_2_4cl_best.h5\n",
            "16/16 [==============================] - 6s 365ms/step - loss: 0.9981 - acc: 0.5470 - val_loss: 0.9473 - val_acc: 0.5533\n",
            "Epoch 76/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9825 - acc: 0.5656Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9668 - acc: 0.5410\n",
            "Epoch 00076: val_loss did not improve from 0.94733\n",
            "16/16 [==============================] - 6s 381ms/step - loss: 0.9838 - acc: 0.5669 - val_loss: 1.0272 - val_acc: 0.5364\n",
            "Epoch 77/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9909 - acc: 0.5486Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9717 - acc: 0.5645\n",
            "Epoch 00077: val_loss did not improve from 0.94733\n",
            "16/16 [==============================] - 6s 364ms/step - loss: 0.9951 - acc: 0.5445 - val_loss: 0.9996 - val_acc: 0.5607\n",
            "Epoch 78/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0048 - acc: 0.5677Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0044 - acc: 0.5527\n",
            "Epoch 00078: val_loss did not improve from 0.94733\n",
            "16/16 [==============================] - 6s 368ms/step - loss: 1.0005 - acc: 0.5698 - val_loss: 1.0036 - val_acc: 0.5514\n",
            "Epoch 79/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9754 - acc: 0.5627Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9194 - acc: 0.5781\n",
            "Epoch 00079: val_loss did not improve from 0.94733\n",
            "16/16 [==============================] - 6s 354ms/step - loss: 0.9711 - acc: 0.5652 - val_loss: 0.9502 - val_acc: 0.5720\n",
            "Epoch 80/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9995 - acc: 0.5464Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9472 - acc: 0.5781\n",
            "Epoch 00080: val_loss did not improve from 0.94733\n",
            "16/16 [==============================] - 6s 357ms/step - loss: 0.9953 - acc: 0.5504 - val_loss: 1.0106 - val_acc: 0.5720\n",
            "Epoch 81/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9915 - acc: 0.5698Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9459 - acc: 0.5566\n",
            "Epoch 00081: val_loss did not improve from 0.94733\n",
            "16/16 [==============================] - 6s 356ms/step - loss: 0.9919 - acc: 0.5688 - val_loss: 0.9621 - val_acc: 0.5589\n",
            "Epoch 82/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9954 - acc: 0.5620Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9677 - acc: 0.5645\n",
            "Epoch 00082: val_loss did not improve from 0.94733\n",
            "16/16 [==============================] - 6s 359ms/step - loss: 0.9918 - acc: 0.5640 - val_loss: 1.0061 - val_acc: 0.5607\n",
            "Epoch 83/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9638 - acc: 0.5650Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9575 - acc: 0.5410\n",
            "Epoch 00083: val_loss did not improve from 0.94733\n",
            "16/16 [==============================] - 6s 348ms/step - loss: 0.9657 - acc: 0.5633 - val_loss: 1.0091 - val_acc: 0.5402\n",
            "Epoch 84/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9858 - acc: 0.5660Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9405 - acc: 0.5781\n",
            "Epoch 00084: val_loss did not improve from 0.94733\n",
            "16/16 [==============================] - 6s 349ms/step - loss: 0.9835 - acc: 0.5638 - val_loss: 1.0155 - val_acc: 0.5701\n",
            "Epoch 85/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9716 - acc: 0.5666Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0939 - acc: 0.4766\n",
            "Epoch 00085: val_loss did not improve from 0.94733\n",
            "16/16 [==============================] - 6s 353ms/step - loss: 0.9719 - acc: 0.5673 - val_loss: 1.1471 - val_acc: 0.4748\n",
            "Epoch 86/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9785 - acc: 0.5507Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 1.0228 - acc: 0.5312\n",
            "Epoch 00086: val_loss did not improve from 0.94733\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 0.9857 - acc: 0.5474 - val_loss: 1.0124 - val_acc: 0.5364\n",
            "Epoch 87/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9752 - acc: 0.5474Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 1.0140 - acc: 0.5332\n",
            "Epoch 00087: val_loss did not improve from 0.94733\n",
            "16/16 [==============================] - 6s 356ms/step - loss: 0.9658 - acc: 0.5547 - val_loss: 0.9931 - val_acc: 0.5402\n",
            "Epoch 88/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9870 - acc: 0.5632Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.9543 - acc: 0.5703\n",
            "Epoch 00088: val_loss improved from 0.94733 to 0.92621, saving model to model_2_4cl_best.h5\n",
            "16/16 [==============================] - 6s 361ms/step - loss: 0.9891 - acc: 0.5637 - val_loss: 0.9262 - val_acc: 0.5757\n",
            "Epoch 89/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9481 - acc: 0.5724Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.1393 - acc: 0.4883\n",
            "Epoch 00089: val_loss did not improve from 0.92621\n",
            "16/16 [==============================] - 6s 365ms/step - loss: 0.9677 - acc: 0.5663 - val_loss: 1.1468 - val_acc: 0.4879\n",
            "Epoch 90/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9875 - acc: 0.5592Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9435 - acc: 0.5488\n",
            "Epoch 00090: val_loss improved from 0.92621 to 0.91947, saving model to model_2_4cl_best.h5\n",
            "16/16 [==============================] - 6s 377ms/step - loss: 0.9841 - acc: 0.5614 - val_loss: 0.9195 - val_acc: 0.5551\n",
            "Epoch 91/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9262 - acc: 0.5885Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9942 - acc: 0.5371\n",
            "Epoch 00091: val_loss did not improve from 0.91947\n",
            "16/16 [==============================] - 6s 375ms/step - loss: 0.9308 - acc: 0.5869 - val_loss: 0.9620 - val_acc: 0.5402\n",
            "Epoch 92/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0066 - acc: 0.5528Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9520 - acc: 0.5449\n",
            "Epoch 00092: val_loss did not improve from 0.91947\n",
            "16/16 [==============================] - 6s 371ms/step - loss: 0.9953 - acc: 0.5594 - val_loss: 0.9224 - val_acc: 0.5458\n",
            "Epoch 93/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9598 - acc: 0.5573Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9905 - acc: 0.5449\n",
            "Epoch 00093: val_loss did not improve from 0.91947\n",
            "16/16 [==============================] - 6s 360ms/step - loss: 0.9622 - acc: 0.5561 - val_loss: 0.9651 - val_acc: 0.5514\n",
            "Epoch 94/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9413 - acc: 0.5682Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9803 - acc: 0.5469\n",
            "Epoch 00094: val_loss did not improve from 0.91947\n",
            "16/16 [==============================] - 6s 377ms/step - loss: 0.9472 - acc: 0.5640 - val_loss: 0.9733 - val_acc: 0.5514\n",
            "Epoch 95/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9776 - acc: 0.5655Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9872 - acc: 0.5547\n",
            "Epoch 00095: val_loss improved from 0.91947 to 0.91438, saving model to model_2_4cl_best.h5\n",
            "16/16 [==============================] - 6s 364ms/step - loss: 0.9796 - acc: 0.5614 - val_loss: 0.9144 - val_acc: 0.5626\n",
            "Epoch 96/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9391 - acc: 0.5745Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9653 - acc: 0.5605\n",
            "Epoch 00096: val_loss improved from 0.91438 to 0.88698, saving model to model_2_4cl_best.h5\n",
            "16/16 [==============================] - 6s 366ms/step - loss: 0.9416 - acc: 0.5733 - val_loss: 0.8870 - val_acc: 0.5720\n",
            "Epoch 97/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9736 - acc: 0.5568Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9459 - acc: 0.5762\n",
            "Epoch 00097: val_loss did not improve from 0.88698\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 0.9732 - acc: 0.5566 - val_loss: 0.8946 - val_acc: 0.5869\n",
            "Epoch 98/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9482 - acc: 0.5656Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0063 - acc: 0.5430\n",
            "Epoch 00098: val_loss did not improve from 0.88698\n",
            "16/16 [==============================] - 6s 361ms/step - loss: 0.9495 - acc: 0.5664 - val_loss: 0.9434 - val_acc: 0.5514\n",
            "Epoch 99/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9411 - acc: 0.5735Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9713 - acc: 0.5391\n",
            "Epoch 00099: val_loss did not improve from 0.88698\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 0.9379 - acc: 0.5753 - val_loss: 0.9060 - val_acc: 0.5495\n",
            "Epoch 100/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9825 - acc: 0.5687Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9601 - acc: 0.5410\n",
            "Epoch 00100: val_loss did not improve from 0.88698\n",
            "16/16 [==============================] - 6s 361ms/step - loss: 0.9834 - acc: 0.5663 - val_loss: 0.9008 - val_acc: 0.5495\n",
            "Epoch 101/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9069 - acc: 0.5973Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9092 - acc: 0.5762\n",
            "Epoch 00101: val_loss improved from 0.88698 to 0.85513, saving model to model_2_4cl_best.h5\n",
            "16/16 [==============================] - 6s 347ms/step - loss: 0.9120 - acc: 0.5946 - val_loss: 0.8551 - val_acc: 0.5832\n",
            "Epoch 102/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9476 - acc: 0.5645Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9409 - acc: 0.5293\n",
            "Epoch 00102: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 349ms/step - loss: 0.9441 - acc: 0.5698 - val_loss: 0.8782 - val_acc: 0.5402\n",
            "Epoch 103/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9366 - acc: 0.5703Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.9203 - acc: 0.5977\n",
            "Epoch 00103: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 0.9357 - acc: 0.5713 - val_loss: 0.9063 - val_acc: 0.5963\n",
            "Epoch 104/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9618 - acc: 0.5660Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.9350 - acc: 0.5566\n",
            "Epoch 00104: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 0.9529 - acc: 0.5703 - val_loss: 0.9347 - val_acc: 0.5514\n",
            "Epoch 105/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9569 - acc: 0.5714Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.9456 - acc: 0.5625\n",
            "Epoch 00105: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 363ms/step - loss: 0.9580 - acc: 0.5698 - val_loss: 0.9614 - val_acc: 0.5589\n",
            "Epoch 106/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9095 - acc: 0.5995Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.1258 - acc: 0.4473\n",
            "Epoch 00106: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 360ms/step - loss: 0.9201 - acc: 0.5930 - val_loss: 1.1497 - val_acc: 0.4486\n",
            "Epoch 107/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9659 - acc: 0.5745Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9089 - acc: 0.5898\n",
            "Epoch 00107: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 374ms/step - loss: 0.9649 - acc: 0.5802 - val_loss: 0.9290 - val_acc: 0.5850\n",
            "Epoch 108/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9373 - acc: 0.5735Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9042 - acc: 0.5723\n",
            "Epoch 00108: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 370ms/step - loss: 0.9337 - acc: 0.5723 - val_loss: 0.9093 - val_acc: 0.5701\n",
            "Epoch 109/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9339 - acc: 0.5771Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9281 - acc: 0.5684\n",
            "Epoch 00109: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 363ms/step - loss: 0.9316 - acc: 0.5812 - val_loss: 0.9491 - val_acc: 0.5645\n",
            "Epoch 110/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9327 - acc: 0.5798Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9202 - acc: 0.5645\n",
            "Epoch 00110: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 367ms/step - loss: 0.9342 - acc: 0.5827 - val_loss: 0.9551 - val_acc: 0.5626\n",
            "Epoch 111/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9200 - acc: 0.5920Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0133 - acc: 0.5430\n",
            "Epoch 00111: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 368ms/step - loss: 0.9220 - acc: 0.5867 - val_loss: 1.0497 - val_acc: 0.5402\n",
            "Epoch 112/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9593 - acc: 0.5818Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9501 - acc: 0.5762\n",
            "Epoch 00112: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 369ms/step - loss: 0.9573 - acc: 0.5815 - val_loss: 0.9340 - val_acc: 0.5757\n",
            "Epoch 113/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9230 - acc: 0.5846Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9029 - acc: 0.5918\n",
            "Epoch 00113: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 0.9246 - acc: 0.5827 - val_loss: 0.8868 - val_acc: 0.5944\n",
            "Epoch 114/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9337 - acc: 0.5767Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9403 - acc: 0.5586\n",
            "Epoch 00114: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 362ms/step - loss: 0.9338 - acc: 0.5792 - val_loss: 0.9169 - val_acc: 0.5589\n",
            "Epoch 115/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9315 - acc: 0.5795Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9466 - acc: 0.5605\n",
            "Epoch 00115: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 352ms/step - loss: 0.9319 - acc: 0.5809 - val_loss: 0.9321 - val_acc: 0.5607\n",
            "Epoch 116/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9410 - acc: 0.5703Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9246 - acc: 0.5762\n",
            "Epoch 00116: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 359ms/step - loss: 0.9351 - acc: 0.5752 - val_loss: 0.8986 - val_acc: 0.5757\n",
            "Epoch 117/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9240 - acc: 0.6080Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9727 - acc: 0.5625\n",
            "Epoch 00117: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 352ms/step - loss: 0.9259 - acc: 0.6036 - val_loss: 0.9456 - val_acc: 0.5570\n",
            "Epoch 118/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9441 - acc: 0.5873Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9186 - acc: 0.5566\n",
            "Epoch 00118: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 353ms/step - loss: 0.9418 - acc: 0.5877 - val_loss: 0.8904 - val_acc: 0.5589\n",
            "Epoch 119/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9113 - acc: 0.5830Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9137 - acc: 0.5957\n",
            "Epoch 00119: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 348ms/step - loss: 0.9106 - acc: 0.5827 - val_loss: 0.8922 - val_acc: 0.5944\n",
            "Epoch 120/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9112 - acc: 0.5905Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.9255 - acc: 0.5840\n",
            "Epoch 00120: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 0.9075 - acc: 0.5882 - val_loss: 0.9013 - val_acc: 0.5850\n",
            "Epoch 121/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9217 - acc: 0.5889Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.9297 - acc: 0.5742\n",
            "Epoch 00121: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 356ms/step - loss: 0.9207 - acc: 0.5912 - val_loss: 0.9009 - val_acc: 0.5776\n",
            "Epoch 122/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9477 - acc: 0.5692Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8867 - acc: 0.5840\n",
            "Epoch 00122: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 362ms/step - loss: 0.9443 - acc: 0.5688 - val_loss: 0.9276 - val_acc: 0.5869\n",
            "Epoch 123/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8949 - acc: 0.6083Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9446 - acc: 0.5566\n",
            "Epoch 00123: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 371ms/step - loss: 0.8961 - acc: 0.6084 - val_loss: 0.9852 - val_acc: 0.5570\n",
            "Epoch 124/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9343 - acc: 0.5751Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9422 - acc: 0.5605\n",
            "Epoch 00124: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 375ms/step - loss: 0.9312 - acc: 0.5784 - val_loss: 0.9016 - val_acc: 0.5570\n",
            "Epoch 125/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8854 - acc: 0.6010Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9658 - acc: 0.5664\n",
            "Epoch 00125: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 376ms/step - loss: 0.8822 - acc: 0.6001 - val_loss: 0.9220 - val_acc: 0.5664\n",
            "Epoch 126/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9716 - acc: 0.5682Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9191 - acc: 0.5664\n",
            "Epoch 00126: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 373ms/step - loss: 0.9652 - acc: 0.5718 - val_loss: 0.8859 - val_acc: 0.5701\n",
            "Epoch 127/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9124 - acc: 0.5952Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9635 - acc: 0.5762\n",
            "Epoch 00127: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 368ms/step - loss: 0.9136 - acc: 0.5917 - val_loss: 0.9320 - val_acc: 0.5794\n",
            "Epoch 128/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9240 - acc: 0.5822Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9970 - acc: 0.5488\n",
            "Epoch 00128: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 372ms/step - loss: 0.9173 - acc: 0.5829 - val_loss: 1.0231 - val_acc: 0.5458\n",
            "Epoch 129/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8941 - acc: 0.6062Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8994 - acc: 0.5840\n",
            "Epoch 00129: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 368ms/step - loss: 0.9004 - acc: 0.6045 - val_loss: 0.9216 - val_acc: 0.5813\n",
            "Epoch 130/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9071 - acc: 0.5978Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9094 - acc: 0.5801\n",
            "Epoch 00130: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 349ms/step - loss: 0.9093 - acc: 0.5945 - val_loss: 0.9375 - val_acc: 0.5738\n",
            "Epoch 131/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8727 - acc: 0.6141Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9488 - acc: 0.5723\n",
            "Epoch 00131: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 364ms/step - loss: 0.8679 - acc: 0.6157 - val_loss: 0.9689 - val_acc: 0.5664\n",
            "Epoch 132/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9372 - acc: 0.5768Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8916 - acc: 0.5996\n",
            "Epoch 00132: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 353ms/step - loss: 0.9284 - acc: 0.5814 - val_loss: 0.9149 - val_acc: 0.5925\n",
            "Epoch 133/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9070 - acc: 0.5938Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9191 - acc: 0.5723\n",
            "Epoch 00133: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 0.9139 - acc: 0.5913 - val_loss: 0.9372 - val_acc: 0.5645\n",
            "Epoch 134/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8882 - acc: 0.5862Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8601 - acc: 0.5840\n",
            "Epoch 00134: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 356ms/step - loss: 0.8905 - acc: 0.5867 - val_loss: 0.8648 - val_acc: 0.5869\n",
            "Epoch 135/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9027 - acc: 0.5846Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9121 - acc: 0.5977\n",
            "Epoch 00135: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 352ms/step - loss: 0.9010 - acc: 0.5867 - val_loss: 0.9207 - val_acc: 0.5981\n",
            "Epoch 136/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9113 - acc: 0.5920Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8771 - acc: 0.5801\n",
            "Epoch 00136: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 5s 341ms/step - loss: 0.9091 - acc: 0.5877 - val_loss: 0.8851 - val_acc: 0.5850\n",
            "Epoch 137/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9275 - acc: 0.5830Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.8879 - acc: 0.5918\n",
            "Epoch 00137: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 0.9252 - acc: 0.5862 - val_loss: 0.8905 - val_acc: 0.5944\n",
            "Epoch 138/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9002 - acc: 0.6016Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8993 - acc: 0.5898\n",
            "Epoch 00138: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 352ms/step - loss: 0.8965 - acc: 0.6046 - val_loss: 0.9030 - val_acc: 0.5925\n",
            "Epoch 139/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9017 - acc: 0.5889Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.9138 - acc: 0.5801\n",
            "Epoch 00139: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 363ms/step - loss: 0.9043 - acc: 0.5867 - val_loss: 0.8915 - val_acc: 0.5832\n",
            "Epoch 140/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9062 - acc: 0.5969Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9154 - acc: 0.5801\n",
            "Epoch 00140: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 368ms/step - loss: 0.9020 - acc: 0.6001 - val_loss: 0.9103 - val_acc: 0.5757\n",
            "Epoch 141/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8929 - acc: 0.5989Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9054 - acc: 0.5762\n",
            "Epoch 00141: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 375ms/step - loss: 0.8963 - acc: 0.5981 - val_loss: 0.9188 - val_acc: 0.5738\n",
            "Epoch 142/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9051 - acc: 0.5930Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9270 - acc: 0.5840\n",
            "Epoch 00142: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 373ms/step - loss: 0.9123 - acc: 0.5925 - val_loss: 0.9537 - val_acc: 0.5832\n",
            "Epoch 143/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8714 - acc: 0.6026Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8701 - acc: 0.5879\n",
            "Epoch 00143: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 367ms/step - loss: 0.8740 - acc: 0.6050 - val_loss: 0.9450 - val_acc: 0.5832\n",
            "Epoch 144/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8914 - acc: 0.6074Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8989 - acc: 0.5938\n",
            "Epoch 00144: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 366ms/step - loss: 0.8927 - acc: 0.6056 - val_loss: 0.8830 - val_acc: 0.5925\n",
            "Epoch 145/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8945 - acc: 0.5878Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8890 - acc: 0.5957\n",
            "Epoch 00145: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 367ms/step - loss: 0.8957 - acc: 0.5912 - val_loss: 0.8702 - val_acc: 0.5963\n",
            "Epoch 146/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8968 - acc: 0.5979Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8956 - acc: 0.5859\n",
            "Epoch 00146: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 0.8971 - acc: 0.5931 - val_loss: 0.8984 - val_acc: 0.5944\n",
            "Epoch 147/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8778 - acc: 0.6076Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8942 - acc: 0.5645\n",
            "Epoch 00147: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 357ms/step - loss: 0.8752 - acc: 0.6072 - val_loss: 0.9031 - val_acc: 0.5664\n",
            "Epoch 148/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9161 - acc: 0.5911Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9404 - acc: 0.5566\n",
            "Epoch 00148: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 356ms/step - loss: 0.9159 - acc: 0.5913 - val_loss: 0.9309 - val_acc: 0.5607\n",
            "Epoch 149/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8890 - acc: 0.5793Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8690 - acc: 0.5918\n",
            "Epoch 00149: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 362ms/step - loss: 0.8824 - acc: 0.5837 - val_loss: 0.8812 - val_acc: 0.5944\n",
            "Epoch 150/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8994 - acc: 0.5952Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9444 - acc: 0.5840\n",
            "Epoch 00150: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 349ms/step - loss: 0.9037 - acc: 0.5930 - val_loss: 0.9469 - val_acc: 0.5832\n",
            "Epoch 151/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8888 - acc: 0.6047Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9522 - acc: 0.5723\n",
            "Epoch 00151: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 357ms/step - loss: 0.8935 - acc: 0.6050 - val_loss: 0.9784 - val_acc: 0.5682\n",
            "Epoch 152/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9130 - acc: 0.5777Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8929 - acc: 0.5898\n",
            "Epoch 00152: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 352ms/step - loss: 0.9110 - acc: 0.5753 - val_loss: 0.8989 - val_acc: 0.5944\n",
            "Epoch 153/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8738 - acc: 0.6117Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8978 - acc: 0.5781\n",
            "Epoch 00153: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 348ms/step - loss: 0.8688 - acc: 0.6115 - val_loss: 0.9112 - val_acc: 0.5757\n",
            "Epoch 154/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8843 - acc: 0.5883Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.8798 - acc: 0.5801\n",
            "Epoch 00154: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 0.8837 - acc: 0.5872 - val_loss: 0.8960 - val_acc: 0.5794\n",
            "Epoch 155/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8747 - acc: 0.6064Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8769 - acc: 0.5801\n",
            "Epoch 00155: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 348ms/step - loss: 0.8752 - acc: 0.6031 - val_loss: 0.8682 - val_acc: 0.5776\n",
            "Epoch 156/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8665 - acc: 0.6053Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8835 - acc: 0.6055\n",
            "Epoch 00156: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 364ms/step - loss: 0.8696 - acc: 0.5991 - val_loss: 0.8630 - val_acc: 0.6075\n",
            "Epoch 157/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8957 - acc: 0.5873Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9340 - acc: 0.5625\n",
            "Epoch 00157: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 371ms/step - loss: 0.9037 - acc: 0.5837 - val_loss: 0.9076 - val_acc: 0.5607\n",
            "Epoch 158/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8993 - acc: 0.5807Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8909 - acc: 0.6016\n",
            "Epoch 00158: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 384ms/step - loss: 0.8951 - acc: 0.5835 - val_loss: 0.8875 - val_acc: 0.6056\n",
            "Epoch 159/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8891 - acc: 0.5963Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9037 - acc: 0.6074\n",
            "Epoch 00159: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 373ms/step - loss: 0.8858 - acc: 0.5966 - val_loss: 0.8728 - val_acc: 0.6150\n",
            "Epoch 160/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8998 - acc: 0.6032Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9257 - acc: 0.5664\n",
            "Epoch 00160: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 367ms/step - loss: 0.9029 - acc: 0.6016 - val_loss: 0.9122 - val_acc: 0.5701\n",
            "Epoch 161/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8874 - acc: 0.6011Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8977 - acc: 0.5879\n",
            "Epoch 00161: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 368ms/step - loss: 0.8845 - acc: 0.6041 - val_loss: 0.8768 - val_acc: 0.5981\n",
            "Epoch 162/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8752 - acc: 0.6089Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9255 - acc: 0.5488\n",
            "Epoch 00162: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 364ms/step - loss: 0.8823 - acc: 0.6090 - val_loss: 0.9220 - val_acc: 0.5551\n",
            "Epoch 163/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9110 - acc: 0.5760Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9221 - acc: 0.5566\n",
            "Epoch 00163: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 366ms/step - loss: 0.9065 - acc: 0.5771 - val_loss: 0.9103 - val_acc: 0.5626\n",
            "Epoch 164/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8794 - acc: 0.6085Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8820 - acc: 0.5820\n",
            "Epoch 00164: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 363ms/step - loss: 0.8791 - acc: 0.6100 - val_loss: 0.8662 - val_acc: 0.5888\n",
            "Epoch 165/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9102 - acc: 0.5854Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9043 - acc: 0.5723\n",
            "Epoch 00165: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 356ms/step - loss: 0.9077 - acc: 0.5854 - val_loss: 0.8776 - val_acc: 0.5832\n",
            "Epoch 166/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8704 - acc: 0.6149Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8853 - acc: 0.6133\n",
            "Epoch 00166: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 357ms/step - loss: 0.8663 - acc: 0.6120 - val_loss: 0.8663 - val_acc: 0.6206\n",
            "Epoch 167/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8757 - acc: 0.6010Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8813 - acc: 0.5840\n",
            "Epoch 00167: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 357ms/step - loss: 0.8773 - acc: 0.6021 - val_loss: 0.8588 - val_acc: 0.5925\n",
            "Epoch 168/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8678 - acc: 0.6074Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8867 - acc: 0.5840\n",
            "Epoch 00168: val_loss did not improve from 0.85513\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 0.8641 - acc: 0.6095 - val_loss: 0.8648 - val_acc: 0.5925\n",
            "Epoch 169/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8906 - acc: 0.5873Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8819 - acc: 0.5820\n",
            "Epoch 00169: val_loss improved from 0.85513 to 0.85158, saving model to model_2_4cl_best.h5\n",
            "16/16 [==============================] - 6s 357ms/step - loss: 0.8897 - acc: 0.5872 - val_loss: 0.8516 - val_acc: 0.5888\n",
            "Epoch 170/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8846 - acc: 0.5973Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8980 - acc: 0.5762\n",
            "Epoch 00170: val_loss did not improve from 0.85158\n",
            "16/16 [==============================] - 6s 346ms/step - loss: 0.8862 - acc: 0.5976 - val_loss: 0.8636 - val_acc: 0.5869\n",
            "Epoch 171/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8690 - acc: 0.5920Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.9133 - acc: 0.5703\n",
            "Epoch 00171: val_loss did not improve from 0.85158\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 0.8733 - acc: 0.5867 - val_loss: 0.8790 - val_acc: 0.5813\n",
            "Epoch 172/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8760 - acc: 0.5926Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8848 - acc: 0.5625\n",
            "Epoch 00172: val_loss did not improve from 0.85158\n",
            "16/16 [==============================] - 6s 348ms/step - loss: 0.8720 - acc: 0.5951 - val_loss: 0.8547 - val_acc: 0.5720\n",
            "Epoch 173/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8815 - acc: 0.6080Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.9071 - acc: 0.5840\n",
            "Epoch 00173: val_loss did not improve from 0.85158\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 0.8835 - acc: 0.6090 - val_loss: 0.8894 - val_acc: 0.5907\n",
            "Epoch 174/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8667 - acc: 0.6053Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9244 - acc: 0.5762\n",
            "Epoch 00174: val_loss did not improve from 0.85158\n",
            "16/16 [==============================] - 6s 373ms/step - loss: 0.8686 - acc: 0.6066 - val_loss: 0.9013 - val_acc: 0.5832\n",
            "Epoch 175/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8660 - acc: 0.6111Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8902 - acc: 0.5762\n",
            "Epoch 00175: val_loss did not improve from 0.85158\n",
            "16/16 [==============================] - 6s 373ms/step - loss: 0.8663 - acc: 0.6120 - val_loss: 0.8935 - val_acc: 0.5776\n",
            "Epoch 176/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8509 - acc: 0.6164Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0048 - acc: 0.5820\n",
            "Epoch 00176: val_loss did not improve from 0.85158\n",
            "16/16 [==============================] - 6s 370ms/step - loss: 0.8482 - acc: 0.6205 - val_loss: 1.0037 - val_acc: 0.5813\n",
            "Epoch 177/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8765 - acc: 0.5891Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8597 - acc: 0.6172\n",
            "Epoch 00177: val_loss did not improve from 0.85158\n",
            "16/16 [==============================] - 6s 374ms/step - loss: 0.8781 - acc: 0.5913 - val_loss: 0.8757 - val_acc: 0.6187\n",
            "Epoch 178/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8601 - acc: 0.6254Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8931 - acc: 0.6152\n",
            "Epoch 00178: val_loss did not improve from 0.85158\n",
            "16/16 [==============================] - 6s 362ms/step - loss: 0.8609 - acc: 0.6234 - val_loss: 0.9010 - val_acc: 0.6187\n",
            "Epoch 179/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8665 - acc: 0.5927Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 3s - loss: 0.8924 - acc: 0.5813\n",
            "Epoch 00179: val_loss did not improve from 0.85158\n",
            "16/16 [==============================] - 6s 379ms/step - loss: 0.8627 - acc: 0.5962 - val_loss: 0.8924 - val_acc: 0.5813\n",
            "Epoch 180/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8415 - acc: 0.6281Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.1071 - acc: 0.5215\n",
            "Epoch 00180: val_loss did not improve from 0.85158\n",
            "16/16 [==============================] - 6s 360ms/step - loss: 0.8492 - acc: 0.6254 - val_loss: 1.0971 - val_acc: 0.5234\n",
            "Epoch 181/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8743 - acc: 0.6047Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8929 - acc: 0.6113\n",
            "Epoch 00181: val_loss did not improve from 0.85158\n",
            "16/16 [==============================] - 6s 364ms/step - loss: 0.8858 - acc: 0.5986 - val_loss: 0.8926 - val_acc: 0.6131\n",
            "Epoch 182/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8671 - acc: 0.6101Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8900 - acc: 0.5879\n",
            "Epoch 00182: val_loss did not improve from 0.85158\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 0.8618 - acc: 0.6076 - val_loss: 0.8814 - val_acc: 0.5888\n",
            "Epoch 183/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8963 - acc: 0.5942Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9046 - acc: 0.5840\n",
            "Epoch 00183: val_loss did not improve from 0.85158\n",
            "16/16 [==============================] - 6s 361ms/step - loss: 0.8912 - acc: 0.5976 - val_loss: 0.8998 - val_acc: 0.5794\n",
            "Epoch 184/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8578 - acc: 0.6117Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8699 - acc: 0.6074\n",
            "Epoch 00184: val_loss did not improve from 0.85158\n",
            "16/16 [==============================] - 6s 351ms/step - loss: 0.8530 - acc: 0.6115 - val_loss: 0.8892 - val_acc: 0.5981\n",
            "Epoch 185/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8638 - acc: 0.6064Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8754 - acc: 0.6230\n",
            "Epoch 00185: val_loss did not improve from 0.85158\n",
            "16/16 [==============================] - 6s 353ms/step - loss: 0.8692 - acc: 0.6016 - val_loss: 0.9161 - val_acc: 0.6150\n",
            "Epoch 186/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8462 - acc: 0.6265Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9177 - acc: 0.5703\n",
            "Epoch 00186: val_loss did not improve from 0.85158\n",
            "16/16 [==============================] - 6s 349ms/step - loss: 0.8505 - acc: 0.6269 - val_loss: 0.9349 - val_acc: 0.5645\n",
            "Epoch 187/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8719 - acc: 0.6042Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8911 - acc: 0.5820\n",
            "Epoch 00187: val_loss did not improve from 0.85158\n",
            "16/16 [==============================] - 6s 346ms/step - loss: 0.8696 - acc: 0.6036 - val_loss: 0.9342 - val_acc: 0.5757\n",
            "Epoch 188/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8609 - acc: 0.6228Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.8726 - acc: 0.5996\n",
            "Epoch 00188: val_loss did not improve from 0.85158\n",
            "16/16 [==============================] - 5s 302ms/step - loss: 0.8605 - acc: 0.6249 - val_loss: 0.9316 - val_acc: 0.5888\n",
            "Epoch 189/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8588 - acc: 0.6133Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8756 - acc: 0.5957\n",
            "Epoch 00189: val_loss did not improve from 0.85158\n",
            "16/16 [==============================] - 6s 353ms/step - loss: 0.8545 - acc: 0.6190 - val_loss: 0.9286 - val_acc: 0.5907\n",
            "Epoch 190/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8507 - acc: 0.6106Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8684 - acc: 0.5938\n",
            "Epoch 00190: val_loss did not improve from 0.85158\n",
            "16/16 [==============================] - 6s 359ms/step - loss: 0.8513 - acc: 0.6110 - val_loss: 0.8970 - val_acc: 0.5888\n",
            "Epoch 191/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8561 - acc: 0.6143Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8540 - acc: 0.6016\n",
            "Epoch 00191: val_loss did not improve from 0.85158\n",
            "16/16 [==============================] - 6s 368ms/step - loss: 0.8556 - acc: 0.6120 - val_loss: 0.8742 - val_acc: 0.5944\n",
            "Epoch 192/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8463 - acc: 0.6180Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9488 - acc: 0.5801\n",
            "Epoch 00192: val_loss did not improve from 0.85158\n",
            "16/16 [==============================] - 6s 366ms/step - loss: 0.8484 - acc: 0.6150 - val_loss: 1.0118 - val_acc: 0.5701\n",
            "Epoch 193/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8496 - acc: 0.6180Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8625 - acc: 0.5801\n",
            "Epoch 00193: val_loss did not improve from 0.85158\n",
            "16/16 [==============================] - 6s 372ms/step - loss: 0.8529 - acc: 0.6160 - val_loss: 0.9433 - val_acc: 0.5738\n",
            "Epoch 194/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8801 - acc: 0.6052Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8793 - acc: 0.6113\n",
            "Epoch 00194: val_loss did not improve from 0.85158\n",
            "16/16 [==============================] - 6s 384ms/step - loss: 0.8837 - acc: 0.6021 - val_loss: 0.9066 - val_acc: 0.6037\n",
            "Epoch 195/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8483 - acc: 0.6164Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8621 - acc: 0.6270\n",
            "Epoch 00195: val_loss did not improve from 0.85158\n",
            "16/16 [==============================] - 6s 365ms/step - loss: 0.8534 - acc: 0.6155 - val_loss: 0.8803 - val_acc: 0.6262\n",
            "Epoch 196/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8514 - acc: 0.6196Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8705 - acc: 0.5938\n",
            "Epoch 00196: val_loss improved from 0.85158 to 0.83236, saving model to model_2_4cl_best.h5\n",
            "16/16 [==============================] - 6s 378ms/step - loss: 0.8490 - acc: 0.6200 - val_loss: 0.8324 - val_acc: 0.5963\n",
            "Epoch 197/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8642 - acc: 0.5973Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0502 - acc: 0.5254\n",
            "Epoch 00197: val_loss did not improve from 0.83236\n",
            "16/16 [==============================] - 6s 363ms/step - loss: 0.8693 - acc: 0.5976 - val_loss: 1.0264 - val_acc: 0.5290\n",
            "Epoch 198/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8461 - acc: 0.6255Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8612 - acc: 0.5957\n",
            "Epoch 00198: val_loss did not improve from 0.83236\n",
            "16/16 [==============================] - 6s 363ms/step - loss: 0.8534 - acc: 0.6225 - val_loss: 0.8373 - val_acc: 0.5963\n",
            "Epoch 199/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8246 - acc: 0.6276Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8778 - acc: 0.6094\n",
            "Epoch 00199: val_loss did not improve from 0.83236\n",
            "16/16 [==============================] - 6s 371ms/step - loss: 0.8324 - acc: 0.6255 - val_loss: 0.9315 - val_acc: 0.6037\n",
            "Epoch 200/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8667 - acc: 0.6038Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8727 - acc: 0.5938\n",
            "Epoch 00200: val_loss did not improve from 0.83236\n",
            "16/16 [==============================] - 6s 349ms/step - loss: 0.8667 - acc: 0.6036 - val_loss: 0.9304 - val_acc: 0.5907\n",
            "Epoch 201/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8561 - acc: 0.6068Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8645 - acc: 0.5918\n",
            "Epoch 00201: val_loss did not improve from 0.83236\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 0.8524 - acc: 0.6069 - val_loss: 0.9684 - val_acc: 0.5869\n",
            "Epoch 202/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8372 - acc: 0.6361Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8640 - acc: 0.5859\n",
            "Epoch 00202: val_loss did not improve from 0.83236\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 0.8384 - acc: 0.6339 - val_loss: 0.8659 - val_acc: 0.5869\n",
            "Epoch 203/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8598 - acc: 0.6042Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8762 - acc: 0.5820\n",
            "Epoch 00203: val_loss did not improve from 0.83236\n",
            "16/16 [==============================] - 6s 351ms/step - loss: 0.8562 - acc: 0.6076 - val_loss: 0.8912 - val_acc: 0.5850\n",
            "Epoch 204/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8448 - acc: 0.6177Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8492 - acc: 0.5957\n",
            "Epoch 00204: val_loss did not improve from 0.83236\n",
            "16/16 [==============================] - 6s 347ms/step - loss: 0.8443 - acc: 0.6180 - val_loss: 0.8722 - val_acc: 0.5888\n",
            "Epoch 205/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8553 - acc: 0.6037Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.8646 - acc: 0.5918\n",
            "Epoch 00205: val_loss did not improve from 0.83236\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 0.8606 - acc: 0.6006 - val_loss: 0.8347 - val_acc: 0.5963\n",
            "Epoch 206/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8430 - acc: 0.6202Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.9033 - acc: 0.5938\n",
            "Epoch 00206: val_loss did not improve from 0.83236\n",
            "16/16 [==============================] - 6s 346ms/step - loss: 0.8386 - acc: 0.6180 - val_loss: 0.8696 - val_acc: 0.6000\n",
            "Epoch 207/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8536 - acc: 0.6233Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8568 - acc: 0.5781\n",
            "Epoch 00207: val_loss improved from 0.83236 to 0.82464, saving model to model_2_4cl_best.h5\n",
            "16/16 [==============================] - 6s 366ms/step - loss: 0.8489 - acc: 0.6225 - val_loss: 0.8246 - val_acc: 0.5850\n",
            "Epoch 208/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8686 - acc: 0.6117Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8705 - acc: 0.5801\n",
            "Epoch 00208: val_loss did not improve from 0.82464\n",
            "16/16 [==============================] - 6s 370ms/step - loss: 0.8651 - acc: 0.6130 - val_loss: 0.8322 - val_acc: 0.5869\n",
            "Epoch 209/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8364 - acc: 0.6111Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8820 - acc: 0.5938\n",
            "Epoch 00209: val_loss did not improve from 0.82464\n",
            "16/16 [==============================] - 6s 374ms/step - loss: 0.8431 - acc: 0.6085 - val_loss: 0.8892 - val_acc: 0.5907\n",
            "Epoch 210/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8482 - acc: 0.6302Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8607 - acc: 0.5938\n",
            "Epoch 00210: val_loss did not improve from 0.82464\n",
            "16/16 [==============================] - 6s 370ms/step - loss: 0.8496 - acc: 0.6274 - val_loss: 0.8584 - val_acc: 0.5850\n",
            "Epoch 211/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8430 - acc: 0.6104Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8634 - acc: 0.6035\n",
            "Epoch 00211: val_loss did not improve from 0.82464\n",
            "16/16 [==============================] - 6s 374ms/step - loss: 0.8419 - acc: 0.6105 - val_loss: 0.8630 - val_acc: 0.5963\n",
            "Epoch 212/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8650 - acc: 0.6053Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8711 - acc: 0.5957\n",
            "Epoch 00212: val_loss did not improve from 0.82464\n",
            "16/16 [==============================] - 6s 377ms/step - loss: 0.8664 - acc: 0.6021 - val_loss: 0.8785 - val_acc: 0.5888\n",
            "Epoch 213/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8204 - acc: 0.6286Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8824 - acc: 0.5957\n",
            "Epoch 00213: val_loss did not improve from 0.82464\n",
            "16/16 [==============================] - 6s 372ms/step - loss: 0.8175 - acc: 0.6284 - val_loss: 0.8928 - val_acc: 0.5944\n",
            "Epoch 214/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8510 - acc: 0.6157Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8725 - acc: 0.5879\n",
            "Epoch 00214: val_loss did not improve from 0.82464\n",
            "16/16 [==============================] - 6s 359ms/step - loss: 0.8481 - acc: 0.6173 - val_loss: 0.8870 - val_acc: 0.5850\n",
            "Epoch 215/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8301 - acc: 0.6109Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8769 - acc: 0.5977\n",
            "Epoch 00215: val_loss did not improve from 0.82464\n",
            "16/16 [==============================] - 6s 364ms/step - loss: 0.8311 - acc: 0.6099 - val_loss: 0.8771 - val_acc: 0.5944\n",
            "Epoch 216/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8437 - acc: 0.6223Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8822 - acc: 0.5840\n",
            "Epoch 00216: val_loss did not improve from 0.82464\n",
            "16/16 [==============================] - 6s 353ms/step - loss: 0.8420 - acc: 0.6190 - val_loss: 0.8762 - val_acc: 0.5832\n",
            "Epoch 217/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8564 - acc: 0.6133Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8796 - acc: 0.5840\n",
            "Epoch 00217: val_loss did not improve from 0.82464\n",
            "16/16 [==============================] - 6s 359ms/step - loss: 0.8500 - acc: 0.6205 - val_loss: 0.9118 - val_acc: 0.5794\n",
            "Epoch 218/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8600 - acc: 0.6164Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9019 - acc: 0.5918\n",
            "Epoch 00218: val_loss did not improve from 0.82464\n",
            "16/16 [==============================] - 6s 356ms/step - loss: 0.8614 - acc: 0.6145 - val_loss: 0.9184 - val_acc: 0.5869\n",
            "Epoch 219/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8358 - acc: 0.6350Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8681 - acc: 0.5859\n",
            "Epoch 00219: val_loss did not improve from 0.82464\n",
            "16/16 [==============================] - 6s 348ms/step - loss: 0.8356 - acc: 0.6344 - val_loss: 0.8763 - val_acc: 0.5832\n",
            "Epoch 220/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8399 - acc: 0.6011Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8935 - acc: 0.5703\n",
            "Epoch 00220: val_loss did not improve from 0.82464\n",
            "16/16 [==============================] - 6s 352ms/step - loss: 0.8444 - acc: 0.6001 - val_loss: 0.9114 - val_acc: 0.5682\n",
            "Epoch 221/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8332 - acc: 0.6249Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8573 - acc: 0.5996\n",
            "Epoch 00221: val_loss did not improve from 0.82464\n",
            "16/16 [==============================] - 6s 347ms/step - loss: 0.8334 - acc: 0.6234 - val_loss: 0.8755 - val_acc: 0.5944\n",
            "Epoch 222/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8360 - acc: 0.6191Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.8909 - acc: 0.6016\n",
            "Epoch 00222: val_loss did not improve from 0.82464\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 0.8348 - acc: 0.6264 - val_loss: 0.8856 - val_acc: 0.6000\n",
            "Epoch 223/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8388 - acc: 0.6175Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8657 - acc: 0.6211\n",
            "Epoch 00223: val_loss did not improve from 0.82464\n",
            "16/16 [==============================] - 6s 352ms/step - loss: 0.8388 - acc: 0.6150 - val_loss: 0.8564 - val_acc: 0.6187\n",
            "Epoch 224/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8404 - acc: 0.6223Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8676 - acc: 0.5879\n",
            "Epoch 00224: val_loss did not improve from 0.82464\n",
            "16/16 [==============================] - 6s 352ms/step - loss: 0.8360 - acc: 0.6230 - val_loss: 0.8563 - val_acc: 0.5888\n",
            "Epoch 225/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8527 - acc: 0.6064Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8557 - acc: 0.6035\n",
            "Epoch 00225: val_loss did not improve from 0.82464\n",
            "16/16 [==============================] - 6s 374ms/step - loss: 0.8498 - acc: 0.6031 - val_loss: 0.8429 - val_acc: 0.6037\n",
            "Epoch 226/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8395 - acc: 0.6233Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8395 - acc: 0.6133\n",
            "Epoch 00226: val_loss did not improve from 0.82464\n",
            "16/16 [==============================] - 6s 379ms/step - loss: 0.8367 - acc: 0.6274 - val_loss: 0.8736 - val_acc: 0.6112\n",
            "Epoch 227/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8470 - acc: 0.6109Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8525 - acc: 0.5957\n",
            "Epoch 00227: val_loss did not improve from 0.82464\n",
            "16/16 [==============================] - 6s 377ms/step - loss: 0.8422 - acc: 0.6138 - val_loss: 0.8857 - val_acc: 0.5944\n",
            "Epoch 228/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8446 - acc: 0.6097Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9945 - acc: 0.5469\n",
            "Epoch 00228: val_loss did not improve from 0.82464\n",
            "16/16 [==============================] - 6s 359ms/step - loss: 0.8422 - acc: 0.6132 - val_loss: 1.0228 - val_acc: 0.5458\n",
            "Epoch 229/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8522 - acc: 0.6214Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8733 - acc: 0.5879\n",
            "Epoch 00229: val_loss did not improve from 0.82464\n",
            "16/16 [==============================] - 6s 370ms/step - loss: 0.8529 - acc: 0.6235 - val_loss: 0.8962 - val_acc: 0.5850\n",
            "Epoch 230/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8461 - acc: 0.6133Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8964 - acc: 0.5898\n",
            "Epoch 00230: val_loss did not improve from 0.82464\n",
            "16/16 [==============================] - 6s 368ms/step - loss: 0.8433 - acc: 0.6150 - val_loss: 0.9202 - val_acc: 0.5888\n",
            "Epoch 231/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8459 - acc: 0.6122Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8609 - acc: 0.5762\n",
            "Epoch 00231: val_loss did not improve from 0.82464\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 0.8479 - acc: 0.6120 - val_loss: 0.8919 - val_acc: 0.5738\n",
            "Epoch 232/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8099 - acc: 0.6303Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8710 - acc: 0.5957\n",
            "Epoch 00232: val_loss did not improve from 0.82464\n",
            "16/16 [==============================] - 6s 364ms/step - loss: 0.8099 - acc: 0.6299 - val_loss: 0.9481 - val_acc: 0.5888\n",
            "Epoch 233/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8474 - acc: 0.6292Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8589 - acc: 0.5898\n",
            "Epoch 00233: val_loss did not improve from 0.82464\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 0.8531 - acc: 0.6270 - val_loss: 0.8400 - val_acc: 0.5925\n",
            "Epoch 234/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8233 - acc: 0.6218Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8918 - acc: 0.5898\n",
            "Epoch 00234: val_loss did not improve from 0.82464\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 0.8202 - acc: 0.6200 - val_loss: 0.8590 - val_acc: 0.5963\n",
            "Epoch 235/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8315 - acc: 0.6324Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8961 - acc: 0.5918\n",
            "Epoch 00235: val_loss did not improve from 0.82464\n",
            "16/16 [==============================] - 6s 353ms/step - loss: 0.8299 - acc: 0.6314 - val_loss: 0.8648 - val_acc: 0.5981\n",
            "Epoch 236/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8347 - acc: 0.6208Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8757 - acc: 0.5898\n",
            "Epoch 00236: val_loss improved from 0.82464 to 0.82284, saving model to model_2_4cl_best.h5\n",
            "16/16 [==============================] - 6s 364ms/step - loss: 0.8330 - acc: 0.6221 - val_loss: 0.8228 - val_acc: 0.5963\n",
            "Epoch 237/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8254 - acc: 0.6223Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9178 - acc: 0.5820\n",
            "Epoch 00237: val_loss did not improve from 0.82284\n",
            "16/16 [==============================] - 6s 354ms/step - loss: 0.8277 - acc: 0.6210 - val_loss: 0.8622 - val_acc: 0.5907\n",
            "Epoch 238/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8315 - acc: 0.6271Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8800 - acc: 0.6016\n",
            "Epoch 00238: val_loss did not improve from 0.82284\n",
            "16/16 [==============================] - 6s 346ms/step - loss: 0.8293 - acc: 0.6319 - val_loss: 0.8423 - val_acc: 0.6075\n",
            "Epoch 239/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8402 - acc: 0.6164Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.8956 - acc: 0.5664\n",
            "Epoch 00239: val_loss did not improve from 0.82284\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 0.8338 - acc: 0.6190 - val_loss: 0.8651 - val_acc: 0.5720\n",
            "Epoch 240/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8245 - acc: 0.6308Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8527 - acc: 0.5879\n",
            "Epoch 00240: val_loss improved from 0.82284 to 0.81544, saving model to model_2_4cl_best.h5\n",
            "16/16 [==============================] - 6s 360ms/step - loss: 0.8293 - acc: 0.6269 - val_loss: 0.8154 - val_acc: 0.5963\n",
            "Epoch 241/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7906 - acc: 0.6424Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8475 - acc: 0.5918\n",
            "Epoch 00241: val_loss did not improve from 0.81544\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 0.7974 - acc: 0.6388 - val_loss: 0.8706 - val_acc: 0.5907\n",
            "Epoch 242/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8436 - acc: 0.6255Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8438 - acc: 0.6152\n",
            "Epoch 00242: val_loss did not improve from 0.81544\n",
            "16/16 [==============================] - 6s 361ms/step - loss: 0.8436 - acc: 0.6230 - val_loss: 0.8882 - val_acc: 0.6168\n",
            "Epoch 243/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8355 - acc: 0.6203Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9440 - acc: 0.5625\n",
            "Epoch 00243: val_loss did not improve from 0.81544\n",
            "16/16 [==============================] - 6s 384ms/step - loss: 0.8503 - acc: 0.6191 - val_loss: 0.9358 - val_acc: 0.5664\n",
            "Epoch 244/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8386 - acc: 0.6238Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8493 - acc: 0.6094\n",
            "Epoch 00244: val_loss did not improve from 0.81544\n",
            "16/16 [==============================] - 6s 368ms/step - loss: 0.8348 - acc: 0.6239 - val_loss: 0.8244 - val_acc: 0.6093\n",
            "Epoch 245/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8321 - acc: 0.6115Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8742 - acc: 0.6426\n",
            "Epoch 00245: val_loss did not improve from 0.81544\n",
            "16/16 [==============================] - 6s 375ms/step - loss: 0.8329 - acc: 0.6152 - val_loss: 0.8514 - val_acc: 0.6411\n",
            "Epoch 246/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7949 - acc: 0.6416Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8744 - acc: 0.5918\n",
            "Epoch 00246: val_loss did not improve from 0.81544\n",
            "16/16 [==============================] - 6s 362ms/step - loss: 0.7975 - acc: 0.6370 - val_loss: 0.8378 - val_acc: 0.5944\n",
            "Epoch 247/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8345 - acc: 0.6276Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8704 - acc: 0.6094\n",
            "Epoch 00247: val_loss did not improve from 0.81544\n",
            "16/16 [==============================] - 6s 364ms/step - loss: 0.8313 - acc: 0.6314 - val_loss: 0.8414 - val_acc: 0.6093\n",
            "Epoch 248/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8169 - acc: 0.6167Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8505 - acc: 0.5742\n",
            "Epoch 00248: val_loss did not improve from 0.81544\n",
            "16/16 [==============================] - 6s 368ms/step - loss: 0.8127 - acc: 0.6201 - val_loss: 0.8268 - val_acc: 0.5738\n",
            "Epoch 249/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8341 - acc: 0.6127Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9115 - acc: 0.5898\n",
            "Epoch 00249: val_loss did not improve from 0.81544\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 0.8283 - acc: 0.6140 - val_loss: 0.9203 - val_acc: 0.5850\n",
            "Epoch 250/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8629 - acc: 0.6186Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8426 - acc: 0.6035\n",
            "Epoch 00250: val_loss improved from 0.81544 to 0.81253, saving model to model_2_4cl_best.h5\n",
            "16/16 [==============================] - 6s 363ms/step - loss: 0.8608 - acc: 0.6200 - val_loss: 0.8125 - val_acc: 0.6056\n",
            "Epoch 251/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8297 - acc: 0.6223Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8513 - acc: 0.6133\n",
            "Epoch 00251: val_loss did not improve from 0.81253\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 0.8258 - acc: 0.6210 - val_loss: 0.8456 - val_acc: 0.6112\n",
            "Epoch 252/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8364 - acc: 0.6106Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8474 - acc: 0.5996\n",
            "Epoch 00252: val_loss did not improve from 0.81253\n",
            "16/16 [==============================] - 6s 357ms/step - loss: 0.8310 - acc: 0.6145 - val_loss: 0.8297 - val_acc: 0.6000\n",
            "Epoch 253/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8290 - acc: 0.6260Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9047 - acc: 0.6016\n",
            "Epoch 00253: val_loss did not improve from 0.81253\n",
            "16/16 [==============================] - 6s 354ms/step - loss: 0.8253 - acc: 0.6304 - val_loss: 0.8797 - val_acc: 0.6037\n",
            "Epoch 254/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8288 - acc: 0.6244Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8243 - acc: 0.6016\n",
            "Epoch 00254: val_loss did not improve from 0.81253\n",
            "16/16 [==============================] - 6s 360ms/step - loss: 0.8225 - acc: 0.6289 - val_loss: 0.8299 - val_acc: 0.6000\n",
            "Epoch 255/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8200 - acc: 0.6170Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8782 - acc: 0.6211\n",
            "Epoch 00255: val_loss did not improve from 0.81253\n",
            "16/16 [==============================] - 6s 345ms/step - loss: 0.8154 - acc: 0.6234 - val_loss: 0.8709 - val_acc: 0.6224\n",
            "Epoch 256/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8397 - acc: 0.6101Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.8727 - acc: 0.5938\n",
            "Epoch 00256: val_loss did not improve from 0.81253\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 0.8304 - acc: 0.6155 - val_loss: 0.8838 - val_acc: 0.5925\n",
            "Epoch 257/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8307 - acc: 0.6186Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8706 - acc: 0.5977\n",
            "Epoch 00257: val_loss did not improve from 0.81253\n",
            "16/16 [==============================] - 6s 349ms/step - loss: 0.8305 - acc: 0.6170 - val_loss: 0.8724 - val_acc: 0.5963\n",
            "Epoch 258/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8233 - acc: 0.6271Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8551 - acc: 0.5938\n",
            "Epoch 00258: val_loss did not improve from 0.81253\n",
            "16/16 [==============================] - 6s 362ms/step - loss: 0.8308 - acc: 0.6254 - val_loss: 0.8847 - val_acc: 0.5907\n",
            "Epoch 259/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8390 - acc: 0.6193Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8157 - acc: 0.6230\n",
            "Epoch 00259: val_loss did not improve from 0.81253\n",
            "16/16 [==============================] - 6s 366ms/step - loss: 0.8291 - acc: 0.6221 - val_loss: 0.8362 - val_acc: 0.6187\n",
            "Epoch 260/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8185 - acc: 0.6202Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8423 - acc: 0.6035\n",
            "Epoch 00260: val_loss did not improve from 0.81253\n",
            "16/16 [==============================] - 6s 369ms/step - loss: 0.8203 - acc: 0.6198 - val_loss: 0.8639 - val_acc: 0.5981\n",
            "Epoch 261/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8181 - acc: 0.6302Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8916 - acc: 0.5840\n",
            "Epoch 00261: val_loss did not improve from 0.81253\n",
            "16/16 [==============================] - 6s 364ms/step - loss: 0.8150 - acc: 0.6319 - val_loss: 0.9252 - val_acc: 0.5813\n",
            "Epoch 262/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8369 - acc: 0.6207Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8834 - acc: 0.5859\n",
            "Epoch 00262: val_loss did not improve from 0.81253\n",
            "16/16 [==============================] - 6s 371ms/step - loss: 0.8376 - acc: 0.6195 - val_loss: 0.9052 - val_acc: 0.5832\n",
            "Epoch 263/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8362 - acc: 0.6250Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8811 - acc: 0.6113\n",
            "Epoch 00263: val_loss did not improve from 0.81253\n",
            "16/16 [==============================] - 6s 368ms/step - loss: 0.8319 - acc: 0.6250 - val_loss: 0.8693 - val_acc: 0.6093\n",
            "Epoch 264/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8252 - acc: 0.6154Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9073 - acc: 0.5938\n",
            "Epoch 00264: val_loss did not improve from 0.81253\n",
            "16/16 [==============================] - 6s 365ms/step - loss: 0.8269 - acc: 0.6155 - val_loss: 0.9076 - val_acc: 0.5925\n",
            "Epoch 265/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8226 - acc: 0.6387Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8586 - acc: 0.6035\n",
            "Epoch 00265: val_loss did not improve from 0.81253\n",
            "16/16 [==============================] - 6s 360ms/step - loss: 0.8264 - acc: 0.6349 - val_loss: 0.8702 - val_acc: 0.5981\n",
            "Epoch 266/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8177 - acc: 0.6232Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8412 - acc: 0.6172\n",
            "Epoch 00266: val_loss did not improve from 0.81253\n",
            "16/16 [==============================] - 6s 349ms/step - loss: 0.8136 - acc: 0.6229 - val_loss: 0.8221 - val_acc: 0.6206\n",
            "Epoch 267/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8434 - acc: 0.6172Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8793 - acc: 0.5879\n",
            "Epoch 00267: val_loss did not improve from 0.81253\n",
            "16/16 [==============================] - 6s 361ms/step - loss: 0.8361 - acc: 0.6201 - val_loss: 0.8579 - val_acc: 0.5907\n",
            "Epoch 268/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8340 - acc: 0.6318Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8554 - acc: 0.6328\n",
            "Epoch 00268: val_loss did not improve from 0.81253\n",
            "16/16 [==============================] - 6s 357ms/step - loss: 0.8286 - acc: 0.6324 - val_loss: 0.8391 - val_acc: 0.6336\n",
            "Epoch 269/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8152 - acc: 0.6302Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8413 - acc: 0.6035\n",
            "Epoch 00269: val_loss did not improve from 0.81253\n",
            "16/16 [==============================] - 6s 356ms/step - loss: 0.8225 - acc: 0.6254 - val_loss: 0.8195 - val_acc: 0.6093\n",
            "Epoch 270/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8186 - acc: 0.6393Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8415 - acc: 0.5977\n",
            "Epoch 00270: val_loss did not improve from 0.81253\n",
            "16/16 [==============================] - 6s 344ms/step - loss: 0.8275 - acc: 0.6345 - val_loss: 0.8592 - val_acc: 0.6019\n",
            "Epoch 271/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8029 - acc: 0.6484Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9129 - acc: 0.5879\n",
            "Epoch 00271: val_loss did not improve from 0.81253\n",
            "16/16 [==============================] - 6s 356ms/step - loss: 0.8035 - acc: 0.6489 - val_loss: 0.9128 - val_acc: 0.5907\n",
            "Epoch 272/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8403 - acc: 0.6228Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8088 - acc: 0.6270\n",
            "Epoch 00272: val_loss improved from 0.81253 to 0.80934, saving model to model_2_4cl_best.h5\n",
            "16/16 [==============================] - 6s 351ms/step - loss: 0.8380 - acc: 0.6230 - val_loss: 0.8093 - val_acc: 0.6299\n",
            "Epoch 273/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8138 - acc: 0.6354Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.8166 - acc: 0.6113\n",
            "Epoch 00273: val_loss did not improve from 0.80934\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 0.8135 - acc: 0.6359 - val_loss: 0.8634 - val_acc: 0.6037\n",
            "Epoch 274/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8127 - acc: 0.6419Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8444 - acc: 0.5996\n",
            "Epoch 00274: val_loss did not improve from 0.80934\n",
            "16/16 [==============================] - 6s 346ms/step - loss: 0.8119 - acc: 0.6398 - val_loss: 0.8871 - val_acc: 0.5925\n",
            "Epoch 275/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8267 - acc: 0.6345Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8218 - acc: 0.6094\n",
            "Epoch 00275: val_loss did not improve from 0.80934\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 0.8218 - acc: 0.6349 - val_loss: 0.8683 - val_acc: 0.6000\n",
            "Epoch 276/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8294 - acc: 0.6307Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8179 - acc: 0.6133\n",
            "Epoch 00276: val_loss did not improve from 0.80934\n",
            "16/16 [==============================] - 6s 364ms/step - loss: 0.8231 - acc: 0.6338 - val_loss: 0.8435 - val_acc: 0.6075\n",
            "Epoch 277/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8268 - acc: 0.6319Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8336 - acc: 0.6113\n",
            "Epoch 00277: val_loss did not improve from 0.80934\n",
            "16/16 [==============================] - 6s 370ms/step - loss: 0.8198 - acc: 0.6365 - val_loss: 0.8727 - val_acc: 0.6056\n",
            "Epoch 278/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8009 - acc: 0.6403Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8470 - acc: 0.6172\n",
            "Epoch 00278: val_loss did not improve from 0.80934\n",
            "16/16 [==============================] - 6s 374ms/step - loss: 0.8076 - acc: 0.6379 - val_loss: 0.8829 - val_acc: 0.6168\n",
            "Epoch 279/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8238 - acc: 0.6095Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8409 - acc: 0.6133\n",
            "Epoch 00279: val_loss did not improve from 0.80934\n",
            "16/16 [==============================] - 6s 366ms/step - loss: 0.8274 - acc: 0.6110 - val_loss: 0.8980 - val_acc: 0.6019\n",
            "Epoch 280/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7824 - acc: 0.6504Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8613 - acc: 0.6133\n",
            "Epoch 00280: val_loss did not improve from 0.80934\n",
            "16/16 [==============================] - 6s 363ms/step - loss: 0.7878 - acc: 0.6478 - val_loss: 0.8971 - val_acc: 0.6093\n",
            "Epoch 281/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8218 - acc: 0.6141Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8423 - acc: 0.6094\n",
            "Epoch 00281: val_loss did not improve from 0.80934\n",
            "16/16 [==============================] - 6s 369ms/step - loss: 0.8215 - acc: 0.6162 - val_loss: 0.8843 - val_acc: 0.6037\n",
            "Epoch 282/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7921 - acc: 0.6382Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8562 - acc: 0.6445\n",
            "Epoch 00282: val_loss did not improve from 0.80934\n",
            "16/16 [==============================] - 6s 354ms/step - loss: 0.7980 - acc: 0.6324 - val_loss: 0.8412 - val_acc: 0.6393\n",
            "Epoch 283/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8057 - acc: 0.6395Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8767 - acc: 0.5977\n",
            "Epoch 00283: val_loss did not improve from 0.80934\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 0.8039 - acc: 0.6385 - val_loss: 0.8619 - val_acc: 0.5944\n",
            "Epoch 284/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8296 - acc: 0.6297Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8445 - acc: 0.6094\n",
            "Epoch 00284: val_loss did not improve from 0.80934\n",
            "16/16 [==============================] - 6s 371ms/step - loss: 0.8326 - acc: 0.6294 - val_loss: 0.8290 - val_acc: 0.6037\n",
            "Epoch 285/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8116 - acc: 0.6133Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8786 - acc: 0.5957\n",
            "Epoch 00285: val_loss did not improve from 0.80934\n",
            "16/16 [==============================] - 6s 351ms/step - loss: 0.8053 - acc: 0.6173 - val_loss: 0.8628 - val_acc: 0.5907\n",
            "Epoch 286/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8029 - acc: 0.6250Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8468 - acc: 0.6426\n",
            "Epoch 00286: val_loss did not improve from 0.80934\n",
            "16/16 [==============================] - 6s 361ms/step - loss: 0.8012 - acc: 0.6240 - val_loss: 0.8325 - val_acc: 0.6336\n",
            "Epoch 287/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8159 - acc: 0.6292Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8658 - acc: 0.5859\n",
            "Epoch 00287: val_loss did not improve from 0.80934\n",
            "16/16 [==============================] - 6s 353ms/step - loss: 0.8193 - acc: 0.6254 - val_loss: 0.8478 - val_acc: 0.5794\n",
            "Epoch 288/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8032 - acc: 0.6345Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8864 - acc: 0.5898\n",
            "Epoch 00288: val_loss did not improve from 0.80934\n",
            "16/16 [==============================] - 6s 353ms/step - loss: 0.8047 - acc: 0.6354 - val_loss: 0.8593 - val_acc: 0.5832\n",
            "Epoch 289/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8144 - acc: 0.6159Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8779 - acc: 0.5703\n",
            "Epoch 00289: val_loss did not improve from 0.80934\n",
            "16/16 [==============================] - 6s 347ms/step - loss: 0.8294 - acc: 0.6145 - val_loss: 0.8437 - val_acc: 0.5701\n",
            "Epoch 290/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8087 - acc: 0.6432Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.8349 - acc: 0.6230\n",
            "Epoch 00290: val_loss did not improve from 0.80934\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 0.8134 - acc: 0.6406 - val_loss: 0.8119 - val_acc: 0.6168\n",
            "Epoch 291/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8411 - acc: 0.6302Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8390 - acc: 0.6250\n",
            "Epoch 00291: val_loss did not improve from 0.80934\n",
            "16/16 [==============================] - 6s 361ms/step - loss: 0.8350 - acc: 0.6309 - val_loss: 0.8441 - val_acc: 0.6206\n",
            "Epoch 292/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7968 - acc: 0.6368Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8333 - acc: 0.6289\n",
            "Epoch 00292: val_loss did not improve from 0.80934\n",
            "16/16 [==============================] - 6s 346ms/step - loss: 0.8051 - acc: 0.6330 - val_loss: 0.8605 - val_acc: 0.6262\n",
            "Epoch 293/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7956 - acc: 0.6359Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8301 - acc: 0.6113\n",
            "Epoch 00293: val_loss did not improve from 0.80934\n",
            "16/16 [==============================] - 6s 368ms/step - loss: 0.7986 - acc: 0.6387 - val_loss: 0.8547 - val_acc: 0.6056\n",
            "Epoch 294/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8313 - acc: 0.6216Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8514 - acc: 0.6016\n",
            "Epoch 00294: val_loss did not improve from 0.80934\n",
            "16/16 [==============================] - 6s 370ms/step - loss: 0.8357 - acc: 0.6188 - val_loss: 0.8898 - val_acc: 0.5944\n",
            "Epoch 295/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8159 - acc: 0.6196Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8801 - acc: 0.5977\n",
            "Epoch 00295: val_loss did not improve from 0.80934\n",
            "16/16 [==============================] - 6s 375ms/step - loss: 0.8100 - acc: 0.6220 - val_loss: 0.8919 - val_acc: 0.5963\n",
            "Epoch 296/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8139 - acc: 0.6240Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8779 - acc: 0.6113\n",
            "Epoch 00296: val_loss did not improve from 0.80934\n",
            "16/16 [==============================] - 6s 373ms/step - loss: 0.8073 - acc: 0.6284 - val_loss: 0.8863 - val_acc: 0.6056\n",
            "Epoch 297/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8164 - acc: 0.6270Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8401 - acc: 0.6191\n",
            "Epoch 00297: val_loss did not improve from 0.80934\n",
            "16/16 [==============================] - 6s 364ms/step - loss: 0.8188 - acc: 0.6249 - val_loss: 0.8784 - val_acc: 0.6187\n",
            "Epoch 298/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8034 - acc: 0.6302Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8601 - acc: 0.6211\n",
            "Epoch 00298: val_loss did not improve from 0.80934\n",
            "16/16 [==============================] - 6s 372ms/step - loss: 0.7987 - acc: 0.6299 - val_loss: 0.8991 - val_acc: 0.6150\n",
            "Epoch 299/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8046 - acc: 0.6492Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8672 - acc: 0.6133\n",
            "Epoch 00299: val_loss did not improve from 0.80934\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 0.8046 - acc: 0.6491 - val_loss: 0.9066 - val_acc: 0.6075\n",
            "Epoch 300/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7883 - acc: 0.6464Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8056 - acc: 0.6328\n",
            "Epoch 00300: val_loss did not improve from 0.80934\n",
            "16/16 [==============================] - 6s 366ms/step - loss: 0.7863 - acc: 0.6450 - val_loss: 0.8415 - val_acc: 0.6262\n",
            "Epoch 301/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8068 - acc: 0.6446Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8318 - acc: 0.6191\n",
            "Epoch 00301: val_loss improved from 0.80934 to 0.79625, saving model to model_2_4cl_best.h5\n",
            "16/16 [==============================] - 6s 363ms/step - loss: 0.8178 - acc: 0.6364 - val_loss: 0.7962 - val_acc: 0.6243\n",
            "Epoch 302/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8095 - acc: 0.6318Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8745 - acc: 0.5977\n",
            "Epoch 00302: val_loss did not improve from 0.79625\n",
            "16/16 [==============================] - 6s 352ms/step - loss: 0.8049 - acc: 0.6384 - val_loss: 0.8451 - val_acc: 0.6037\n",
            "Epoch 303/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8242 - acc: 0.6233Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8538 - acc: 0.6074\n",
            "Epoch 00303: val_loss did not improve from 0.79625\n",
            "16/16 [==============================] - 6s 353ms/step - loss: 0.8235 - acc: 0.6234 - val_loss: 0.8150 - val_acc: 0.6112\n",
            "Epoch 304/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8120 - acc: 0.6419Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8084 - acc: 0.6270\n",
            "Epoch 00304: val_loss improved from 0.79625 to 0.79093, saving model to model_2_4cl_best.h5\n",
            "16/16 [==============================] - 6s 353ms/step - loss: 0.8117 - acc: 0.6374 - val_loss: 0.7909 - val_acc: 0.6299\n",
            "Epoch 305/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8141 - acc: 0.6329Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8314 - acc: 0.6230\n",
            "Epoch 00305: val_loss did not improve from 0.79093\n",
            "16/16 [==============================] - 6s 346ms/step - loss: 0.8162 - acc: 0.6324 - val_loss: 0.8031 - val_acc: 0.6262\n",
            "Epoch 306/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8072 - acc: 0.6350Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8669 - acc: 0.5977\n",
            "Epoch 00306: val_loss did not improve from 0.79093\n",
            "16/16 [==============================] - 5s 341ms/step - loss: 0.8000 - acc: 0.6423 - val_loss: 0.8263 - val_acc: 0.6019\n",
            "Epoch 307/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8189 - acc: 0.6218Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.8556 - acc: 0.6055\n",
            "Epoch 00307: val_loss did not improve from 0.79093\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 0.8176 - acc: 0.6230 - val_loss: 0.8132 - val_acc: 0.6075\n",
            "Epoch 308/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7871 - acc: 0.6438Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8577 - acc: 0.5918\n",
            "Epoch 00308: val_loss did not improve from 0.79093\n",
            "16/16 [==============================] - 6s 351ms/step - loss: 0.7921 - acc: 0.6377 - val_loss: 0.8213 - val_acc: 0.6000\n",
            "Epoch 309/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8075 - acc: 0.6384Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8477 - acc: 0.6035\n",
            "Epoch 00309: val_loss did not improve from 0.79093\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 0.8021 - acc: 0.6431 - val_loss: 0.8060 - val_acc: 0.6075\n",
            "Epoch 310/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8224 - acc: 0.6286Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8628 - acc: 0.6074\n",
            "Epoch 00310: val_loss did not improve from 0.79093\n",
            "16/16 [==============================] - 6s 368ms/step - loss: 0.8204 - acc: 0.6324 - val_loss: 0.8333 - val_acc: 0.6093\n",
            "Epoch 311/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8175 - acc: 0.6318Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8416 - acc: 0.5879\n",
            "Epoch 00311: val_loss did not improve from 0.79093\n",
            "16/16 [==============================] - 6s 371ms/step - loss: 0.8153 - acc: 0.6344 - val_loss: 0.8037 - val_acc: 0.5944\n",
            "Epoch 312/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7963 - acc: 0.6403Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8506 - acc: 0.6074\n",
            "Epoch 00312: val_loss did not improve from 0.79093\n",
            "16/16 [==============================] - 6s 373ms/step - loss: 0.7985 - acc: 0.6388 - val_loss: 0.8193 - val_acc: 0.6075\n",
            "Epoch 313/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8103 - acc: 0.6370Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8461 - acc: 0.6270\n",
            "Epoch 00313: val_loss did not improve from 0.79093\n",
            "16/16 [==============================] - 6s 375ms/step - loss: 0.8119 - acc: 0.6348 - val_loss: 0.8398 - val_acc: 0.6280\n",
            "Epoch 314/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7786 - acc: 0.6524Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9282 - acc: 0.5781\n",
            "Epoch 00314: val_loss did not improve from 0.79093\n",
            "16/16 [==============================] - 6s 367ms/step - loss: 0.7797 - acc: 0.6542 - val_loss: 0.9474 - val_acc: 0.5757\n",
            "Epoch 315/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8046 - acc: 0.6302Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8707 - acc: 0.6035\n",
            "Epoch 00315: val_loss did not improve from 0.79093\n",
            "16/16 [==============================] - 6s 363ms/step - loss: 0.7991 - acc: 0.6344 - val_loss: 0.8911 - val_acc: 0.6037\n",
            "Epoch 316/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8047 - acc: 0.6469Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8433 - acc: 0.6074\n",
            "Epoch 00316: val_loss did not improve from 0.79093\n",
            "16/16 [==============================] - 6s 363ms/step - loss: 0.8075 - acc: 0.6426 - val_loss: 0.8530 - val_acc: 0.6075\n",
            "Epoch 317/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7910 - acc: 0.6451Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9636 - acc: 0.6328\n",
            "Epoch 00317: val_loss did not improve from 0.79093\n",
            "16/16 [==============================] - 6s 359ms/step - loss: 0.7917 - acc: 0.6451 - val_loss: 0.9652 - val_acc: 0.6318\n",
            "Epoch 318/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8002 - acc: 0.6380Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8485 - acc: 0.6328\n",
            "Epoch 00318: val_loss did not improve from 0.79093\n",
            "16/16 [==============================] - 6s 361ms/step - loss: 0.8086 - acc: 0.6353 - val_loss: 0.8725 - val_acc: 0.6280\n",
            "Epoch 319/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8098 - acc: 0.6350Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8499 - acc: 0.6230\n",
            "Epoch 00319: val_loss did not improve from 0.79093\n",
            "16/16 [==============================] - 6s 359ms/step - loss: 0.8017 - acc: 0.6393 - val_loss: 0.8740 - val_acc: 0.6206\n",
            "Epoch 320/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8001 - acc: 0.6451Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8414 - acc: 0.6230\n",
            "Epoch 00320: val_loss did not improve from 0.79093\n",
            "16/16 [==============================] - 6s 354ms/step - loss: 0.8040 - acc: 0.6413 - val_loss: 0.8573 - val_acc: 0.6206\n",
            "Epoch 321/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7965 - acc: 0.6477Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8568 - acc: 0.6113\n",
            "Epoch 00321: val_loss did not improve from 0.79093\n",
            "16/16 [==============================] - 6s 354ms/step - loss: 0.7960 - acc: 0.6483 - val_loss: 0.8610 - val_acc: 0.6075\n",
            "Epoch 322/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8101 - acc: 0.6387Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8400 - acc: 0.5996\n",
            "Epoch 00322: val_loss did not improve from 0.79093\n",
            "16/16 [==============================] - 6s 349ms/step - loss: 0.8098 - acc: 0.6369 - val_loss: 0.8427 - val_acc: 0.5981\n",
            "Epoch 323/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7966 - acc: 0.6499Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8621 - acc: 0.5977\n",
            "Epoch 00323: val_loss did not improve from 0.79093\n",
            "16/16 [==============================] - 6s 347ms/step - loss: 0.7939 - acc: 0.6503 - val_loss: 0.8720 - val_acc: 0.5925\n",
            "Epoch 324/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7899 - acc: 0.6419Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.8322 - acc: 0.6211\n",
            "Epoch 00324: val_loss did not improve from 0.79093\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 0.7861 - acc: 0.6438 - val_loss: 0.8397 - val_acc: 0.6224\n",
            "Epoch 325/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7961 - acc: 0.6435Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8655 - acc: 0.6211\n",
            "Epoch 00325: val_loss did not improve from 0.79093\n",
            "16/16 [==============================] - 6s 352ms/step - loss: 0.7977 - acc: 0.6423 - val_loss: 0.8238 - val_acc: 0.6224\n",
            "Epoch 326/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8210 - acc: 0.6323Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8579 - acc: 0.6152\n",
            "Epoch 00326: val_loss did not improve from 0.79093\n",
            "16/16 [==============================] - 6s 357ms/step - loss: 0.8300 - acc: 0.6318 - val_loss: 0.8255 - val_acc: 0.6168\n",
            "Epoch 327/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7860 - acc: 0.6408Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8482 - acc: 0.6270\n",
            "Epoch 00327: val_loss did not improve from 0.79093\n",
            "16/16 [==============================] - 6s 366ms/step - loss: 0.7875 - acc: 0.6418 - val_loss: 0.8204 - val_acc: 0.6280\n",
            "Epoch 328/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7779 - acc: 0.6449Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8745 - acc: 0.6074\n",
            "Epoch 00328: val_loss did not improve from 0.79093\n",
            "16/16 [==============================] - 6s 373ms/step - loss: 0.7728 - acc: 0.6502 - val_loss: 0.8275 - val_acc: 0.6112\n",
            "Epoch 329/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7909 - acc: 0.6424Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8271 - acc: 0.6348\n",
            "Epoch 00329: val_loss did not improve from 0.79093\n",
            "16/16 [==============================] - 6s 375ms/step - loss: 0.7977 - acc: 0.6374 - val_loss: 0.7991 - val_acc: 0.6374\n",
            "Epoch 330/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7978 - acc: 0.6422Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8769 - acc: 0.5977\n",
            "Epoch 00330: val_loss did not improve from 0.79093\n",
            "16/16 [==============================] - 6s 369ms/step - loss: 0.7983 - acc: 0.6450 - val_loss: 0.8214 - val_acc: 0.6000\n",
            "Epoch 331/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8056 - acc: 0.6130Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8562 - acc: 0.6289\n",
            "Epoch 00331: val_loss did not improve from 0.79093\n",
            "16/16 [==============================] - 6s 359ms/step - loss: 0.8041 - acc: 0.6138 - val_loss: 0.8042 - val_acc: 0.6336\n",
            "Epoch 332/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7942 - acc: 0.6401Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8942 - acc: 0.6309\n",
            "Epoch 00332: val_loss did not improve from 0.79093\n",
            "16/16 [==============================] - 6s 366ms/step - loss: 0.7969 - acc: 0.6348 - val_loss: 0.8709 - val_acc: 0.6336\n",
            "Epoch 333/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8109 - acc: 0.6509Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8260 - acc: 0.6367\n",
            "Epoch 00333: val_loss improved from 0.79093 to 0.78160, saving model to model_2_4cl_best.h5\n",
            "16/16 [==============================] - 6s 372ms/step - loss: 0.8109 - acc: 0.6493 - val_loss: 0.7816 - val_acc: 0.6411\n",
            "Epoch 334/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7801 - acc: 0.6503Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8458 - acc: 0.6309\n",
            "Epoch 00334: val_loss did not improve from 0.78160\n",
            "16/16 [==============================] - 6s 350ms/step - loss: 0.7858 - acc: 0.6481 - val_loss: 0.7977 - val_acc: 0.6355\n",
            "Epoch 335/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8108 - acc: 0.6385Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8263 - acc: 0.6211\n",
            "Epoch 00335: val_loss did not improve from 0.78160\n",
            "16/16 [==============================] - 6s 370ms/step - loss: 0.8089 - acc: 0.6392 - val_loss: 0.7853 - val_acc: 0.6224\n",
            "Epoch 336/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7970 - acc: 0.6430Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8410 - acc: 0.6582\n",
            "Epoch 00336: val_loss did not improve from 0.78160\n",
            "16/16 [==============================] - 6s 360ms/step - loss: 0.8027 - acc: 0.6433 - val_loss: 0.8282 - val_acc: 0.6579\n",
            "Epoch 337/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7847 - acc: 0.6573Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8580 - acc: 0.6133\n",
            "Epoch 00337: val_loss did not improve from 0.78160\n",
            "16/16 [==============================] - 6s 364ms/step - loss: 0.7864 - acc: 0.6557 - val_loss: 0.8348 - val_acc: 0.6168\n",
            "Epoch 338/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8158 - acc: 0.6249Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8251 - acc: 0.6035\n",
            "Epoch 00338: val_loss did not improve from 0.78160\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 0.8138 - acc: 0.6279 - val_loss: 0.8130 - val_acc: 0.6075\n",
            "Epoch 339/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7895 - acc: 0.6371Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8462 - acc: 0.6230\n",
            "Epoch 00339: val_loss did not improve from 0.78160\n",
            "16/16 [==============================] - 6s 353ms/step - loss: 0.7876 - acc: 0.6408 - val_loss: 0.8301 - val_acc: 0.6262\n",
            "Epoch 340/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7873 - acc: 0.6344Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8609 - acc: 0.6328\n",
            "Epoch 00340: val_loss did not improve from 0.78160\n",
            "16/16 [==============================] - 6s 354ms/step - loss: 0.7906 - acc: 0.6334 - val_loss: 0.8562 - val_acc: 0.6355\n",
            "Epoch 341/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7762 - acc: 0.6438Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.7987 - acc: 0.6387\n",
            "Epoch 00341: val_loss did not improve from 0.78160\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 0.7818 - acc: 0.6455 - val_loss: 0.7873 - val_acc: 0.6430\n",
            "Epoch 342/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8004 - acc: 0.6303Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8515 - acc: 0.6191\n",
            "Epoch 00342: val_loss did not improve from 0.78160\n",
            "16/16 [==============================] - 6s 354ms/step - loss: 0.8105 - acc: 0.6259 - val_loss: 0.8321 - val_acc: 0.6224\n",
            "Epoch 343/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8125 - acc: 0.6308Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8216 - acc: 0.6484\n",
            "Epoch 00343: val_loss did not improve from 0.78160\n",
            "16/16 [==============================] - 6s 357ms/step - loss: 0.8070 - acc: 0.6299 - val_loss: 0.8127 - val_acc: 0.6411\n",
            "Epoch 344/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7924 - acc: 0.6408Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8209 - acc: 0.6367\n",
            "Epoch 00344: val_loss did not improve from 0.78160\n",
            "16/16 [==============================] - 6s 364ms/step - loss: 0.7950 - acc: 0.6423 - val_loss: 0.8089 - val_acc: 0.6374\n",
            "Epoch 345/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7827 - acc: 0.6453Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8283 - acc: 0.6230\n",
            "Epoch 00345: val_loss did not improve from 0.78160\n",
            "16/16 [==============================] - 6s 377ms/step - loss: 0.7795 - acc: 0.6504 - val_loss: 0.8040 - val_acc: 0.6243\n",
            "Epoch 346/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8144 - acc: 0.6308Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8313 - acc: 0.6387\n",
            "Epoch 00346: val_loss improved from 0.78160 to 0.77265, saving model to model_2_4cl_best.h5\n",
            "16/16 [==============================] - 6s 370ms/step - loss: 0.8130 - acc: 0.6304 - val_loss: 0.7726 - val_acc: 0.6467\n",
            "Epoch 347/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7995 - acc: 0.6313Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8383 - acc: 0.6309\n",
            "Epoch 00347: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 367ms/step - loss: 0.8012 - acc: 0.6304 - val_loss: 0.8261 - val_acc: 0.6299\n",
            "Epoch 348/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7875 - acc: 0.6573Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8730 - acc: 0.6094\n",
            "Epoch 00348: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 359ms/step - loss: 0.7885 - acc: 0.6547 - val_loss: 0.8545 - val_acc: 0.6093\n",
            "Epoch 349/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8045 - acc: 0.6167Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8615 - acc: 0.6074\n",
            "Epoch 00349: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 369ms/step - loss: 0.7978 - acc: 0.6211 - val_loss: 0.8430 - val_acc: 0.6093\n",
            "Epoch 350/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7931 - acc: 0.6631Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8510 - acc: 0.6035\n",
            "Epoch 00350: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 362ms/step - loss: 0.7989 - acc: 0.6607 - val_loss: 0.8229 - val_acc: 0.6075\n",
            "Epoch 351/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7869 - acc: 0.6411Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8370 - acc: 0.6250\n",
            "Epoch 00351: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 357ms/step - loss: 0.7892 - acc: 0.6380 - val_loss: 0.8155 - val_acc: 0.6318\n",
            "Epoch 352/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7906 - acc: 0.6443Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8282 - acc: 0.6113\n",
            "Epoch 00352: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 362ms/step - loss: 0.7862 - acc: 0.6484 - val_loss: 0.7870 - val_acc: 0.6187\n",
            "Epoch 353/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7949 - acc: 0.6446Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8361 - acc: 0.6348\n",
            "Epoch 00353: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 351ms/step - loss: 0.7962 - acc: 0.6398 - val_loss: 0.8110 - val_acc: 0.6393\n",
            "Epoch 354/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7833 - acc: 0.6589Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8623 - acc: 0.6191\n",
            "Epoch 00354: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 357ms/step - loss: 0.7844 - acc: 0.6592 - val_loss: 0.8289 - val_acc: 0.6206\n",
            "Epoch 355/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8088 - acc: 0.6334Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8577 - acc: 0.5977\n",
            "Epoch 00355: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 357ms/step - loss: 0.8032 - acc: 0.6374 - val_loss: 0.8283 - val_acc: 0.6056\n",
            "Epoch 356/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7991 - acc: 0.6488Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8063 - acc: 0.6211\n",
            "Epoch 00356: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 352ms/step - loss: 0.7958 - acc: 0.6493 - val_loss: 0.7888 - val_acc: 0.6280\n",
            "Epoch 357/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7876 - acc: 0.6495Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8307 - acc: 0.6055\n",
            "Epoch 00357: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 346ms/step - loss: 0.7875 - acc: 0.6478 - val_loss: 0.8154 - val_acc: 0.6112\n",
            "Epoch 358/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7921 - acc: 0.6329Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.8327 - acc: 0.6133\n",
            "Epoch 00358: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 0.7886 - acc: 0.6364 - val_loss: 0.7979 - val_acc: 0.6187\n",
            "Epoch 359/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7997 - acc: 0.6472Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8551 - acc: 0.6016\n",
            "Epoch 00359: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 345ms/step - loss: 0.8060 - acc: 0.6408 - val_loss: 0.8251 - val_acc: 0.6093\n",
            "Epoch 360/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7615 - acc: 0.6488Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8498 - acc: 0.6016\n",
            "Epoch 00360: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 357ms/step - loss: 0.7627 - acc: 0.6473 - val_loss: 0.8125 - val_acc: 0.6093\n",
            "Epoch 361/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7797 - acc: 0.6401Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8174 - acc: 0.5996\n",
            "Epoch 00361: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 364ms/step - loss: 0.7792 - acc: 0.6392 - val_loss: 0.8151 - val_acc: 0.6019\n",
            "Epoch 362/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7884 - acc: 0.6514Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8576 - acc: 0.6035\n",
            "Epoch 00362: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 374ms/step - loss: 0.8079 - acc: 0.6426 - val_loss: 0.8877 - val_acc: 0.6037\n",
            "Epoch 363/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7901 - acc: 0.6406Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8277 - acc: 0.6133\n",
            "Epoch 00363: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 372ms/step - loss: 0.7911 - acc: 0.6396 - val_loss: 0.8227 - val_acc: 0.6131\n",
            "Epoch 364/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7752 - acc: 0.6492Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8194 - acc: 0.6152\n",
            "Epoch 00364: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 365ms/step - loss: 0.7777 - acc: 0.6481 - val_loss: 0.8584 - val_acc: 0.6131\n",
            "Epoch 365/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7686 - acc: 0.6484Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8319 - acc: 0.6055\n",
            "Epoch 00365: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 367ms/step - loss: 0.7653 - acc: 0.6514 - val_loss: 0.8690 - val_acc: 0.6056\n",
            "Epoch 366/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8135 - acc: 0.6414Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8410 - acc: 0.6035\n",
            "Epoch 00366: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 363ms/step - loss: 0.8087 - acc: 0.6423 - val_loss: 0.8935 - val_acc: 0.6019\n",
            "Epoch 367/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7719 - acc: 0.6424Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8133 - acc: 0.6289\n",
            "Epoch 00367: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 367ms/step - loss: 0.7713 - acc: 0.6443 - val_loss: 0.8834 - val_acc: 0.6280\n",
            "Epoch 368/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7935 - acc: 0.6361Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8380 - acc: 0.6328\n",
            "Epoch 00368: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 363ms/step - loss: 0.7896 - acc: 0.6369 - val_loss: 0.8079 - val_acc: 0.6318\n",
            "Epoch 369/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7983 - acc: 0.6313Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8365 - acc: 0.6191\n",
            "Epoch 00369: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 361ms/step - loss: 0.7951 - acc: 0.6334 - val_loss: 0.8060 - val_acc: 0.6206\n",
            "Epoch 370/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7947 - acc: 0.6472Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8345 - acc: 0.6172\n",
            "Epoch 00370: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 351ms/step - loss: 0.7939 - acc: 0.6473 - val_loss: 0.8103 - val_acc: 0.6206\n",
            "Epoch 371/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7743 - acc: 0.6525Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8463 - acc: 0.6094\n",
            "Epoch 00371: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 0.7731 - acc: 0.6488 - val_loss: 0.8229 - val_acc: 0.6150\n",
            "Epoch 372/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7786 - acc: 0.6520Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8533 - acc: 0.6055\n",
            "Epoch 00372: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 360ms/step - loss: 0.7840 - acc: 0.6523 - val_loss: 0.8265 - val_acc: 0.6131\n",
            "Epoch 373/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8029 - acc: 0.6361Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8796 - acc: 0.6250\n",
            "Epoch 00373: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 352ms/step - loss: 0.8012 - acc: 0.6359 - val_loss: 0.8448 - val_acc: 0.6262\n",
            "Epoch 374/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7575 - acc: 0.6531Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8405 - acc: 0.5977\n",
            "Epoch 00374: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 347ms/step - loss: 0.7615 - acc: 0.6528 - val_loss: 0.8136 - val_acc: 0.6037\n",
            "Epoch 375/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7835 - acc: 0.6510Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.8273 - acc: 0.6094\n",
            "Epoch 00375: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 0.7817 - acc: 0.6528 - val_loss: 0.8029 - val_acc: 0.6187\n",
            "Epoch 376/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7698 - acc: 0.6632Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8423 - acc: 0.6270\n",
            "Epoch 00376: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 350ms/step - loss: 0.7722 - acc: 0.6643 - val_loss: 0.8062 - val_acc: 0.6355\n",
            "Epoch 377/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7844 - acc: 0.6605Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8621 - acc: 0.6035\n",
            "Epoch 00377: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 353ms/step - loss: 0.7899 - acc: 0.6577 - val_loss: 0.8050 - val_acc: 0.6112\n",
            "Epoch 378/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7851 - acc: 0.6552Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8206 - acc: 0.6367\n",
            "Epoch 00378: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 364ms/step - loss: 0.7837 - acc: 0.6499 - val_loss: 0.7874 - val_acc: 0.6411\n",
            "Epoch 379/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7690 - acc: 0.6492Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8065 - acc: 0.6113\n",
            "Epoch 00379: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 369ms/step - loss: 0.7757 - acc: 0.6456 - val_loss: 0.7742 - val_acc: 0.6168\n",
            "Epoch 380/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7903 - acc: 0.6515Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8352 - acc: 0.6309\n",
            "Epoch 00380: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 375ms/step - loss: 0.7926 - acc: 0.6463 - val_loss: 0.8037 - val_acc: 0.6374\n",
            "Epoch 381/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7741 - acc: 0.6578Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9068 - acc: 0.5898\n",
            "Epoch 00381: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 368ms/step - loss: 0.7765 - acc: 0.6562 - val_loss: 0.8476 - val_acc: 0.5981\n",
            "Epoch 382/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7766 - acc: 0.6467Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8454 - acc: 0.6309\n",
            "Epoch 00382: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 370ms/step - loss: 0.7812 - acc: 0.6488 - val_loss: 0.8227 - val_acc: 0.6393\n",
            "Epoch 383/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7995 - acc: 0.6542Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8314 - acc: 0.6113\n",
            "Epoch 00383: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 366ms/step - loss: 0.8022 - acc: 0.6523 - val_loss: 0.8094 - val_acc: 0.6187\n",
            "Epoch 384/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7717 - acc: 0.6530Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8154 - acc: 0.6250\n",
            "Epoch 00384: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 360ms/step - loss: 0.7748 - acc: 0.6532 - val_loss: 0.7953 - val_acc: 0.6299\n",
            "Epoch 385/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7823 - acc: 0.6499Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8188 - acc: 0.6309\n",
            "Epoch 00385: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 361ms/step - loss: 0.7868 - acc: 0.6483 - val_loss: 0.7805 - val_acc: 0.6374\n",
            "Epoch 386/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7608 - acc: 0.6546Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8350 - acc: 0.5977\n",
            "Epoch 00386: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 0.7683 - acc: 0.6493 - val_loss: 0.8112 - val_acc: 0.6075\n",
            "Epoch 387/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7730 - acc: 0.6440Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8329 - acc: 0.5938\n",
            "Epoch 00387: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 0.7733 - acc: 0.6413 - val_loss: 0.7964 - val_acc: 0.6019\n",
            "Epoch 388/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7778 - acc: 0.6547Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8520 - acc: 0.6133\n",
            "Epoch 00388: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 0.7774 - acc: 0.6523 - val_loss: 0.8304 - val_acc: 0.6187\n",
            "Epoch 389/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7746 - acc: 0.6493Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8413 - acc: 0.5957\n",
            "Epoch 00389: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 5s 342ms/step - loss: 0.7731 - acc: 0.6507 - val_loss: 0.7840 - val_acc: 0.6037\n",
            "Epoch 390/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7793 - acc: 0.6557Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8231 - acc: 0.6133\n",
            "Epoch 00390: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 359ms/step - loss: 0.7772 - acc: 0.6548 - val_loss: 0.7748 - val_acc: 0.6150\n",
            "Epoch 391/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7694 - acc: 0.6361Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8244 - acc: 0.6367\n",
            "Epoch 00391: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 349ms/step - loss: 0.7792 - acc: 0.6324 - val_loss: 0.8323 - val_acc: 0.6318\n",
            "Epoch 392/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7607 - acc: 0.6578Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.8168 - acc: 0.6484\n",
            "Epoch 00392: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 0.7676 - acc: 0.6547 - val_loss: 0.8106 - val_acc: 0.6467\n",
            "Epoch 393/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7866 - acc: 0.6375Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8182 - acc: 0.6191\n",
            "Epoch 00393: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 357ms/step - loss: 0.7788 - acc: 0.6421 - val_loss: 0.7893 - val_acc: 0.6206\n",
            "Epoch 394/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7868 - acc: 0.6568Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8451 - acc: 0.6016\n",
            "Epoch 00394: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 356ms/step - loss: 0.7901 - acc: 0.6532 - val_loss: 0.8135 - val_acc: 0.6019\n",
            "Epoch 395/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7712 - acc: 0.6456Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8369 - acc: 0.6309\n",
            "Epoch 00395: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 374ms/step - loss: 0.7734 - acc: 0.6468 - val_loss: 0.8159 - val_acc: 0.6280\n",
            "Epoch 396/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7723 - acc: 0.6536Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8411 - acc: 0.6035\n",
            "Epoch 00396: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 380ms/step - loss: 0.7719 - acc: 0.6542 - val_loss: 0.8703 - val_acc: 0.6093\n",
            "Epoch 397/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7909 - acc: 0.6438Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8387 - acc: 0.6230\n",
            "Epoch 00397: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 368ms/step - loss: 0.7842 - acc: 0.6465 - val_loss: 0.8497 - val_acc: 0.6280\n",
            "Epoch 398/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7718 - acc: 0.6681Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8573 - acc: 0.6016\n",
            "Epoch 00398: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 364ms/step - loss: 0.7844 - acc: 0.6582 - val_loss: 0.8794 - val_acc: 0.6075\n",
            "Epoch 399/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8063 - acc: 0.6446Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8356 - acc: 0.6270\n",
            "Epoch 00399: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 362ms/step - loss: 0.8082 - acc: 0.6413 - val_loss: 0.8437 - val_acc: 0.6318\n",
            "Epoch 400/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7744 - acc: 0.6515Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8477 - acc: 0.6152\n",
            "Epoch 00400: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 360ms/step - loss: 0.7745 - acc: 0.6523 - val_loss: 0.8780 - val_acc: 0.6168\n",
            "Epoch 401/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7798 - acc: 0.6361Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8130 - acc: 0.6406\n",
            "Epoch 00401: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 360ms/step - loss: 0.7840 - acc: 0.6339 - val_loss: 0.8457 - val_acc: 0.6411\n",
            "Epoch 402/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7683 - acc: 0.6594Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8863 - acc: 0.6055\n",
            "Epoch 00402: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 365ms/step - loss: 0.7744 - acc: 0.6558 - val_loss: 0.8403 - val_acc: 0.6075\n",
            "Epoch 403/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7706 - acc: 0.6573Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8612 - acc: 0.6191\n",
            "Epoch 00403: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 357ms/step - loss: 0.7689 - acc: 0.6572 - val_loss: 0.8426 - val_acc: 0.6206\n",
            "Epoch 404/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7792 - acc: 0.6499Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8323 - acc: 0.6387\n",
            "Epoch 00404: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 350ms/step - loss: 0.7836 - acc: 0.6473 - val_loss: 0.8036 - val_acc: 0.6393\n",
            "Epoch 405/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7662 - acc: 0.6642Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8227 - acc: 0.6602\n",
            "Epoch 00405: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 0.7669 - acc: 0.6637 - val_loss: 0.7958 - val_acc: 0.6579\n",
            "Epoch 406/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7801 - acc: 0.6500Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8172 - acc: 0.6230\n",
            "Epoch 00406: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 0.7797 - acc: 0.6499 - val_loss: 0.7940 - val_acc: 0.6243\n",
            "Epoch 407/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7701 - acc: 0.6531Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8080 - acc: 0.6348\n",
            "Epoch 00407: val_loss did not improve from 0.77265\n",
            "16/16 [==============================] - 6s 349ms/step - loss: 0.7694 - acc: 0.6528 - val_loss: 0.7764 - val_acc: 0.6318\n",
            "Epoch 408/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7662 - acc: 0.6504Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.7847 - acc: 0.6309\n",
            "Epoch 00408: val_loss improved from 0.77265 to 0.75487, saving model to model_2_4cl_best.h5\n",
            "16/16 [==============================] - 6s 351ms/step - loss: 0.7683 - acc: 0.6473 - val_loss: 0.7549 - val_acc: 0.6280\n",
            "Epoch 409/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7862 - acc: 0.6488Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.8657 - acc: 0.6113\n",
            "Epoch 00409: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 0.7842 - acc: 0.6518 - val_loss: 0.8206 - val_acc: 0.6112\n",
            "Epoch 410/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7794 - acc: 0.6584Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8332 - acc: 0.6406\n",
            "Epoch 00410: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 356ms/step - loss: 0.7776 - acc: 0.6587 - val_loss: 0.7894 - val_acc: 0.6393\n",
            "Epoch 411/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7638 - acc: 0.6472Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.7945 - acc: 0.6621\n",
            "Epoch 00411: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 361ms/step - loss: 0.7635 - acc: 0.6483 - val_loss: 0.7825 - val_acc: 0.6561\n",
            "Epoch 412/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7898 - acc: 0.6432Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8569 - acc: 0.6152\n",
            "Epoch 00412: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 369ms/step - loss: 0.7895 - acc: 0.6436 - val_loss: 0.8401 - val_acc: 0.6093\n",
            "Epoch 413/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7849 - acc: 0.6492Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8253 - acc: 0.6250\n",
            "Epoch 00413: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 366ms/step - loss: 0.7784 - acc: 0.6496 - val_loss: 0.8171 - val_acc: 0.6206\n",
            "Epoch 414/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7466 - acc: 0.6615Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8402 - acc: 0.6133\n",
            "Epoch 00414: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 374ms/step - loss: 0.7531 - acc: 0.6592 - val_loss: 0.8215 - val_acc: 0.6075\n",
            "Epoch 415/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7924 - acc: 0.6521Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8286 - acc: 0.6230\n",
            "Epoch 00415: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 365ms/step - loss: 0.7921 - acc: 0.6509 - val_loss: 0.8390 - val_acc: 0.6168\n",
            "Epoch 416/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7821 - acc: 0.6476Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8342 - acc: 0.6152\n",
            "Epoch 00416: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 362ms/step - loss: 0.7778 - acc: 0.6507 - val_loss: 0.8556 - val_acc: 0.6150\n",
            "Epoch 417/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7608 - acc: 0.6609Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8280 - acc: 0.6250\n",
            "Epoch 00417: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 366ms/step - loss: 0.7653 - acc: 0.6602 - val_loss: 0.8704 - val_acc: 0.6262\n",
            "Epoch 418/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7833 - acc: 0.6531Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8191 - acc: 0.6211\n",
            "Epoch 00418: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 366ms/step - loss: 0.7818 - acc: 0.6562 - val_loss: 0.8334 - val_acc: 0.6280\n",
            "Epoch 419/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7650 - acc: 0.6663Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8751 - acc: 0.5957\n",
            "Epoch 00419: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 367ms/step - loss: 0.7695 - acc: 0.6622 - val_loss: 0.8899 - val_acc: 0.6037\n",
            "Epoch 420/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7546 - acc: 0.6546Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8231 - acc: 0.6328\n",
            "Epoch 00420: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 353ms/step - loss: 0.7586 - acc: 0.6542 - val_loss: 0.8202 - val_acc: 0.6355\n",
            "Epoch 421/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7841 - acc: 0.6551Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8152 - acc: 0.6426\n",
            "Epoch 00421: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 359ms/step - loss: 0.7792 - acc: 0.6577 - val_loss: 0.8626 - val_acc: 0.6411\n",
            "Epoch 422/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7870 - acc: 0.6443Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8280 - acc: 0.6348\n",
            "Epoch 00422: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 356ms/step - loss: 0.7869 - acc: 0.6440 - val_loss: 0.8456 - val_acc: 0.6374\n",
            "Epoch 423/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7692 - acc: 0.6621Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.7974 - acc: 0.6406\n",
            "Epoch 00423: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 353ms/step - loss: 0.7688 - acc: 0.6607 - val_loss: 0.8236 - val_acc: 0.6449\n",
            "Epoch 424/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7629 - acc: 0.6599Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8405 - acc: 0.6230\n",
            "Epoch 00424: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 346ms/step - loss: 0.7614 - acc: 0.6632 - val_loss: 0.8830 - val_acc: 0.6262\n",
            "Epoch 425/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7839 - acc: 0.6472Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8187 - acc: 0.6465\n",
            "Epoch 00425: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 347ms/step - loss: 0.7826 - acc: 0.6483 - val_loss: 0.8315 - val_acc: 0.6505\n",
            "Epoch 426/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7872 - acc: 0.6552Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.8152 - acc: 0.6250\n",
            "Epoch 00426: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 0.7800 - acc: 0.6587 - val_loss: 0.8608 - val_acc: 0.6262\n",
            "Epoch 427/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7576 - acc: 0.6525Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8276 - acc: 0.6074\n",
            "Epoch 00427: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 352ms/step - loss: 0.7571 - acc: 0.6552 - val_loss: 0.8467 - val_acc: 0.6131\n",
            "Epoch 428/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7987 - acc: 0.6531Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8032 - acc: 0.6191\n",
            "Epoch 00428: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 363ms/step - loss: 0.7916 - acc: 0.6562 - val_loss: 0.8512 - val_acc: 0.6243\n",
            "Epoch 429/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7783 - acc: 0.6488Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8499 - acc: 0.6328\n",
            "Epoch 00429: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 362ms/step - loss: 0.7830 - acc: 0.6458 - val_loss: 0.8596 - val_acc: 0.6374\n",
            "Epoch 430/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7518 - acc: 0.6716Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8361 - acc: 0.6367\n",
            "Epoch 00430: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 375ms/step - loss: 0.7523 - acc: 0.6736 - val_loss: 0.8670 - val_acc: 0.6393\n",
            "Epoch 431/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7814 - acc: 0.6536Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.7978 - acc: 0.6211\n",
            "Epoch 00431: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 365ms/step - loss: 0.7840 - acc: 0.6503 - val_loss: 0.8338 - val_acc: 0.6206\n",
            "Epoch 432/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7729 - acc: 0.6510Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8627 - acc: 0.6230\n",
            "Epoch 00432: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 377ms/step - loss: 0.7721 - acc: 0.6484 - val_loss: 0.8805 - val_acc: 0.6262\n",
            "Epoch 433/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7727 - acc: 0.6627Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8152 - acc: 0.6230\n",
            "Epoch 00433: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 354ms/step - loss: 0.7729 - acc: 0.6623 - val_loss: 0.8488 - val_acc: 0.6243\n",
            "Epoch 434/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7507 - acc: 0.6711Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8423 - acc: 0.6504\n",
            "Epoch 00434: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 360ms/step - loss: 0.7545 - acc: 0.6687 - val_loss: 0.8684 - val_acc: 0.6505\n",
            "Epoch 435/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7707 - acc: 0.6562Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.7989 - acc: 0.6387\n",
            "Epoch 00435: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 361ms/step - loss: 0.7705 - acc: 0.6592 - val_loss: 0.8299 - val_acc: 0.6430\n",
            "Epoch 436/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7594 - acc: 0.6568Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8086 - acc: 0.6250\n",
            "Epoch 00436: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 0.7636 - acc: 0.6537 - val_loss: 0.8255 - val_acc: 0.6299\n",
            "Epoch 437/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7663 - acc: 0.6609Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.7739 - acc: 0.6289\n",
            "Epoch 00437: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 369ms/step - loss: 0.7667 - acc: 0.6592 - val_loss: 0.8082 - val_acc: 0.6299\n",
            "Epoch 438/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7706 - acc: 0.6520Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.7848 - acc: 0.6328\n",
            "Epoch 00438: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 364ms/step - loss: 0.7664 - acc: 0.6538 - val_loss: 0.8201 - val_acc: 0.6374\n",
            "Epoch 439/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7819 - acc: 0.6451Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8266 - acc: 0.6309\n",
            "Epoch 00439: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 0.7779 - acc: 0.6463 - val_loss: 0.7895 - val_acc: 0.6299\n",
            "Epoch 440/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7886 - acc: 0.6419Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8440 - acc: 0.6152\n",
            "Epoch 00440: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 353ms/step - loss: 0.7861 - acc: 0.6463 - val_loss: 0.8202 - val_acc: 0.6187\n",
            "Epoch 441/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7655 - acc: 0.6541Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8429 - acc: 0.6289\n",
            "Epoch 00441: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 351ms/step - loss: 0.7622 - acc: 0.6557 - val_loss: 0.8088 - val_acc: 0.6262\n",
            "Epoch 442/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7896 - acc: 0.6589Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8023 - acc: 0.6191\n",
            "Epoch 00442: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 347ms/step - loss: 0.7829 - acc: 0.6607 - val_loss: 0.8439 - val_acc: 0.6206\n",
            "Epoch 443/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7661 - acc: 0.6615Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.8563 - acc: 0.6270\n",
            "Epoch 00443: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 0.7752 - acc: 0.6567 - val_loss: 0.8667 - val_acc: 0.6318\n",
            "Epoch 444/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7635 - acc: 0.6594Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8192 - acc: 0.6289\n",
            "Epoch 00444: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 350ms/step - loss: 0.7551 - acc: 0.6652 - val_loss: 0.8586 - val_acc: 0.6318\n",
            "Epoch 445/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7632 - acc: 0.6499Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8171 - acc: 0.6211\n",
            "Epoch 00445: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 360ms/step - loss: 0.7602 - acc: 0.6538 - val_loss: 0.8422 - val_acc: 0.6243\n",
            "Epoch 446/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7744 - acc: 0.6647Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8145 - acc: 0.6406\n",
            "Epoch 00446: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 372ms/step - loss: 0.7758 - acc: 0.6587 - val_loss: 0.8575 - val_acc: 0.6430\n",
            "Epoch 447/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7812 - acc: 0.6403Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8113 - acc: 0.6523\n",
            "Epoch 00447: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 374ms/step - loss: 0.7723 - acc: 0.6458 - val_loss: 0.8572 - val_acc: 0.6523\n",
            "Epoch 448/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7851 - acc: 0.6411Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8326 - acc: 0.6191\n",
            "Epoch 00448: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 368ms/step - loss: 0.7849 - acc: 0.6416 - val_loss: 0.8592 - val_acc: 0.6243\n",
            "Epoch 449/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7533 - acc: 0.6600Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8369 - acc: 0.6191\n",
            "Epoch 00449: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 384ms/step - loss: 0.7491 - acc: 0.6618 - val_loss: 0.8378 - val_acc: 0.6206\n",
            "Epoch 450/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7925 - acc: 0.6469Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8519 - acc: 0.6133\n",
            "Epoch 00450: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 384ms/step - loss: 0.7848 - acc: 0.6484 - val_loss: 0.8232 - val_acc: 0.6168\n",
            "Epoch 451/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7615 - acc: 0.6541Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8127 - acc: 0.6211\n",
            "Epoch 00451: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 362ms/step - loss: 0.7689 - acc: 0.6502 - val_loss: 0.7833 - val_acc: 0.6280\n",
            "Epoch 452/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7886 - acc: 0.6443Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8432 - acc: 0.6387\n",
            "Epoch 00452: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 373ms/step - loss: 0.7831 - acc: 0.6479 - val_loss: 0.8320 - val_acc: 0.6393\n",
            "Epoch 453/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7368 - acc: 0.6668Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8715 - acc: 0.6328\n",
            "Epoch 00453: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 365ms/step - loss: 0.7350 - acc: 0.6672 - val_loss: 0.8135 - val_acc: 0.6374\n",
            "Epoch 454/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7634 - acc: 0.6684Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8375 - acc: 0.6309\n",
            "Epoch 00454: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 360ms/step - loss: 0.7584 - acc: 0.6692 - val_loss: 0.7742 - val_acc: 0.6411\n",
            "Epoch 455/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7802 - acc: 0.6393Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8037 - acc: 0.6445\n",
            "Epoch 00455: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 0.7727 - acc: 0.6463 - val_loss: 0.8211 - val_acc: 0.6430\n",
            "Epoch 456/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7640 - acc: 0.6578Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8074 - acc: 0.6328\n",
            "Epoch 00456: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 0.7607 - acc: 0.6552 - val_loss: 0.8302 - val_acc: 0.6318\n",
            "Epoch 457/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7658 - acc: 0.6584Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8339 - acc: 0.6309\n",
            "Epoch 00457: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 353ms/step - loss: 0.7655 - acc: 0.6567 - val_loss: 0.8233 - val_acc: 0.6299\n",
            "Epoch 458/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7672 - acc: 0.6621Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8077 - acc: 0.6309\n",
            "Epoch 00458: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 357ms/step - loss: 0.7655 - acc: 0.6642 - val_loss: 0.8058 - val_acc: 0.6299\n",
            "Epoch 459/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7535 - acc: 0.6668Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8263 - acc: 0.6133\n",
            "Epoch 00459: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 347ms/step - loss: 0.7556 - acc: 0.6662 - val_loss: 0.7881 - val_acc: 0.6206\n",
            "Epoch 460/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7634 - acc: 0.6653Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.8332 - acc: 0.6250\n",
            "Epoch 00460: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 5s 301ms/step - loss: 0.7613 - acc: 0.6637 - val_loss: 0.7996 - val_acc: 0.6299\n",
            "Epoch 461/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7757 - acc: 0.6599Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8240 - acc: 0.6406\n",
            "Epoch 00461: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 351ms/step - loss: 0.7768 - acc: 0.6557 - val_loss: 0.7984 - val_acc: 0.6449\n",
            "Epoch 462/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7505 - acc: 0.6546Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.7928 - acc: 0.6406\n",
            "Epoch 00462: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 359ms/step - loss: 0.7558 - acc: 0.6533 - val_loss: 0.7753 - val_acc: 0.6486\n",
            "Epoch 463/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7702 - acc: 0.6495Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8536 - acc: 0.6211\n",
            "Epoch 00463: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 372ms/step - loss: 0.7658 - acc: 0.6499 - val_loss: 0.8152 - val_acc: 0.6318\n",
            "Epoch 464/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7426 - acc: 0.6578Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.7908 - acc: 0.6172\n",
            "Epoch 00464: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 373ms/step - loss: 0.7438 - acc: 0.6592 - val_loss: 0.7555 - val_acc: 0.6243\n",
            "Epoch 465/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7776 - acc: 0.6642Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8362 - acc: 0.6406\n",
            "Epoch 00465: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 374ms/step - loss: 0.7799 - acc: 0.6657 - val_loss: 0.8122 - val_acc: 0.6449\n",
            "Epoch 466/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7503 - acc: 0.6573Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8123 - acc: 0.6270\n",
            "Epoch 00466: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 371ms/step - loss: 0.7470 - acc: 0.6577 - val_loss: 0.7952 - val_acc: 0.6336\n",
            "Epoch 467/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7717 - acc: 0.6627Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8182 - acc: 0.6270\n",
            "Epoch 00467: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 357ms/step - loss: 0.7701 - acc: 0.6633 - val_loss: 0.7829 - val_acc: 0.6299\n",
            "Epoch 468/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7680 - acc: 0.6599Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8657 - acc: 0.6250\n",
            "Epoch 00468: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 363ms/step - loss: 0.7676 - acc: 0.6592 - val_loss: 0.8383 - val_acc: 0.6299\n",
            "Epoch 469/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7458 - acc: 0.6521Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8081 - acc: 0.6152\n",
            "Epoch 00469: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 372ms/step - loss: 0.7489 - acc: 0.6528 - val_loss: 0.7829 - val_acc: 0.6224\n",
            "Epoch 470/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7758 - acc: 0.6681Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.7880 - acc: 0.6309\n",
            "Epoch 00470: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 359ms/step - loss: 0.7765 - acc: 0.6684 - val_loss: 0.7845 - val_acc: 0.6299\n",
            "Epoch 471/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7705 - acc: 0.6605Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8287 - acc: 0.6738\n",
            "Epoch 00471: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 357ms/step - loss: 0.7831 - acc: 0.6602 - val_loss: 0.8529 - val_acc: 0.6710\n",
            "Epoch 472/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7384 - acc: 0.6661Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8170 - acc: 0.6387\n",
            "Epoch 00472: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 361ms/step - loss: 0.7358 - acc: 0.6680 - val_loss: 0.8301 - val_acc: 0.6355\n",
            "Epoch 473/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7611 - acc: 0.6721Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8449 - acc: 0.6250\n",
            "Epoch 00473: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 351ms/step - loss: 0.7637 - acc: 0.6716 - val_loss: 0.8597 - val_acc: 0.6243\n",
            "Epoch 474/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7356 - acc: 0.6775Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.7731 - acc: 0.6387\n",
            "Epoch 00474: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 0.7372 - acc: 0.6766 - val_loss: 0.7825 - val_acc: 0.6393\n",
            "Epoch 475/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7644 - acc: 0.6552Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.7920 - acc: 0.6523\n",
            "Epoch 00475: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 353ms/step - loss: 0.7573 - acc: 0.6577 - val_loss: 0.8028 - val_acc: 0.6467\n",
            "Epoch 476/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7640 - acc: 0.6684Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8196 - acc: 0.6367\n",
            "Epoch 00476: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 5s 339ms/step - loss: 0.7580 - acc: 0.6736 - val_loss: 0.8704 - val_acc: 0.6393\n",
            "Epoch 477/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7735 - acc: 0.6642Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.7784 - acc: 0.6367\n",
            "Epoch 00477: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 0.7703 - acc: 0.6647 - val_loss: 0.7968 - val_acc: 0.6374\n",
            "Epoch 478/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7372 - acc: 0.6687Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8152 - acc: 0.6445\n",
            "Epoch 00478: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 360ms/step - loss: 0.7422 - acc: 0.6672 - val_loss: 0.7904 - val_acc: 0.6467\n",
            "Epoch 479/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7697 - acc: 0.6621Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8124 - acc: 0.6191\n",
            "Epoch 00479: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 357ms/step - loss: 0.7680 - acc: 0.6602 - val_loss: 0.7826 - val_acc: 0.6206\n",
            "Epoch 480/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7359 - acc: 0.6605Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.7950 - acc: 0.6523\n",
            "Epoch 00480: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 365ms/step - loss: 0.7397 - acc: 0.6627 - val_loss: 0.7590 - val_acc: 0.6505\n",
            "Epoch 481/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7568 - acc: 0.6806Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8485 - acc: 0.6328\n",
            "Epoch 00481: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 378ms/step - loss: 0.7524 - acc: 0.6836 - val_loss: 0.8005 - val_acc: 0.6318\n",
            "Epoch 482/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7504 - acc: 0.6526Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8034 - acc: 0.6562\n",
            "Epoch 00482: val_loss did not improve from 0.75487\n",
            "16/16 [==============================] - 6s 376ms/step - loss: 0.7506 - acc: 0.6538 - val_loss: 0.7770 - val_acc: 0.6542\n",
            "Epoch 483/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7783 - acc: 0.6659Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.7764 - acc: 0.6543\n",
            "Epoch 00483: val_loss improved from 0.75487 to 0.74395, saving model to model_2_4cl_best.h5\n",
            "16/16 [==============================] - 6s 367ms/step - loss: 0.7823 - acc: 0.6598 - val_loss: 0.7440 - val_acc: 0.6542\n",
            "Epoch 484/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7424 - acc: 0.6801Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8022 - acc: 0.6445\n",
            "Epoch 00484: val_loss did not improve from 0.74395\n",
            "16/16 [==============================] - 6s 369ms/step - loss: 0.7479 - acc: 0.6766 - val_loss: 0.7709 - val_acc: 0.6467\n",
            "Epoch 485/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7535 - acc: 0.6594Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8762 - acc: 0.6191\n",
            "Epoch 00485: val_loss did not improve from 0.74395\n",
            "16/16 [==============================] - 6s 368ms/step - loss: 0.7514 - acc: 0.6577 - val_loss: 0.8401 - val_acc: 0.6168\n",
            "Epoch 486/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7680 - acc: 0.6795Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8391 - acc: 0.6328\n",
            "Epoch 00486: val_loss did not improve from 0.74395\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 0.7568 - acc: 0.6866 - val_loss: 0.8021 - val_acc: 0.6318\n",
            "Epoch 487/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7592 - acc: 0.6573Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8472 - acc: 0.6211\n",
            "Epoch 00487: val_loss did not improve from 0.74395\n",
            "16/16 [==============================] - 6s 366ms/step - loss: 0.7475 - acc: 0.6637 - val_loss: 0.8102 - val_acc: 0.6206\n",
            "Epoch 488/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7916 - acc: 0.6448Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.7981 - acc: 0.6562\n",
            "Epoch 00488: val_loss did not improve from 0.74395\n",
            "16/16 [==============================] - 6s 359ms/step - loss: 0.7964 - acc: 0.6436 - val_loss: 0.7675 - val_acc: 0.6505\n",
            "Epoch 489/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7388 - acc: 0.6849Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8091 - acc: 0.6602\n",
            "Epoch 00489: val_loss did not improve from 0.74395\n",
            "16/16 [==============================] - 6s 360ms/step - loss: 0.7366 - acc: 0.6850 - val_loss: 0.7869 - val_acc: 0.6505\n",
            "Epoch 490/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7613 - acc: 0.6536Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8064 - acc: 0.6465\n",
            "Epoch 00490: val_loss did not improve from 0.74395\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 0.7607 - acc: 0.6508 - val_loss: 0.7673 - val_acc: 0.6467\n",
            "Epoch 491/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7550 - acc: 0.6695Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8102 - acc: 0.6445\n",
            "Epoch 00491: val_loss did not improve from 0.74395\n",
            "16/16 [==============================] - 6s 354ms/step - loss: 0.7583 - acc: 0.6682 - val_loss: 0.7735 - val_acc: 0.6449\n",
            "Epoch 492/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7593 - acc: 0.6637Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8234 - acc: 0.6367\n",
            "Epoch 00492: val_loss did not improve from 0.74395\n",
            "16/16 [==============================] - 6s 346ms/step - loss: 0.7632 - acc: 0.6637 - val_loss: 0.7837 - val_acc: 0.6374\n",
            "Epoch 493/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7492 - acc: 0.6594Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8207 - acc: 0.6543\n",
            "Epoch 00493: val_loss did not improve from 0.74395\n",
            "16/16 [==============================] - 6s 349ms/step - loss: 0.7492 - acc: 0.6602 - val_loss: 0.7785 - val_acc: 0.6523\n",
            "Epoch 494/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7670 - acc: 0.6642Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.8131 - acc: 0.6523\n",
            "Epoch 00494: val_loss did not improve from 0.74395\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 0.7570 - acc: 0.6711 - val_loss: 0.8786 - val_acc: 0.6467\n",
            "Epoch 495/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7585 - acc: 0.6642Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8807 - acc: 0.6094\n",
            "Epoch 00495: val_loss did not improve from 0.74395\n",
            "16/16 [==============================] - 6s 361ms/step - loss: 0.7591 - acc: 0.6632 - val_loss: 0.8883 - val_acc: 0.6037\n",
            "Epoch 496/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7492 - acc: 0.6557Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8179 - acc: 0.6367\n",
            "Epoch 00496: val_loss did not improve from 0.74395\n",
            "16/16 [==============================] - 6s 353ms/step - loss: 0.7488 - acc: 0.6562 - val_loss: 0.7953 - val_acc: 0.6355\n",
            "Epoch 497/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7647 - acc: 0.6649Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8098 - acc: 0.6504\n",
            "Epoch 00497: val_loss did not improve from 0.74395\n",
            "16/16 [==============================] - 6s 360ms/step - loss: 0.7603 - acc: 0.6689 - val_loss: 0.8004 - val_acc: 0.6486\n",
            "Epoch 498/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7382 - acc: 0.6732Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8038 - acc: 0.6543\n",
            "Epoch 00498: val_loss did not improve from 0.74395\n",
            "16/16 [==============================] - 6s 368ms/step - loss: 0.7336 - acc: 0.6711 - val_loss: 0.7987 - val_acc: 0.6542\n",
            "Epoch 499/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7759 - acc: 0.6562Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.7968 - acc: 0.6543\n",
            "Epoch 00499: val_loss did not improve from 0.74395\n",
            "16/16 [==============================] - 6s 367ms/step - loss: 0.7771 - acc: 0.6567 - val_loss: 0.8179 - val_acc: 0.6505\n",
            "Epoch 500/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7250 - acc: 0.6737Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8437 - acc: 0.6309\n",
            "Epoch 00500: val_loss did not improve from 0.74395\n",
            "16/16 [==============================] - 6s 373ms/step - loss: 0.7290 - acc: 0.6751 - val_loss: 0.8131 - val_acc: 0.6336\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCIvZ0IzXP2G",
        "colab_type": "code",
        "outputId": "ca380011-9f5c-40cd-f409-e4c275ac4656",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# History of accuracy and loss\n",
        "tra_loss_2 = history_2.history['loss']\n",
        "tra_acc_2 = history_2.history['acc']\n",
        "val_loss_2 = history_2.history['val_loss']\n",
        "val_acc_2 = history_2.history['val_acc']\n",
        "\n",
        "# Total number of epochs training\n",
        "epochs_2 = range(1, len(tra_acc_2)+1)\n",
        "end_epoch_2 = len(tra_acc_2)\n",
        "\n",
        "# Epoch when reached the validation loss minimum\n",
        "opt_epoch_2 = val_loss_2.index(min(val_loss_2)) + 1\n",
        "\n",
        "# Loss and accuracy on the validation set\n",
        "end_val_loss_2 = val_loss_2[-1]\n",
        "end_val_acc_2 = val_acc_2[-1]\n",
        "opt_val_loss_2 = val_loss_2[opt_epoch_2-1]\n",
        "opt_val_acc_2 = val_acc_2[opt_epoch_2-1]\n",
        "\n",
        "# Loss and accuracy on the test set\n",
        "opt_model_2 = models.load_model('model_2_4cl_best.h5')\n",
        "test_loss_2, test_acc_2 = model_2.evaluate(test_images, test_labels, verbose=False)\n",
        "opt_test_loss_2, opt_test_acc_2 = opt_model_2.evaluate(test_images, test_labels, verbose=False)\n",
        "\n",
        "print(\"Model 2\\n\")\n",
        "\n",
        "print(\"Epoch [end]: %d\" % end_epoch_2)\n",
        "print(\"Epoch [opt]: %d\" % opt_epoch_2)\n",
        "print(\"Valid accuracy [end]: %.4f\" % end_val_acc_2)\n",
        "print(\"Valid accuracy [opt]: %.4f\" % opt_val_acc_2)\n",
        "print(\"Test accuracy [end]:  %.4f\" % test_acc_2)\n",
        "print(\"Test accuracy [opt]:  %.4f\" % opt_test_acc_2)\n",
        "print(\"Valid loss [end]: %.4f\" % end_val_loss_2)\n",
        "print(\"Valid loss [opt]: %.4f\" % opt_val_loss_2)\n",
        "print(\"Test loss [end]:  %.4f\" % test_loss_2)\n",
        "print(\"Test loss [opt]:  %.4f\" % opt_test_loss_2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 2\n",
            "\n",
            "Epoch [end]: 500\n",
            "Epoch [opt]: 483\n",
            "Valid accuracy [end]: 0.6336\n",
            "Valid accuracy [opt]: 0.6542\n",
            "Test accuracy [end]:  0.6071\n",
            "Test accuracy [opt]:  0.6131\n",
            "Valid loss [end]: 0.8131\n",
            "Valid loss [opt]: 0.7440\n",
            "Test loss [end]:  0.9278\n",
            "Test loss [opt]:  0.9047\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y07EZqDoXwJa",
        "colab_type": "code",
        "outputId": "ca75958a-d4bd-4554-e25a-81350fde46bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 991
        }
      },
      "source": [
        "# Model accuracy\n",
        "plt.figure(figsize=(7, 7), dpi=80, facecolor='w', edgecolor='k')\n",
        "plt.title('Model 2 accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.plot(epochs_2, tra_acc_2, 'r', label='Training set')\n",
        "plt.plot(epochs_2, val_acc_2, 'g', label='Validation set')\n",
        "plt.plot(opt_epoch_2, val_acc_2[opt_epoch_2-1], 'go')\n",
        "plt.vlines(opt_epoch_2, min(val_acc_2), opt_val_acc_2, linestyle=\"dashed\", color='g', linewidth=1)\n",
        "plt.hlines(opt_val_acc_2, 1, opt_epoch_2, linestyle=\"dashed\", color='g', linewidth=1)\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "# Model loss\n",
        "plt.figure(figsize=(7, 7), dpi=80, facecolor='w', edgecolor='k')\n",
        "plt.title('Model 2 loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylim(0.7, 1.7)\n",
        "plt.plot(epochs_2, tra_loss_2, 'r', label='Training set')\n",
        "plt.plot(epochs_2, val_loss_2, 'g', label='Validation set')\n",
        "plt.plot(opt_epoch_2, val_loss_2[opt_epoch_2-1], 'go')\n",
        "plt.vlines(opt_epoch_2, min(val_loss_2), opt_val_loss_2, linestyle=\"dashed\", color='g', linewidth=1)\n",
        "plt.hlines(opt_val_loss_2, 1, opt_epoch_2, linestyle=\"dashed\", color='g', linewidth=1)\n",
        "plt.legend();"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAHnCAYAAABHfw/FAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAMTQAADE0B0s6tTgAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOydd3gU1frHv1uym7abhCSQkBB6kN6L\njWJBQIqKBaWFi4Ci6FWvP0BQsBcUvOhFQbiIIFUQRVEEFAEBpUqHEEoSEpKQ3rbP74+zZ+ZM2c0G\nCO2ez/Pw7O7UMxOd77zveYtOEAQBHA6Hw+Fwbij013oAHA6Hw+Fwqg8XcA6Hw+FwbkC4gHM4HA6H\ncwPCBZzD4XA4nBsQLuAcDofD4dyAcAHncDgcDucGhAs4h8PhcDg3IFzAOZwbkE2bNkGn0wW8/ZYt\nW6DT6eByuWpwVBwO52rCBZzDqQF69uwJnU6HuXPnypaXlpbCYrFAp9Ph1KlT12h0av78808MGDAA\ncXFxsFqtaN26NRYuXHith8XhcPzABZzDqSFatGihEvDFixejfv3612hEvsnPz8fgwYNx8OBBFBcX\nY/bs2Xj++eexdu3aaz20gHE6ndd6CBzOVYULOIdTQwwYMAA5OTn4888/xWWfffYZxo0bp9r2xx9/\nRMeOHREREYHk5GR8+OGH8Hg84vq9e/eia9euCA8PR6dOnXDw4EHVMb766iu0bdsWERERaNmyJZYv\nXx7wWPv164eUlBTUrl0bOp0OvXr1wl133YXffvvN5z6HDx/G3XffjdjYWERERKBr16749ddfZdsc\nO3YMAwcORFxcHCIiItCtWzdkZGQAACorKzF16lQkJyfDYrGgUaNGWLRoEQBg+vTpuOOOO2THSklJ\nwbBhw8TfDRo0wLRp09CnTx9YLBZ89NFHyM7ORv/+/VGnTh1YLBa0adMGq1atkh0nMzMTQ4cORWJi\nIqxWK9q1a4d9+/Zh8+bNsFqtKCsrk23funVrfPzxxwHfSw7nqiFwOJwrTo8ePYQpU6YIr732mpCS\nkiIIgiBs27ZNSEpKEtLS0gQAQmpqqiAIgvDXX38JQUFBwooVKwSn0yns2bNHiI+PF2bNmiUIgiAU\nFxcLMTExwtSpUwWbzSYcOXJEaNy4scD+77tw4UKhXr16wu7duwW32y1s27ZNsFgswrZt2wRBEITf\nfvtNACA4nc6Axl9cXCzExcUJCxcu9LnNoUOHhF9++UWoqKgQbDabMG3aNMFqtQo5OTmCIAjChQsX\nhOjoaGHy5MlCcXGx4HK5hL/++kvIy8sTBEEQhg4dKnTu3Fk4evSo4PF4hPPnzwt79+4VBEEQpk2b\nJtx+++2y840cOVIYOnSo+Lt+/fpCnTp1hB07dggej0coLy8XMjIyhNWrVwulpaWCw+EQ5s+fLxiN\nRuHw4cOCIAhCRUWF0LRpUyElJUXIy8sT3G63cOTIEeHs2bOCx+MRkpOThXnz5onn2L59uxASEiIU\nFBQEdN84nKsJF3AOpwagAp6RkSFYLBahsLBQeOKJJ4Q333xTOHPmjEzAx44dKzzwwAOy/WfOnCk0\na9ZMEARBWLJkiVC7dm3B5XKJ62fPni0T8NatWwuff/657BhPPvmkMHr0aEEQqifgdrtd6NOnj9Cz\nZ8+ABZ8SEREhfP/994IgCMKMGTOEli1bam6Xl5cnABB2796tuT5QAZ80aVKVY2rTpo0we/ZsQRAE\nYdWqVUKtWrUEm82mue3MmTOFTp06ib+HDx8ujBw5sspzcDjXAu5C53BqkMTERPTq1Qsffvghvvvu\nO4wePVq1TUZGBho3bixb1qRJE6SnpwMgLt969erBYDCI6xs2bCjbPjU1FS+99BIiIyPFf8uWLUNW\nVla1xltRUYGBAwfCbrdj3bp1MBqNPrdNT0/HkCFDkJSUBKvVisjISJSUlCA3NxcAcObMGTRr1kxz\n3zNnzgCAz/WBorwPhYWFGDNmDBo2bCiO6ciRI7IxNWjQAGazWfN4KSkpOHLkCPbv34/CwkKsWrVK\nc8qDw7ke4ALO4dQwTz/9NN555x307dsX8fHxqvX16tVDWlqabFlaWhqSkpIAkJeAjIwMuN1ucf3Z\ns2dl28fFxWHOnDkoKioS/5WVlWH9+vUBj7OwsBD33HMPjEYj1q9fj/DwcL/bjxkzBh6PB7t370ZJ\nSQkKCwthtVoheDsUN2jQAKmpqZr7NmjQAABw8uRJzfUWiwXl5eWyZVovI3q9/BE2adIkHD9+HL//\n/juKi4tRVFSEli1bysZ09uxZOBwOzfNGRUVhyJAhmDt3LhYtWoTk5GTceuutvm8Ch3MN4QLO4dQw\n9913HzZu3IhZs2Zprv/HP/6BH3/8EatXr4bb7cb+/fsxY8YMjB07FgDQv39/uN1uvPHGG7Db7Th+\n/Dj+/e9/y47xz3/+E2+++SZ2794Nj8cDu92O3bt3Y+/evQGN8cKFC+jRowfq1auHb7/9FsHBwVXu\nU1xcjPDwcERFRaG8vByTJ0+WBYCNGDECmZmZePXVV1FaWgq32409e/bg4sWLiI2NxeOPP45nnnkG\nJ06cAABkZ2dj3759AIBOnTrh0KFD2L59O9xuN1atWoWtW7cGNKbQ0FBER0fD6XTik08+wZEjR8T1\n/fv3R1RUFMaPH4+LFy9CEAQcPXoU586dE7cZP348li5dijlz5nDrm3NdwwWcw6lhdDod7r77biQm\nJmqu79q1K7755hu8/fbbiIqKwiOPPILnnnsOzz//PAAgIiIC69evx/r16xEdHY1hw4bh6aeflh3j\n+eefx/Tp0/HUU0+hVq1aSEhIwMsvv6yyYn0xd+5cHDp0CD/88AOioqIQHh6O8PBw9O3b1+c+s2fP\nxt9//42oqCi0aNECCQkJsmusU6cOtm7dir1796Jhw4aIjo7GhAkTYLPZAABffPEFevTogb59+yI8\nPBy33367KLY9evTAK6+8goceegixsbHYsmULBg8eXOV1vPXWW6isrESdOnXQoEED5OTk4PbbbxfX\nh4SE4Ndff0VZWRlat26NiIgIDB06FAUFBeI2nTp1QrNmzZCVlSWLeudwrjd0AvUtcTgcDgcA8Nhj\nj8FqteKLL7641kPhcHziO0KFw+Fw/gc5cOAAvvvuu4CnHzicawUXcA6Hw/Fy55134u+//8Ybb7yB\nli1bXuvhcDh+4S50DofD4XBuQHgQG4fD4XA4NyBcwDkcDofDuQG5qefAzWYzYmNjr/UwOBwOh8O5\nJPLy8mC32zXX1biAp6amYuTIkbh48SIiIiLw5ZdfqoJDFi5cKCtMkZmZie7du2PNmjUAgB9++AH/\n+te/4Ha70bp1a3z55ZewWq1Vnjs2NhaZmZlX9oI4HA6Hw7lK+KofAVwFF/q4ceMwduxYnDx5EhMn\nTkRKSopqm1GjRuHAgQPiv7i4OAwdOhQAUFZWhtGjR2Pt2rVITU1F3bp18eabb9b0sDkcDofDua6p\nUQHPzc3Fnj17xGpGgwcPRkZGBk6dOuVznz///BO5ubkYOHAgAOCnn35C+/btccsttwAgZQ6XLVtW\nk8PmcDgcDue6p0YFPCMjA/Hx8WJHI51Oh6SkJLHLkhYLFizA8OHDERQUBIB0PKpfv764vkGDBsjO\nzobL5arJoXM4HA6Hc11zXQWxlZeXY/ny5di1a9cl7T9z5kzMnDlT/M02VuBwOBwO52aiRi3wevXq\nyaxlQRCQnp4utklUsmrVKrRs2RItWrQQlyUlJck6BZ09e1Zm1bO8+OKLyMzMFP9V1Q6Rw+FwOJwb\nlRoV8Nq1a6NDhw5YsmQJAGD16tVITExEkyZNNLdfsGABRo8eLVvWp08f7Nu3D8ePHwcAzJkzB0OG\nDKnJYXM4HA6Hc91T46VUT5w4gZSUFOTn58NqtWLhwoVo3bo1nnzySQwcOFAMVjtx4gQ6deqErKws\nWCwW2TG+//57/N///R9cLhdatWqFRYsWISIiospzJyYm8jQyDofD4dyw+NOxm7oWOhdwDofD4dzI\n+NMxXkqVw+FwOJwbEC7gHA6Hw+HcgHAB53A4HA7nBoQLOIfD4XA4NyBcwDkcDofDuQHhAs7hcDgc\nzg0IF3AOh8PhcG5AuIBzOBwOh3MDwgWcw+FwOBxf/PUX8MUX13oUmnAB53A4HA7HFx99BIwdCzid\nwHVWuJQLOIfD4XA4vrDZyOcffwB6PfDjj9d2PAxcwDkcDofDoeTmAjt3Sr/tdvL52Wfk8/33r/6Y\nfKBuqs3hcDgczv8qbdoAOTlAQQEQFQU4HGQ5FfLryI3OLXAOh8PhcCg5OeSTus6pcNPfXMA5HA6H\nw7mO8XjIJxdwDofD4XBuIKjrnH5yAedwOBwO5waAWt7cAudwOBwO5waCW+AcDofD4dyAKKPPeRQ6\nh8PhcDjXAaWlwO23Axs2aK/PyABatACys8lvboFzOBwOh3Md8O23wI4dwIAB2us/+QQ4dkz6HYiA\n798PfP+9tG0NwwWcw+FwOP97ZGaSz7p1tddTlzklEAGfNw8YNAgoK7v88QUAF3AOh8PhXD3mzLk+\n6olTAc/JAaZOVQuzUsADmQOvqCCfYWFXZoxVwAWcw+FwOFePZ54B+ve/1qMgc9wAsazffhvYu1cq\n3kKXs1Dh9ifg5eXkMzj4yo3TD1zAORwOh/O/R1qa/HdpqVy0lRY4pSoLPDQU0Okuf3wBwAWcw+Fw\nOFeH6yCCe/XR1Wj2STJK01PlK8rKgMpK6bevQDR6DYcOAbVrAwcPAmfPAlYr8NNPRMCvErwbGYfD\n4XCuDjS3+hry8KqHAQC/JwD9TzIrLl6UC7ivQDQq4H/9BeTlkUj2w4eJBQ9cVQHnFjiHw+Fwrg5K\nt/T582pXdqAIAjB0KAmKu5TdlQvy8uQCXlTk+7wAUFhIPrOygI0bpfVXKYAN4ALO4XA4nKuF0gJP\nTASaNLm0Y+3aBSxdSoLiAuXAAfnvmBjpe26uXMB9cegQ8NJLkoBnZwMnGVOeW+AcDofDuem4lMAw\nX3z1Ffm0WALf57PPpFNawuUvDx99BKxYEdhxZs4Ezp0j30+flq/jAs7hcDicmw5WwFlr/FIKnxw8\nSD6bNSOfggC8+y6webN8O9aqZt3btWqpxfaddwI//44d5PP4cflyLuAcDofDuelgBZwWUgFIAJkW\n69YBmzZpr6NFU+gxDxwAXnkFuOceaZtdu4igUmudEXChVtTlie2ZM+QzK0u+nM+BczgcDidgdu0i\nLuDrHdbqZoPXfAn4wIHAvfdqr6OWNU33oiINSA1IVq4kn7Nnk0+jlHglREbWTMEVboFzOBwOJ2Bu\nvRX4179IWdArzXPPAc2bX9q+aWnAb79Jv1kLPJXJw87PV+9b1bw4tcCpgLOu859/Jp9OJ/k8dAhY\ntkzaB4AQFSltH3WZ1jgLF3AOh8PhVBtqeV5JPvmEzPOyZUZ9kZsL7N4t/W7SBLjrLkmMWQFnI7e1\nLHAa5e0LKsbUEs/KAmJjyXdq3VNxdziAJ56Q3R93VKR0TffcQ15UrgRcwDkcDodTbWh975ogkECz\ntm2BLl1ITfCCAmm5cr4akOaQAW0Bz82Vvrtc5PPBB4GXX5Yf02Yjx83PB9q3J8suXCCfyheaXbvE\nr86IcEnA9XogIaHq6wuEkJArc5wA4ALO4XA4VxO7HRgxgrh1rzRsYNiVpqTE//rcXEk4L1wAfvlF\nWkfFnxVwVqCVAn74MNCrl/SbFlVZuxb48ENi0bNz4PS8zZsDJpM0lZCeLj8u47Z3moySZ0CvB+Lj\n/V9foFylOugAF3AOh8O5uqxaBSxeDPToQX6XlUlztZdLTVrgtFQoi8tFhP3QIaBOHWl5To7cRU73\nZYPYlALOzE9j6FBJlAF1VTS2TrnLJe/tXaeOtK+f++GMskoWuE4nWeB33+1zHxFq6deuLS0LCiKf\nbnfV+18huIBzOBzO1YRafeXlRNAsFuD++y//eMDlW+B2u+/gMWqBb9wILFlCvo8aBUREAL//Lt/2\nwgW5y33KFCLyrAWel0euXacD5s4l6VfUxa209sePlws+K/aA5I6vWxeIiyPnLy/3XQ4VgDOxrtyF\n3q0b6VP+3Xc+9xHp3h349Vf5ddeqRT65gHM4HM6Nw8WKi7h/6f04knuk6o1pKpPbLYkcW0u7urBi\ndjkW+P79JK1q3jxpmSBgWStg0j2QrOjevYHhw8l3KuRKV/U775BmH5SVK4E2beQCXloKREaScqqU\nb74hn9SapWzcKC+ZqhRwWg0tPp5Y4Dk5csHXwOF2yAUcAPr1CyyPOyyMuPiTk6W/JxXwQIL9rhBc\nwDkcDucy+feuf2N96nqMXDuy6o1ZAffVsrI6sFbm+fOXfpzvvyefM2eSz99/B8LDsbA9MPNWqK1i\nGlgGyFPCAGDvXrVVDqhLqVosQKNG0m9BIAKo9SLCRqUrA+pYAY+LI1MSdEwNGpDPVq1kuzjdTuDZ\nZ8mP0aNl6wQA25OALx9NxvYkQOjRXX4+s5l86vXkhUGnI54IgFvgHA6HcyPh8hAx8xT7dtmKGAzS\nd6UleSmwAk6Dt956C+jatXo1xqkgU+u3d2+gogIVQYDTAAjFxeI2U+8CVuxeKO179Ghg5xg3Tv7b\napULeFYWmQbQerFha54r893XryfjrldPmos/4vWGTJlCXgrYoDgATo+TWNyCQFziXs4VnUPzZ4C7\nRwATWmfg7jEmNO9+COcimJ1ZD0HdukS8n3qK/B40yM8NuLJwAedwOJwrRVqauhY3S06OvPRmIN2v\nqoK1TEtKyEvBq68SF7ZW4FlBAbB1KxFdVghpIJ3JRLbxBpxVeLXKVVoM5ORAAPB2d2DIL2OlfWnA\n2iOPVG/sFgvQuLH0+/RpyZr+8EN5EZjycuk7DVKL9BZjycsj8/EWCxFxAPjjD/IZE0MsZLqcXq5b\nHTgoCALuW3If0moBDiNQ5q6Ew+1Amr4IfYYxLUhNJmmn114DZswARo4k91/xolCTGKvehEOxu+yw\nuyUXUJA+CCFBIah0VpK3OS9mgxlmoxnljnK4BcmdEmwMhslgQpmjDB5BmicJDQqFUW9EiV3uogoL\nCoNep0epQ/4/ocVkgUfwoNxZLltuNVvh8rhQ4ZTe6vU6PcJN4XC4HbC5pLdag86AMFMYvyZ+Tfya\nNm2DsG0ryl6fcsnX5HATsdMJQGX6aTjtnTWvyRoXJztHZXE+aNZwib3k0q6psBA6AJ6YaOgv5qM0\n/RSorVp2LhWe5KayaxK6dIHOW+hEMJlQXpqP8NmfA++/DwBwG/WoyM8Wj0EFvLTwAkxnTiKIcSCw\nCDoddMuWkSj7QLFaURkRJt4DT9opCLm5MACoqB0FT4wV4fT4Fy6AJmjZMs8iGIAnKhJ6rwei/KEB\ncNtLoLuzCxn76tVkuTUEbnsJjLVrIRTkbyTogFJHqXg/6d/p1zO/4kzRGbgU1+jSCTgdBfyRBNyR\nDrkF3r8/bC4bnlwzDP/s9k90snQK/PovEy7g1eDd7e/i9d9fF3+Pbj8a8wfOx4SfJmDB/gXi8mk9\npmF6z+l4aOVD+CVNyoX8YsAXeLLDk+g6vyuO5kkup5+H/oz7mtyHxJmJsofL4acPo15EPUS8x/pu\ngOJJxcgozkCrz6Q5HYvJgpLJJdh8ejP6fN1HXN4itgWOjD+Cr/7+CmPWjRGX927cGxuGbeDXxK/p\nf/6ahOmADkBt4wewB13aNTWIbACAHGfYz2OxJn2s5jUpHdrT1r+MD7zfI96LuKRrarJtC8wA/gjN\nx50Aen/YFju965+e1gm3ZgBv9AAqosk16Zga5DqHA9/2qY/hv0lFV3Zd2ItRs1uBJoFRAV/+w/vY\ncvh9fM4YnyyVlmCEGgz4cnATpKw+pVo//95oPLlRUTLVYsGQfa+Axn3r8wtw4fCfiAMwaONo7D8E\n0AxxIUcS8I/XTsYkAAcc6ejgXdb5+wE45g1iT6tjQqMc8lLV4ds+OLkN6H0K2MCcesaOGZixYwYA\n6e/0+u+viy9jSkxu4FQtDQEHsDFtI74+9DXWHFuDiilXYFokQHSCcCmNWAMnNTUVI0eOxMWLFxER\nEYEvv/wSLVu2VG136NAhTJgwATlel87bb7+Nhx56CFu2bEHfvn3RjLaMA7Bz506EBFDtJjExEZlX\nsLDBdWMx3IxWEL8mfk3X6JqswUTQS7LPkprYl3BN07dMx6xds9DpPPB73xVw9eujeU30XBTb2tUI\nfmAwOb+tuFrXZPxmDYKPnID+3fcAAPbx42CeMxcVyxcjdMhw+Xk+eAeOp8fC+tTzwNdfwx+CXg/n\nE0NgWrIUABDzf0B+KJD7ARBj0yMz3IOkF73bTpf28yQ3hf7ESZQ7ymHucReMu/6CEBICnXeawPbZ\nJwh+eoL8ZM89h5IP3oTxh/Uwbv4Nps/mwfPEE9AvXYqyXVvhadcW+r37kPZQL8zuCnz+AxDkARzD\nh8K0+Gu47u4F42biZi/NSIMQGwMACH5pEkz/Ib2/S8+fgRBdC7rTZ2Bp0Q6GaYBHBzzb+Vm8fffb\nsr/T5tOb0W9pP00RN7mAzV8RAXfPm4vxcXsxqv0odEvshkUHFiHluxRyT6ZdWUn1p2M1boGPGzcO\nY8eORUpKCr755hukpKRgN1srF0BFRQUGDRqEr776CnfccQfcbjcKmDJ8zZo1w4EDB2p6qFViNpIH\niZKQoBCEQP1CEWbSTkcIN4VrLrearQEvN+gMmsuNeqPmcpPBBJNB/erMr4lfk6+x+1p+M14TAFg9\nQYBiXaDXZNRLj9JQvVl1HF/XFOyURJo9j+ya8vKASS8A778Pa0yMtHzYKOn7fffB/ODDwJy5CM3K\nU58nIxvBaZlVijcA6DweUbwByQJ3GMi6ch8WuD6G1CEPM4UBEeRFSBcfL85pB9/SSr2T1Uque/AQ\nwDtu/eHDAIDwug3IfbytJ7qMJecfdAIYeAIw5RFL3hgjFVKxxNeXAgTv6A54BdxSpx5Z3rwtsGcP\ndD92Bbwvgsq/7V0N70LDyIY4kX9CttwIPRoVenC7N1tuP7Ixb988zNs3D8I0AWeKpLKwDrdD87/3\nmqBGg9hyc3OxZ88eDBs2DAAwePBgZGRk4NQpuXtl6dKl6NatG+644w4AgMFgQCwtSs/hcDhXA62I\n8IwM4Msvpd8XLwLbt6s2o45MHSCvNgaQCOhp00hDkEDOqWTsWOC//xXnqAGo08Uef1wqBaoVEX7y\npN+iJr7w6IBKr4A7vdpYHuRj4+ho6bvVK4yxsfikC/B1awD166t2WRKSilk7Z5EfdPy0xCxzPIf3\n3ME0c412G2PPyUb3d+umvbxjR/Er6+WhZJRkoFVt+YuGyWBCk6A4tL0A9B1G3Oi6yEjZNqcLT4vf\nA6oFcIWoUQHPyMhAfHw8jN68R51Oh6SkJKQrkv6PHj0Ks9mM/v37o127dhgxYgTy8qS3yLS0NHTo\n0AGdO3fGnDlzanLIHA7nRqeiAjh4sPr7aUWE33MPiW7e6Z1V7toVuPNOqUnGmTPA999D8M5u6wSo\nc51/+QV44w2gZ0//51y6VDuHmHos2WlDhRcTYWEk/xlQ11iPiwM2bJCKpFQDG+OjpSJaFqXotvXS\nSySPegLjHqcpX2YznusHDBsMudh6Ge5cgRd/8frjqYALAunopdHVK0SpubR4ihKNlwWKzlurXCsK\nfdiaYVh9bLVs2dKHluK3Rm9gRWtgQxNgxf/dj7JObWXbsBZ4RkkNlrNVcF2kkblcLmzatAlz587F\n/v37kZCQgKeffhoA0KFDB2RmZmLfvn349ttv8fnnn2MlbdKuYObMmUhMTBT/lQXSPYfD4VwbHn+c\npPdc6cpV48eTrlh79lRvP6U1vG2blB5FC4vQFCda1GTMGGDQIAinpcAwlYDTimBsdy7K3LnS96FD\nSf42iyBI1jZ7XJoiRQkLI2JWqxbw55/ydTTP+tNPyedjj6nH4YMKxtp2NGkIAChvJE/HwoMPAvPn\nA/feKy0LDpbGT2HzuJXncVaQfGoKO1XA4FBGwDMxCywbT2/ClIXD1fcJgM4bCqdlgbNxDZTk6GQ4\ngqU3mX0NzSh1Stri8rhkFni5Qx4fUpPUqIDXq1cP2dnZcHmT/wVBQHp6OpKSkmTbJSUloVevXkhI\nSIBOp8OwYcOwy1sT12q1IsJb4SYxMRGPP/44tm3bpnm+F198EZmZmeK/8HDtuTEOh3MdsHw5+dQq\n2rFxIymyoRTDQKDu1S1bqrcfaw0fOyYr7qFyP9P8aq8oC97nlQ5Qj5mKfYQ8gA0AKV/KMn06Eb0/\n/yTWONsOk3olS0qABQvk+4WFkZchttrYrbeSpin9+8u3rUbXLVbAnc1IOlq5VTGXr2XtUrc161Fg\nu3TREqxeskuz5ePyIeB2ZdSWVTueofeS3njn3GKUdmytWkctcK1ANTaWgXK26CwcZkbAs/ehzCEJ\neHpxOnLKchBiJPdFGeBZk9SogNeuXRsdOnTAEu8fa/Xq1UhMTESTJk1k2z366KPYvXs3Srz/oa9f\nvx5t2xIXRXZ2NjzeN/TS0lL88MMPaE87wXA4nBsfLZHu3Rv46SdNC6pKmnrznk+pU5n8wlrgp0/L\n17HFVwCguJh80rlQ72+dAPUceGkpLoYCY+6tRLE6Zk/NvHlkDve99+TnpS03160jxVuolQtI9bvZ\nDJ9p04Bhw4AXXwQeekha7hXKD24HNjA1VLSoiJDc2I5O7QAA5e2ZcxiN2i8E3trigtulXgcQbwNz\nn7LLssn10PvpzwLfvZvEE7z7rua52cQqLTGl0f1OjxO55bkY/d1oFFYW4r3t72Fn5k5xu9hQEod1\nvvQ8HCbJ9D9bdBbnis6Jvw/nHoZbcKOuhXgQWHGvaWrchT537lzMnTsXycnJeO+997BwISm/9+ST\nT+J7b+3dpKQkvPLKK7jtttvQpk0b/Prrr/j8888BENFv3bo12rZti27duuHee+/FqFGjfJ6Pw+Hc\nYPizsi8ly5VW3KqugLMWuLLut7I2N11PLXHvvqIFLgikvKfLBeTnY0JfYH6zcky+J4BxrF1LPjdu\nlDfkoBY4FfIuXaR1VMBZC5yKm9kMeAOEAQB168KjAybeC/yHHmLgQM2hVHz0nvjdObA/sGMHyrsz\nAWK1asmDxCjeZU5BY06fwvgR12cAACAASURBVORSZ5d6PQ3UO8u402mZWgCwG0Cs7mbNgEmTpLKp\n90g39lyxJK5Kd7YgCOLxnG4nnvvpOfz3wH8xefNkTN48WbZtvIXcvyJbERxGYrXXd5L7vPjgYnG7\ntII02fZX04Ve42lkzZo1w86dO1XL58+fL/s9fPhwDB8+XLXds88+i2dpwXkOh3PzcaUFnJYEVTbY\n0IJtyLF3LzBxIrBihdrizsiQW+gPPUSi070CLhul3Q7Mng3885/ECs7JEVOvSgKxwKlom0xyAc/O\nJuOlLw2s9UkF/LbbyOeIEUBrxn3MVoCLjxdd43YDiBX93XfEqu/RQxYEVxEmpUM5PE7g1jtRtn2r\ndCxfzVj0eqTWAt5ufVa+nLYVVZBd5hXwr78mXhfG7V9QKcUO2I2QB/N16kTKrTLR5fuy94nfL1Zc\nxEc7P8LU7lNR11JXVkfA4XaIdQjYOWxKhDlC2i6I2LrDyxpjZu1TOJInRZrT8VEL/Gq60HklNg6H\nc2250gJOhTYzkwTI6f04Glmr+913yeesWUDt2vLtMjLU7SlTUkRL0cNM78Jul1pp7tsH2GzQewOw\n3TpUDa3zzQq4xQKcOwe0aAE88ABZpiXg7dqReXllcBe1VAEgIgJlXl22GyHdn6go+Tw1gAqjFGBI\no7ZlAuWrlntQEHqmAFlWReU1ZZCeF9ECb9VK1TXsYsVF8bvdAHV0uiK6/2zRWfH729vexrqT63A4\n9zC2jtoqs+adHqc4582egxIZTNz5HsEDRxC5LzG6UNzb6F58d0LqGZ5fSa6xbrhXwG+WIDYOh8Op\nEn8tNS9FwKmoeDzakd8bNpBIdUHQzsNOSiLiz3LiBIlKV+K1hl3eJymdAy9xlePZfkB+iADk5MDg\n1UFPIAJOrf+cHMlapQFwqalSQJ2WgAPakdmsBR4SIgm4AfIXHMX8fYVeEnAa9CUTKHZuneXll5Gl\niC/zV/QzqyzL5zpWXB0GyCxwm8uGFze8KCs7W2qXKu0V2kijl5xyUuGTTR1zup3imLJK1eePCiH3\n0SN44AghN8wcakU9qzwKnwq46EK/WYLYOBwORxM2daymLHBAmjcGSGrZlClAnz7AZ58Rl7SWgBcX\nywul1KlDxjFxonpbb6oqLXJC58Anxh7Af7oA/0o4QgTcexnu6jxx9+yRorVZgaa1zFkBN1VR+YsV\n8OBgUcBtrAXuHTtLhV7ucgYUAqWMhqdovESwZXMB+dy2lgVMKbJJGQB2I2TBezP+mIFZu2bhhQ0v\niMvYIDK3h4yfpocpLXClwLOEGkPF49m9UeimfgNEoabkV3gFPJwLOIfDuQ6xuWyYsH4CUvMDmFcO\nBLY1pD8B95Uj7nb7ttxZUaYuaJuNFHd55x1pXXGxtgs4P18etHbvvUBsrDyly8sfiQLe6xMu5ifr\nBACHDiHDSR7qP4Rn4T8N80QLPCAXuhYrVkjfT5wgAWBsYRSv6/v97e/jz0xFHjggF1RGwO1GiF27\nAIjW7detgTXNgQqdXPAASaAMOoP8xcKLIAh4a6vaVa7Msba7pL+7sm49C1uLXukxoMFk0SHSvWBr\n3dM5b3puNvfb4XZoWt6UcHO4OE768mKyRIpCTaFz4NGh0WId+6sFF3AOh1MlSw4uwae7P8UDKx64\nMgdk+1Tb7SQfWkusnepiGwCAIUOI2GiJuJaA5+ertyso0LbAf/tNHXXuo+LXHaOByd3KkMm6i7ds\nQaGLPMQvGux4to9HzF+ulgXO0ratZO2eP08isRXimVOWg0mbJ6Hbgm7q/XU6Mse/YoXchV4/kXgk\nKGvXAl27YthgYPBjcgGnIkYFSitnGiBpV6/+9qpqOSvYgNwiD1TAHWOkDKQSewlSC8gLpcCEEbIC\nXumslJ1bFtHusiOnTG15UywmUnjG4XGI1242mNUWuNeFbjVbERYUxufAORzOdYAgAN6yx/ShzUYE\nXxasgC9eDHToAHz0kWqzWVlr8FPqT+r9aVnQPHXjDplVTddrCXhhoXZ9cir6VLQ9Ht8lO72c9BqA\n1MAuCpavP+yNiVNa4GuaAyvVzRm1YV3mFotKwN2KlK0lB5fgh5M/SAsmTQIefRQIDhbrmdsFxQtS\n06ZSgR0oLHAaxOYVKOX5KGcKz2gup1bwp399ip9P/SwT9GJbseY+gMICTyBTAYdyDqH/UilSvbCy\nUPzOWsBUXOnLAjsHnlWa5fMaAKnRicMtCbjJYFJZ4NSFbjVbEW4K5y50DodzHfDZZ6TK1rp1YvEL\nve4KPTJYAf/2W/K5bh35LJYe5i/mLEK/pf18V1Xbto1Yl+vXS8sqKqSo62eeIa5zLQH/4QdAI3UV\nAIlCp7nTbneVAp7hjTGjwWxKAU/1CrwyiG3wY8Bjj3h/sII8mLQYxcyZUvMUttSo1QooKk2y7UcB\nYPi3wzFg2QD1YFkXukY5UTbKu8IteTioiFW6yAuSy+PSDExj64Kz2Fw2nCo4hQk/TUDfr/tekgVO\nRf/JdU9iW7oUVEjnsgF5EFteeZ54bkDuQqf7GHQaeewAYkJJMRm3xy2e12QwqSxwKtgR5giEmbgF\nzuFwrgeWeltK/vKL+KDWu69Qr2NWwGlRFLOZuNIVnZ4AyN28LG+8QT7fkwqOoKJCXt6zVy8SvKZk\n9Wr1ssRE8tmunVSgxOORzSH/2JRYzVp3ggp4cbDGSma9JuxLwr//TV4cXngBuP12sqwKC5y1aF/7\n7TXxe2p+Kt74/Q1JbPV6KYjNoxF/wAo4I55U/NjzKF8aAO2caoBYwf/d/1/N8ZbYS7A3ay9m7pyp\n2k/mQve+RLBtQOta6soC3VgLXFnvnHWhU8Z3Hq85Xjqv7vK4ZBY4FXYlogudW+AcDueaQ4ucGI2S\nBZ6VTdKwLhdWwClZWSS9y4vMWg3y0cPyhLdvM7W43W6SClWPSfUpKJC6ibFc1Ih8ptHcyclAgwbk\ne2KiTFz7DyVWs9LKBgCn94nqq2c2W1tczBWnsFMIdeuq89djYkjRFUDTAmdre7+59U3xe/u57TFt\nyzRsT5faoIoWuEY9cIFJ09IST9Zy1hJEfxb4jowdAICWsS1lx3ELbnT6ohNe+uUlVWCZzAL37hNs\nJDe/d+PeaBzVWOZCL3WUolaItsdEqwNZi9gWeKylusELrZle4ayQ5sCNZuh1erSPa49uifJYA4vZ\ngjBTGA9i43A41wFaAi5AKvV5OWgJ+NGjgLcpCCCJIQDJKhQEYNky9b5UwOn8t8UileWsDjQ6PiGB\nRKx/8AHw9tuaLvRsjeZaLj1Q6ac8lkzYO3eWvgsC8MgjQMOGQPPmqoIqAIigJyeT7woLfG/WXny8\n62Ptc3otQpNBOjkVcKfHqbKiHYIkyloCzr4oaAn46cLTiA6JRuYL8lx6m8smusptLptm5y8AyC2X\nF8zREvDCykLUDquNDcM2ICokCoW2QtHDUGovRVx4HJQ43U7N8YabwrH84eV4uMXDsuVmg1k8J2uB\nA8C+cfuw+EGpnGpYUBiMeiMPYuNwOFeAtDTNkpXVwpeAa6RTVcmuXSQX+YzXOtMScAVOdmqSCvjq\n1cATT6g3NntrlNKo8tBQ0pBESwj9QQuT9OxJ8o1ffplEu2sJuEazQ6cByPHTBLHchyNBtAyr+rs1\nb+49UDnxFnz+ObBzJ2btmoV5++b53g/y+IUy5kVC2ZWLFVaZC92tdqFrCWJOWQ7iLfEIDZJXTLO5\nbCi2F4vHpccJN8lvmFiVTWMMdJ8iWxGigsm0RlRwFFwel/iiUuYoQ52wOlBSaCvUbCFKo82pYFOo\nlc+WXGVfgtgo/DBTmPhZ6arUnFqoCbiAczjXM8XFwJ13yizTgGjSBGjT5vLOzdQJlwk4LfVZHZ5/\nnlQW++QTfLH3C+wrPCpff/fdql1kFrgg4PsT3+Pr46u0j08tb1bADQbt+XSWdu1I21LKzJnA4cOk\nGxiLRmGSMRr9P5x64GKoejmFtcBpkRGAESmdTrs5CIUKOI2eHzcO6NbNbxAYhXVZs+NQpnf5EvBA\nXegOtwPBxmCVgNtddnGcFc4K8Ti06xfFnwudjqHQVihWSqMlT4tsRRAEAaWOUkQER4gCTCmsLPRp\ngQO+BdzpdqoscAAI0ktvY3Rfeix2zDUJF3AO53pmyRIShTxo0NU/NxXwiorLt8C9c8sVjnKM/WEs\nOjo+ka+//37gzTeJG9k79+tgdeziRQxaPgjD3Cu1j68UcDqPG+7HHAbIOX/8kUSpFxQQq7ulRl6X\nRqWzM15NTw6TAuZcVQk4Y4HTaG6gGg/8vn3J5z3ytmaBBE6xljZrgStd2T4tcK/1WpUL3eF2wGQw\nycSOHlcm4N4Xh9ph8rrzYmMTZgwmgwkhxhCZC50KN7XECysLYXPZ4BE8sJgsCAuSB/mdKz6nOQdu\nMRMLXCn4kcGRiAmJgdPjlOWBU1gLnF4rPefVcqNzAedwOIT0dFJU5ZtvSEMPKuBlZZcm4H/+SXpR\nezyiALorfDzYrFZg6lRg5UrRHS5zoZdX8UCkAk4/qcvdojFRzXLffeSzVi3YLaF4fcvrsoAoER8l\nXT/aALSv1UL87TQAeX4EvMxEotcLg4Epm6XI+EAFfHFYGv749Uvy92GPG0DglC8BZy3qC2UXMG3L\nNNlxqet9xo4ZOJl/skoXOhVwnWL6otheLI7B6XGKLx0qAfe60Hdm7MST3z+JdSfXITQoFCaDCXaX\nHXaXHZWuSsmF7rXEC22FYhGXcFO46Nam7M/eL76EsJHkogvdKLfATQYTrMFW/HX+L8zdO1dcRtES\n8Bn3zkDllErVNdUUXMA5HA5p3lG/PjBsGLGCX3xRqoLGCLgOIMvZ8qdOp6oJBgDihp41i6SGeQXc\nleej8hVt1gFIAl6dpxO1vFkXOiBZ4HFxxMqnnDwJHDsmi25fsH8Bpv8+HY+segQq7rmHzIN//bVs\ncZgDsAZLY6/KAvfoSfnS0YOA2X/NloYfgICXO8oxYu0I3LE1Rd5SE5cg4D1uFb+zgvzwyoex6O9F\n4u9ie7HYVhMA2n7eNiAXutL6BtTBafRFSelCpxb4hzs/xIL9pPpcaFAozEYzHG6HmDJGBbxBZAMA\nwK7MXWIOuMVkEccdYY6ADjrsu7BPHC8rsL5c6CaDCWcLzwKQ6rHLXOiGINm2ABASFIJgY7Dq5aWm\n4ALO4dwIXEpTj0A4e5ZEW9PgMlrhDJDys8vL5RY4IO/yddttJDra1xhdLknAC5jKaUYj1jcFNjcE\nscApWha4Lx54gIi/1hw4AFgsOBkNfNo7EkLHDtJ+TZsCt9wiO1SIkYji5jOb1eeJjgby8+F5fIhs\nsckNWEOlefaq5sAB4ka/oPDsByLgf+f87XNdIALOCnWZnikpyghyZok8crzIVoQI5gXF5rIF5EJn\n54cpSgGnVf1iw7QFnK36FxoUCrPBDLvbLhZgoZb3fY3vQ0xoDCZumoiFBxYCIKJMC67EhsUiOToZ\nK4+sFCvTsS8N1IVOLfDaYbUhTBNgNprhgTwYrSoL/GrDBZzDuRG4VAH31QyEMno0KXIyTyOCmbat\nVLrQ2XUA6Zp17hywcaP2OSorRQF3FjC514mJuH8ocM9IaFrgjqoE/P77SRW3kBBJuGnFNXq80FD0\nGQZMaHQc24NztY9DT6twoWqhjNgO8gARoVIjDadBLeC1bHJrrNwEmBW6F4iA78ve53NdtS1wZntW\n2FmrEiACTueatVAKuCAIPi1wZccvKsStardCsDEYep0ewcZgUejZqQy9Ti+60OlyOi6z0YxnOj8D\ngPT/BkhRFVry1O1xo19TEqj4n93/AQBZNTVfFrgW7H8jrIAr79vVggs4h3Oj89VXJCeYihcr9r6a\ngVDotv5yu7UEvFBjnniVjwjx4mIxstpVyJQ0ZeentSzwqp5ONHUsNJS8JDz8MDB0KFnWpAn51OmQ\n7/U2HzCqC7dcrLiImTtnwiN4ZMFbWlHdpfZSvPH7G7JlJjdgDZNSzKgLnU3ZquOSB0dVGgGzogT3\nueJz+GjHR37Tj66kgLNBb/sv7MeXB77EkoNLcKrglGqfQAU8tzwXb219CwIEvy506r6mQtwgsgEK\n/q8ApZNLcWvireJytjxqib1EdKGLFniwlBkwved03JF0h/g7NixWFPAiWxE+6v0RWsRKsQotYqTv\nVIhpEJu/vuXXmwXup+QAh8O54pw8SappNWp0+ccaNYrU7P7gA/J782bSrIKdn3Y4JKHLywO6dwe+\n+EKq8920Kem+VeZHAMrKxAe1ygJnXxBon2olxcVi1zCXw0cLUK058KoscHpdISEkyI0tjdq0KfkU\nBNxyEfgrETimU9dDH7R8EHZk7EBsaKxMwE/mn0Snup1k2z7949P4+pB8DjzIDVhDJSGhFnitkFpi\nj+sYoxWAFHFeGUSEn2XUd6TLVkxoDEa2G6l5uWmF5P7qdXp4BI/4ksA22/AH6ypnBX/MujF+92PL\nliphBbzr/K44W3QWgLag0brkceFxyC3PRYGNuMjNBjNCgshbVlRIFIpsRfAIHll51GJbMeLD41Fs\nL5bmwEPkqX1NajURq83FhMaIVnaRrQg6nQ63xNyCo3kkfbFlbXWmAR0z7WwWFhSGLnW74K8sqWIe\nWzddr9OLfwvuQudw/hdo1gxo3Fhz1Z+Zf8q7RwH+XedffknEO9hr4SnngQHgwAGSY52XByxaRPKH\nqZUK+O6pzVJWJgqEygJno8NPa9fARlGROCaZVe1mVIy1wL3u9ipd6GYzFv+9GMdiQYLwGP4sOoJV\nR1YBgoA63iEecqt7Px+/SPKpS+wlMgFXFhMBoLJOASLE7ByxRwfktk+WRTlHhsqLwFQa1S50Sl6F\nRnc1L3R8HsEjCvDKIyuxKzOwGgG+XOhVoUzHYqECXuGsEMUb0BZw6kKnlvGaY2sAyN3SUcFRECDg\n1V9flXlBKl2VKhc6a4EDQEyIdM9jQmPE81BBZruINY9prhqfMvBMr9OL8+O+tqFWOLfAOZybjZ07\ngZ9+Al5/XV0R7MwZUmubWU77OAvTBNIp6+uvgY4dqz5PaCgRYircbDvNnj3JPPjy5VIuM2uha/XD\nVuJPwFnLPSODWPzvvivVEQfIS8T58wAUzTxYAWcbc3gjw6tyoWeEODFi7QgYu+vg3CJ/0aH3MsN4\nl1ja9JTTOwfO3HOaF2wymGSCocxFBtTz3wCZAzcrLNQ8Wz6So5OlS4utC+QcE39XBqld6BS2uIsS\ndq66sLIQwcZgPPaNuoa3L9hSqIFY7BRlQRYA0EEHAYIo4Puz98vWU0Eb1GwQvjvxHQDJha4sc8rO\nPVN3/Tvb3wEANIxsKNZWNxvlQWxK1z770hQTGqOKK2AFvK6lLpTovM1gxZKsjlLtgEYGo97oc87/\nasAtcA6nprjtNlIoJCNDva5RI+DDD33vO2AAEV0aHa60xNnfNOJamUoFSEFsVquUMsWmfAUi4OXl\ncHjdryoXOivgHg+Jap8+HUhJkZYvXEjqnEMh4GxKFvuC4y3k4suFToeQHuLwHlNxb5o1E7/+NyZD\nbCBiE7zXzVQ6YytssRa4shoYuy2Lya12MZfYS2Q5yMHx9WTrK42AwcdUt7/+1KwLvNBWGFD1NRY6\nflpkxN/cNouWgNProwKu7BNPBW3tkLWonFIpW6cUcFb8lFZ1w6iG4nezwTsHXimPQqcoBZx2E6Ow\noq20rAHJuq5OGVQq+lzAOZybBUEAFiyQfrt9PJTnztVezs4r+6oZzm5Dc4K1LHBKYaFkgTscJOp8\n8eKqC6Q0bAi4XHAsIuk5emOQdDxAEnDavnP/fvhDJsq+vAtaldgYPN6n1jmzxnU++yywaRNaxpI5\nzt8tBYyAe+8ZI+C0sEeQIahKF7pWHW2TW+1idnqcMtHrUrcLAKBZNHmxqAzyfW3+LHB2fIWV1Rdw\nasFT97lS4HwRGhSKEGOIrGY5vWZ6T9j5akAuaGaDWZZWxlrCgDwnWynKXRO6AgCe6/IcIoIjUOYo\nQ1YZeblSudAZAQ8NCkX9SPLf5LiO48h5mchzGj/Qo34PcRkV4+pA3fPchc7h3Cz89BPw5JPSb1/z\n2DnaRU2EffukR0mR/MEIlwuYPRt48EFpGRVwKsZaVvULL0jfHQ5SQxuQd8TSokkT4MwZUXB0JhMA\np2oO3Nm6BebWOYfRu3cgRPtIZPiMycBG+7JBWaIFzpoXJhMAr8VdOxaGC3k4HUSEKNIdRMYEAM89\nByQmitZmRb04VJwmwWs2wQkBgK5VK9l5AbUFzrrQd2bsxLfHv8XJ/JOq6wlyQwzAYmEFvK6lLtyv\nubHuxDo8sOIBVBpJMRct/Fl/Mhe6rRCRtsAsaIpogXsj0KNDo8XAOH+EBoWi/JVynC89j3qz6onL\nAMkCZyPGAbmg6XQ6WM1W5FeSv0OCNUG6pql2vxZ4UkQS3K+5odfp8fbWt/HN0W+w9dxWzflpZZ/u\n0KBQcV8Aqhaj7tfcMtGmFrig2eldG/G/Hz23wDmcm4M8RSASdVkrLXEfkd/OIwelH0oBnzULeOkl\nYAwTOUwtSrqtlgUuOwFjSVZlgXuj1amAC0FBRGAVLvR3WhZgQj/gxbI1/k/NPHFYwZQ11NBwobvC\nJJF0G8n6MwZigcZ5GBdvYiIAKa+6MsSIikaJ4mrHpx+T2ucKjHqj6KIODQqVCfjU36Zixo4Zmtdj\ncqstSoBYqFPvnAoA6Fi3I/Q6vSh6FUGAzYeAB+pCL7IVXbIL/VIscJ1OJ7fAFS50ZflZpUXKBvqx\n90u5ndKtbzVbRQHuEE8K8WSVZiHCHCFL1QPUAg7I0/ma1CKphS90e0FcxwalKefALSYLbk2UKtZp\nQbflLnQO5wbgWN4xdaQ4S2oqcPCgfBkNGmODx/xgr2SEvbhYvpIem86NA9I8d2EhEefFixEwRUU+\no+IBALffDkAScJdBRzp8FRaS/PP+/QEAZ73P3bNO38VSTjeKwgrJ+JUXE3FrCDjzdGIbf7gM5EF7\nRkfuTYjO+/AMDxe9EVTAK5wV8naUT46SeoczuD1u8YWiYWRD7Mnag50ZO2XH0iLIQyxw56tOPN/1\neXF5aFAo3uj1BpyvOpFoJS8Q1FKv9CPgys5gynV0vv3V315VVTarCpWAhwYu4IB8qoB+//SvT+Hy\nuFQWuLISGx23v5Q0QO1CZ+89FXCt7QBtAWepFVILjqkOfNT7I831Sgucjfb3xbV2oXMB53CqQYs5\nLTBg2QDfxR6Sk0lLShZ/Au7SKEX5H6lGtsoCz/U+tNmobVrytLAQ+Mc/SNBYoGRlAXWZiNydO8kx\nKO3bA5CsYZceRMD//hsYKeUre7zj0dt8Rzc3HlGI/3SRftPGE4CiI5bGHLiNCSBzG8j6EwLxdFR6\nvOs6SA940QJ3VcpEQNl5SzymIAl4lwQyyImbJgLwL6omD3noG/VG2UOcWq1ssQ9aqrXy8Udga99a\n83j+BMPutovpT1mlWVh+ZLnPbX3tz56DTbvyBxVwttoYtcB/TP0Rs3bO8utCByThjgqOQqMoUgPh\n5dteVp1L6UK/rd5t4vc64XWQYEnQ3A6QRH1gM40+r16CDEE+65TfmXQnAGDyHZMBkKmGQ7lSb3Za\nc52FutB5JTYO5wZCK6CJsqY58GZ3pt41FW6tnGtF/jIAODLOSj+UFjjtxc0KO61Lfv48aT+q4Gwk\nsPYW1WKJsDCS+rVoEWlAMn++tK4WmTcULXDBTQRfUYnNE0SEigaEL//0KVzokAx/+CrnSSPSWRc6\na7G6jDpcCAeyBPLiUkkFukMHrDyyEueKzoliVe4ol4m2LwF3eVywuWww6Az4YsAXCDGGiKLkL+Uq\nCNIgWbHWitwWLfDWt8Aeov3A35C2AbvP71Ytd3vccHlcqB9ZH98P+R6AOnWrKhxuB5YdWibmsytr\nkPuCbWZCYa8voyTDbxAbe4yokCjEW+Jhm2LD+/e8rzou60KveKVCVj0NkKxwLQtcr9PDPtWONY/6\nn8bxRbOYZrBNsWHi7RNV6ybfMRmnJqjrALAxFNcCLuAcziXgzyob/Bjw2l3AorZ0Yz8WeBaJqGUr\nWskCnKiA5+cDEycSFz0gT02j23hTtZQ0fg54cAiQ66seR1gYMGkSMGIE+a3TAc8/Lwn56tVwGImo\nugSXFHHO4DESIdMLwF8JwOMXP0f3FIEE6rEpZQy0cxQQgAud0Tu3QYd9zLRzZUQoYDAgc9RgPPbN\nY2jw7wbiOqVl6Ovv5va4YXfbEWwMhkFvQKvarVBsI/fVn4CbGAFn3caaAk4tcGel7EWC7UOdVpiG\nLvO7qPal98dsMIsV4mh+dFWMbEs8JVvPbcUTa57ACxvIHHCgLS+13N6sO92gM1Q5B06PQe+B2WjW\ntIRpoNkDtzygGRwoCriGBU7Pa9AH0gVHG1/jCgsK0zwunwPncG5ANB/q5eWy+FWavuRXwL0WdaVT\nmuP1WYHsgw+qDlDTgKZd+TxuqFps8PHHwOjROFt0Fkub2uCII9aaS3ADSUmqzd3eeWmDABR6n7up\nBamk1GuytiXuywJfHZOL7HD5eCtZC9ygFwU8whyBSr0HcLlQEi+PMtaiKguciqnVbBWDxGQvFwpM\nl2KBu4iAt6nTBpVTKlEnTD0nr4TeH7PBjLjwOJno+2Ne/3lYMJCkNCqL0wQq4GwAGoUV8H0X9mFb\n+jaZ9awUNNpzWxl4piTIEISKVyqw6hHtuvpUwAPNYb9cqsrz5nPgHM7lIAjAvn01127TB5oP9bw8\nmdtX/O7PhZ6TA1y8CNs7r4uLqiwheon4vENaAu6lzWdtMHTNUKQaiDXqEjzaFrh3XlonAIYYhTD4\nOD47B07v58Gcg3g4+QC6j5K70CuXSj2q3Xog1avVHet2FOe4qcXsj6oEnJb1jAiOQIm9ROyupexZ\nTQliamOzolqVBW532REaFIpgY7BmURFljIVogXstxIaRDVX7aGExW2DQG2AymMSqc5TLscDZ69t6\nbisAyKLUlYJGrdqq5WYRVwAAIABJREFUBBwgLzrsyxBLt8RusJgsKtd6TWA1W/HePe8BAO5pdI/f\nbbmAcziXwr//TQqCsIVTrgCCIGDF4RU+RUHTFZuTI3P7it+9An668DQ2KnuYZGcDTZvC9rEUGWuv\nIQH3lXssC4hTQEW2REeuwQVtARcYF7p+4CD5yoQE1faAtgVOI6tPRStSzhpJVr/LoBPFvVZILbgF\nN5xup9+0Kmqx+Qtis7vsMgtcgIAyBykj26p2K5RMUh+ftcDZqG4tAafLqAVOz8UKH4V9uQGk+0P3\nYSuUKbnw0gXxO3XrmwwmVYpadEi0pqC2jG2JtY9J3ek0Xegm9X8zbC9xpaCJ3ewCEHB/1A6rjcwX\nMzGhy4TLOk4guDwutKndBgX/V4D28e39bssFnMO5FDZsIJ/bt1/Rw64+thpDVg/ByLXanaE0LfDc\nXL8W+PTjn6P/E4pyoj//DBQVyeZ4a8oCr5YL3Qeu6ChtF7re60Jv0xa6Rx6Vrxw8WB2ZD/kcOBVW\nNhbA0baVaj0AuGNjxHtIXbOVrkq/Ak7nTH25w1UudBMRrRJ7CRxuB8xGs6alzFrgykpgqm0NQTDo\nDKhwVsjORa+BhXYyo9Drp3XDtZpxUNiCJdSS1ep1bTFbNJcb9AaZ21wriE2rwUlKuxTxu1LQaIW5\ny5mfpljN1itynKqocFag79K+AZ2LCziHcynQ4iiGK/s/NG07SLtVKdGcA8/NVVngfyUAO0rJsQod\nxXAYGQE3GIDdJOKYjbKuUsCDqkhZ2bwZ6NpVPeYrIeAGnWSBDxoEbN0KfPopPF4Hvb55C9ihSI3T\n6eSV4Lxo5YGzou6EZDGyMQLuj2fCdUsyDDqDzC1dbJd7S1gRpaLGvgiwbmqaB05FlQpYib0Edpfd\n5wPa0Fm6z1UJOEDcw4FY4FTAfz3zKz744wNZQw8AeLzV4z6vlXU/0/QmrfFHBkf6DMxit9eab1cG\nmD14y4OY13+e+LumLPDrFS7gHM6lQPOor7CA07QYX8Eymi50DQu86xjg9gJSxavcW4xEFHCmoEi1\nBLyhhvuUFeHu3UkHNAXicXv3Bpo3l/Km09OrOKGEy+MiLveCAmDlSuDOO4FnnpE9oAPtdCWbA/fe\nTzYdSSbgbCGXWlFwNW8Go94oc0srLXC20piWgLPjFOfAvRYpdRsX2Yrg9Dh9P6CXLRO/BiTgxhCU\nOcrgFtziubQseyrgA5cNxMRNE/Hu9ncBSJZ0x7odZcLKvgSwUdS+2l0GG4NJxL1OQ8AhyCLqtaKy\nlXXDG0c1luVCK8/3YHNS+nd4m+GqY90McAHncC4FaoEbL7Os/7RpwIoV4k869+1TwJ0a0eDZ2dpz\n4ABw/DjKj5Mqam767KO53PXqyaKsfc5VU5iCJSKsqBuNUuMSdswGYHVzoHzdGuDIEWDsWLLCR5S4\nFqKLOyoKpYJd7OnM1vD2l2LHomWBs2lfDkbAZS50geREG/VGKbLbqSHgoWoBZ8fGFnhxeVxiGhkg\nCTit3+3zAc30MWcD3fxZ4DTlip6LehFYLlZchMvjEuuW09xttnd23st5YllQXz272TlwFjqloGUR\nKy1wLZT1wpVV0JT790/uj9x/5WJE2xF+j3s9odfp0SK2RUBeAy7gHM6lcKVc6G+8AQwZIv4ssmtY\n4EzxEkexvH0iAODMGe05cAB46CFUeIVZtMCpEM+ZUz0LvFMn9TK2/zag6WZf2B54+DFg/PrxxK09\nbhypvDYh8IAgdo764VUPY/DKwdh0epMYIOX0OP2mXbFoWeBsPrEzVhJg1oXu8rgkATdKqVnKgEPW\nAqff2RcB1qqnldhEF7p33jevnFR7o5bvA7c84PN62HljfxY49TLQcynLjgJEwNl7QdubsnPW4aZw\nUTi13PAAMwdulM9100IoWi50j+DxWVmM5pQr+2krBVxr/0ALx1wvhJvCcWT8EZ/3loULOIdzKVAX\n+uVa4ApkLnS3G9i2TaxKBgD2+XOBQ1KZRTidQFqabwvc4UC59/9xUcAXLwb++APo108dxOaj3CMA\ngOmmJRIn77GsZYHv8T5zD+Ywtdq7davWvat0VYppQ7+k/QKA9IKm7mi7y65yoe/M2ImzRWdVx9IK\nYmMt8B8s2ar1gFSVrDoWOC2DSY9zMOegWOsc0M4DB4C8CiLg9AG98uGV+OFx7Vr4rKXmS8DZRin0\nXFRk28W1w67RuwAAM3bMwLnic6r9lfPR9AUm3BSO0smlKJ0sj173NQdOX0y1XOgeweNTkOYPnI+L\nL19URaZXZYHfiDjcDszfNz+gKSGt+3g14O1EOTcGmZmkalkXRZWqK+FC96hbOFLrJ8QYQtKgFK0/\n7Zt+BuZuJp3GCgqAaCIWTqYmh8wCDwoSC7uIAt6ggWg5sxa43QAiwA6Hdn67VaMhRHAwqZzm7cZF\nLXA38x6Q59WUqhpKVEWPL3ugbLLk/hYEQRRGh9uhcqHf9t/boAU7302tdnZZRolUbY4VcC0LvMJZ\ngRKH7zlwmnZlc9ngdDvR9vO2sm1tLhs8gke0VOk9onPRVJCCDEGoE1514RVfAp5gTcD+C6QEKrWm\nqYAbdAa0rE36mF8ou4A5u+eo9lda0mwgnJal6MuFTl3umkFs8O1CN+qNiA6NRnK0fNrlZhRwm8uG\nMevG4NGWj1Z5PdcqOI9b4Jwbg3r1SGS1UtAuJYhNEOTHYdprXii7gJ9SfxKFxOVxavbtthuY/ZjO\nYL4scE/6OZR7Bdyt8X+dpgs92Ee1rbAwkprFXrPZDIweDdx3H/nttcBZy/5igAKeVpCGfdn7/G7D\n1oIvtBWKLm6H2yFzodP0IS3YvGG7y44zhWewPnW95rZKd7fT45Rb4F4XOpuSxUZj148gkfNrT6zF\nssNS4Bml3EHmmpVR6NQCZ13XWi5vJb4EfOlDS8X5+BP5J8jxvFayy+NCuCkc6x5fBwDi34C9DmXa\nF73+Kl3oiv3oOanlOPXOqfjXrf8CQCxwf33JASA5OhnZL0keEmUg3s0g4NWBCziHEwhORRORS5kD\n79tXrLetPGbnLzqj39J+YtqOq1S7kItsnpopb+oMlR6UsmYczkq1Bc4eQingguBfwFetIi8v4d4H\nt1mRz+u1wCsYrXF5x1OVgDf5pAk6zuvodxsqeADxVrAWOOty9Dcfnl6cLtuu+5fdVQVMKFXOgXtd\n6FazFaPajQIANItuJu5DBW57+nbN3H4q1PQFgM6B55SRlzdWkPx1nqL52b5E3mK2YPlg0kWMdr+i\nIkvjC7omkNQ02gmrTZ024v6+LHCtwirsWJUvFKLV77XAw03hGNBsAAASKU5d7Pc2utfXpSIuPA4D\nksk+tEsY5X9NwH11OKtpuAudc2PhcMjnd6mAu31beiJbtwItWkjFX9xuIvyMgLNWIQC4ijSC1eCN\nFI/0BriVSK5bZ7fOAEhRGdYCLzZLNcm1BNymjEIXBClo7tlnyb9bvC3FQkOlOfKICKCsTC3g3ntU\noaEj/qziQKFR0QBxe1MBt7vtMhe6r8pngNyqtrvsqnvPUuUcuEsS8Ln95+LNXm+SWuxeqqodvidr\nDwCgdW3S5pPOn9P5apmA+7HA94zdg3JHud8H+r2N70X6P9MRbyEF3ZUCHh0aDaPeKP5uXbu1aI0r\nLWnRhR7k3wJPikjSXE4tR7fgRvf63ZH+z3QkWBOg1+mR/VK2z6YhlFWPrEJBZYGqt/jNIOAGnQG9\nG/cOaH6bW+AcTiA4mICS4mKgtFS9HCB9sy9IJSUxaRLQowfw5pvSsooKUkd9/Hifp3MVSUFVrPPe\nboAk4HQMM2bA2f0OaajM//f5jAGkaYErg9hYF/+tt5KmIBS29GmEN/JZ2VdcwwKn+Os5HShphWni\n90JboSjGShe6r1K0ytQpu9uuWfGLIssDZyxwOpdb7ihHka0IEcERCDIEIcGaIDtHVQJOxb5jXeJ5\nCA0KRYgxRIz+DtQCDw0KDSjaul5EPVFEu9fvDgAY0opkQeh1esSFS0GJ7eLa+bwONohNC/qyQXtw\nU9h5d0BKA6wXUU8Uo7jwOJXFr8RsNIsvIiw3g4CHmcKwYdgGn94NFi7gHA5FEEhvay1YoY6MlNpq\nKl3rdeoA8cyDZZG3GUaaJDwoKyN11Jcv9zkUV4kk4Ozctd0IIMprnVALvHVrOA2S5cW60AsYvXJr\nGGfKOfD8EAE76nkX3HqrXLS1BLxI3o/ZnwVOc4svB1aYt6dvx4Uy8rKkdKEr+0RT6kXUk/0utZei\n2F6M7vW745nOz6i2X3tcqs3N5oFTV2+RrQj5lfmyYCp2nr4qIQKI2LWMbSn+jg2LFWuzs/sHMgde\nHXo26Ikzz5/Bq91fFZfFh0v/7d7d8G7xu78gNi2oUPsScPp5JbwyWse/kbG77Ji+ZXpAdQ2UhW2u\nFlzAOdcfM2aQaOrfflOv02rJCagtcCXlGqJVVrUl6syTAthYl7jDACnXmlrgViucRp3m9qyAu/SQ\nVWED1AJ+W4obt48GssNBItXZaQN2vp8KeImiDrgfC5ydv/aHv0AmNmXr2MVj0tgVUeg+BdwqF3Ca\nMtW2TltNlyWbXsa60KmApxenw+F2yASc5io/1vKxgNpvNotpJhNI9liBWuCXSoPIBrKIcGrVWkwW\ntKotpQ0qXegJ1gTooEP9SHWDGXasyu5l/Zr0AyDNgSsbnVwq1FsQaLvT6xm7247Xf3/dbxxHv6bk\nPtI0xatNjQt4amoqbrvtNiQnJ6Nz5844cuSI5naHDh1Cz5490bx5czRv3hxr1qwR1y1YsABNmzZF\n48aNMWbMGDiV1hbn5uLrr8nn5s3qdVSoldHo/v6bcLslkS1lgqQCEHBXMVNYhNEVuwFSe1AqnhaL\nXMB9WOCuWR8BBw7IzuNQHPukd0qxZMvP/nPCqYAXK1zVV8AC9zd/raw7TrG77LIHni8BV87J0peA\n+PB4MZCtU91O+Pz+z1X7si50WpCEusBjQiTRbRTVCKefO42vHvxKs2mHEmVTEZ8CfoUtcC2o5d+r\nYS/ZfLry5aFJrSZInZCKYW2GaR5HywI/8ewJDG0zFIDkQr9SFvj2UduR+ULmTSHggbDm0TU48ewJ\nv93hapIaF/Bx48Zh7NixOHnyJCZOnIiUlBTVNhUVFRg0aBDeeustHDt2DIcPH8add5IIzTNnzuDV\nV1/Ftm3bcOrUKeTk5GDevHmqY3BuImhOt5YoUwFXWtz+LHBWtFmhC0TAfaSF2Y2QBJy1wA3aFng+\nK+BdOqkKr9i7dRa/s2JeGi8PDlJBm4Q8/7x8udcCL6+mBc5WWvO3na+5beUcOGs5sygtcFroJd4S\nj54NegIARrcfjQSruhUp60K3mq3QQScJuCIfuWFUQ5gMJlW+s5bAKOdtr6YFroRGfz/flfxd+zTp\nA0C7M1jjWo19uqzpywZ90akTVkeWwz24+WAAwG31tHP1q0uYKUzzb3azYjaaVTnxV5MaFfDc3Fzs\n2bMHw4aRt8PBgwcjIyMDp06dkm23dOlSdOvWDXfcQQKADAYDYmNJIMg333yDgQMHIi4uDjqdDk89\n9RSWLVPncXJuIqi7WEuU164lPbQrFbXIfVngCxfK59OzpdzVgAW8WzdyCkYDHAl1tC1wH6VU2SA2\nt1H9v52jXWvpO7OfsrrY/jhFq0maG9+rl/yA3peg6lrgrGj7SukCoCqaQgl0Drx2WG3N5fHh8Rje\nZjiOjD+CcR3HaQoTa4HrdXpEBkeKEez+AsgyXsgQXclac8bK+WXWmq9uHvjlMuXOKTj+zHHc1fAu\nAMDax9YidUJqtcWRfdk4/+J5HHvmmGz9lO5TcOyZY7g/+f7LH/RNRpA+CKPbj74qf+9LpUYFPCMj\nA/Hx8TB6HyY6nQ5JSUlIV3Q/Onr0KMxmM/r374927dphxIgRyMsjeZnp6emoX1+a32nQoIFqf8rM\nmTORmJgo/isL4AHNuQ6hc8taojx1KqkFrhRwVuzZiOx//ENevS03V/quNS+uwGXQic0+ZBZ4kEEa\nA7XALRafhVxkLnSPImIcgMMjjZ+NSGct3ZzlC9DhKaD34t5Vjpu63UuaJKpW+bOsWXH3F63uywJX\nppH5EnBfQlvXUhc6nQ4tYltAp9NpCjg7Bw7I69UrLXCWRGsi/tH+HwCkuUsWpZu9KgucjRS/0piN\nZjSLaSb73aRWk2ofh71/dS11RUucotfpcUvMLZc+0JuYkKAQzB84X9U69Xriughic7lc2LRpE+bO\nnYv9+/cjISEBTz/9dLWP8+KLLyIzM1P8Fx5edRF6znWIPwscICVVbYr5Wa/Y78rchcqSfPm6igpo\nEsALXk6UCYet5FyyOfAgndwCDw39f/bOPL6K+tz/nzl7crICAQJJ2ELCqhClVcQiVMEVFVywxCtI\nAEtd7qVVrK2XxdrS21Z79RaJBPlV4bb1ElTcwBXFigVERFBkkZAEgmxZT5Kzzfz+mDNzZubMnC1n\nzpI879crr5xZzzchzOd8nu/zfR7AZAorC11NwKWid0oyFSt14Psu4d2XUIozJK2tqFlwe8DuDk+H\n6pznzrqdaGj1RyiktcqVCOPaOX8njj90HEceOIKrh14dEELXFHBJ5y6hMhmAgCVJoRw4AJkoBRNw\nAHjsysew/779mDN2TsCxcEPoBsaAb+//NsDNJiPdIRs8UXS4O1CxpUJWRCjZ0FXACwsL0dDQAI/P\nEXEch9raWhQVyRNYioqKMGXKFAwcOBAMw6C8vByfffaZeOzECX9R/5qamoDriW5GMAcuoOLAP637\nFJevuxz3vnVfeO/Tqi1QAvt6OTG2z8twmJUOnOGvLy8Hzp8HMnnVdRv8yXVaDlxNPF1el7iW9IRk\nmlMm4Kf5xDetMp0BZGTgeIs8WiXM/UpbaQLAFw1fYOILE3HT324S9wUNofvGlZ+Rj8E5g1Hcqxi5\ntlyxKYjAhQ71QjhS0RbE3Gwwy+qXC/uUSOfAAciKjYQScANjwNh+Y8MKoUujBMpjJb1LNFvNJgNC\ntb1ErU/uDrhZN9Z9sU62HDHZ0PVft2/fvigrK8OGDRsAANXV1SgoKEBxsTwUdMcdd2D37t1o8c0l\nvvXWW7j4Yr7ZwKxZs7BlyxacPn0aHMdhzZo1mC1p+0ikBu3udvyz9p/hnRwsiU1AZQ78m7O8I9pS\ns031Eq5XLj4eJFmHLS30EgKXUTEHLsxjb9wI7NolNhhxGfilVza3Yg68r18wVEPoXhdsJhtMBhNO\n5PpdvFTA957mq3FJQ6lfnv4yYJ5cyneN38lETQj7KufBq/ZWAfBXHgOA7TXbNe8rvKc0vCiInLSO\nupaAS12zMB/eP6N/QAWzWDtwAWXGORAYQpcuDUq1wiTHHzqeEhEComvo/vGssrISlZWVKCkpwapV\nq7B+/XoAQEVFBbZs2QKAd9mPPfYYJk6ciIsuuggffPAB1qzhl48MHToUK1aswBVXXIHi4mLk5eVh\n0aJFeg+biDHlm8sxaf0kWQtHTYQQeoQCLqxlNWq4ji0TsjB5HvALYQq5Xrt0pxKWUclClyI6cH4z\n3a1w4Pl+t6Yl4BajBRajBU6j38VLl2t99T1fG5vzLaE71XoK4yrHBZ0TP950XDbH2c/Orz+XzoNz\nHIeXv3454Nrf//P3mvcVxiWtdmYx8P9uUtHWEnCpexUEXK2iF4fAbmzKOXCpAw/XFas6cIWAS9dO\np5qA90rrRXPbPQDdJ0hKS0uxc2fgQ7uqqkq2fffdd+Puu+9WvceCBQuwYMECXcZHxIEXXsBbJ98E\nwJfgvLzw8oBTWp2tqGupw6i8UaIDr0cL0FKPgqzARKyAOXCXSyw80upx4EBfYMwZ+Sm7BvH3/fPl\nwFPbgIMXDmGIGXBY+OVWQ9SnawHw2egB68ClCALO8IKT7gZa7SaA48VaKmRSAa9pqoHNZIPT64TF\naAkIr0vd9clWPpteSC47387P9f/r5L+w7/Q+ZFmzYDfbxXaXjR2NaOpsQnGvYnxSy9dnV3PgJ5pP\n4Fz7OVxWcBk+q/9M+5cgQRiD1IGrLa/SEnCpAxZC6NLqYwJq0QWlAxey8icMmBB2yFjZPQsIFGlp\nmD/VBJzoOlajFcsmLwurhkCioAkSQl/q6/k2l76ENE6tvzWAqS9OxejVo/mSnL6cicJRW1H4dKHq\n+WoOXJo1PXYx8K1iCfXBXn5xfHcYMPbSXbh+DtDvYWDovwf/MTwGlUpsUnzLHqUC7ub8Qi2dc5ZW\nvRry30OQ/6d8uLwuWI3WgPXKgoA5XA7xtTA3LRW38ZXjMeyZYcj/k18EhX7aQitNQN2BCyHv20be\npvnzA4FrkE0GkyzELdQNl6Il4NJQuejAVQRcbZ+wTE14b6FS2cMTHw46finCBwhpQRnlPLd0jMn8\nECf0wWqyYvlVy8Mqw5soSMAJffEJt0/XwHndwG23Ae++KztN6AbV1NkUuiwq4BfwtWvhGFmMQ9ZW\nNHbIi4b8dZz8kr02/3EhUezjweH9GG7FHPh75lq0SP9f+5qNuBk+CpAeJPovOHDpBw4hhK50kEKo\nWjo3LWSHq2V4S0POwocGabhYmC+WRgEEAf/xUH/NbTX+OO2P+M2U34jbyoYkB84cCLhGS8ClCMli\naiH0sf3GYu9CeW9yIUlOEPBfTvoldlXswu2jAzPutbCarPjmZ99g3yJ/RbxgIp2odpFE4nC4HJi+\nYXrYpYcTAQk4ERfEx9/xGqC6GpimPm9rMpgC6p2r1uT+4AP+e79+mDHlNEZedwz7z+yXnfKqMAXY\npw+abEAd1Ncui+8T5BmtdOAA8J/S2ilRCPjxxuPiPqeHD6Er64ALLlu6vMvpdcLtdWtWOZPeE5AL\nkzBfLI0C7G3YC4vRImvkoUaaKU02/aHMhp9UNEl5iewDxW2j1B3+sNxhAIDhvYarHh+fP162LSxT\nEwQ8zZyGCQMnBFwXihF9RsgS4NTC5FcUXgEAYtczoufg5bx459g7MasTrwck4IS+KNw0ZwreW9fL\negMEvPl6FWdYWcl/t9nwQV/eyX69T+7qGwTj+c03+P4DPmEyx2fcHTmBS7E6gmSEuCVz4A/b+Q8f\nn0mm5g/1YtHp6YTb9589lIC7vC68cugVcZ/L64LVpB1CFxy4EPqtb6mXZXurIThVaQgw25YtjgHg\npzQ+b/gcF/W7KGSJUJPBJFvWpSxw8dwNz2HrnK2q1754y4t46daXVI9dNfgq7Ji3A3eMviPo+wsI\nH0xivcZZLVS6tXwrPl/4ecJqXRNEMEjACX3xCbiwPJrVmAMXcLPuANE/u3u79gVpfhFpglz4m9J8\nrrlPH5wbyCckDeR4VW/NCayu1BSk/4LUgY+1FGA6Mxxf9uP3H8sFRl5YiTs33Qm3l1fu9B9eoXkv\nL+vFQ28/hGXbl4n7hBC60oGfdfAVCQUHLtRdHv7scDz92dOq9xciFoJTlTpwwWUKAn6q9RTOOM7g\nkny+D7bgONUwGUwyl6oModstdkwbph5ZuXLQlQH1x4U5dbPRjElFkwI+vEgZlTdKfK0MoccKtRB6\nhiUDZfllMX0fgogVJOCEvvjctDAHHnRpGMALoMKBnwtWt0Qq4CoCLBRQETKVB4zhQ8Bt2YE3DSXg\nX/oqZ5phQJm3LzrNwDd9gNM+p7/l2y1i0Yf0/hrJd+Dnptd8Lu+yJQq4RMRG5Y1CQ1sDzjrOigli\nw3vzYeZgYT2hzKkYQpc4S0H0PKwH3zV+hx21OwBAFKm357wtNtAAgBtLbhRfm41mmUtXKzHJMAy+\n+dk3OLnkpEzgBXE88sARcX3ykQeOYP99+8MS4n/e+0/8bRbfA0EZQo8VyZysRMQfm8mGtTetTerO\naiTghL4oQ+ju4AlqLq8r4JpwBZxV+WsWrhUEXFiS1pYV+LAOJuBbi4FlvjlvM2fEJU7e0X88CJAs\n2/Y7cJP2oD868ZFs2262i8vIpElslw64FAA/Ry1klJf0Ct35SEhuE4RO+gASHH5dcx2GPTMMd1Xf\nBYDvww3wy6ukLvyG4f4mFwEhdJN6jegRfUZgQOYA2C3+eWNBHIt7FYvrk/PseRjbb6zqPZTk2HLE\n34deDpyWihFSLEYLKsoqkvrvggSc6DqnTvk7cvk4cv6IbD5byA8LJeBuNtCBn84AjvbSuMAW/NOx\nUsAHZvL1xFvtgfO9jUF6FnzVz//azBgxva0/MpzAC+PlHb9EBx6k3OnpNr4C3NPTn0ZhViHcrNu/\njEwSQp8wgE/M+vO//ozdp3ZjSM4Q1QYa75S/I9tuaGvAd43fyZLYjj14DEceOCKK3mcn5eu9pWVD\npS5bmrxlNpjlIfQQTR6k2e+xWIYljF03B05LxQgJba42jF49OmhTn0RDAk50nYEDgVH+OcoPj3+I\nkv8pwa8/+HVACJ1ThtC//x7I9q8vFkLo0pnyRTcBwx8E9gxQee80dRHJ9H0GUAr4gEz+Jm22wD/9\nYA68t6R0uBkGZMz+N8w+AOwdAHwl6YwZTMAFcRaWVo3sMxI/LPghXF4XOj2dASH0svwyGBkjth7d\niqMXjqIsv0y1AMk1w66Rbc/8x0wMe2YYDp07BIB3v0Nzh6K4V7EoekJddQFpYRWpy5aKsMlgkol7\nqJrsUvGPRXha+P3pNgdOIXRCAsux+Prs1+qrYJIEEvAezJHzR8SQb9Swvj9uSc9tYV5186HN/nXg\nvmOcb/toL4BjWeDtt2XuXUhic6vkMx1SK3OtIeADfH04zj3xKP+9w+fAff2U26yBa8Yan3hM9V6A\nvHCLmTMAkybhB8v4TPh9t/uXTwlrRtXcqdBg4nzHeXFbCG+zHBuQxJZlzcJ7//aeuD2u/zjNsLWU\n7x3fAwA+qeOrr0mdpSB6+7+XL7mTCrXUZQcIeBghdAEhhG5kjDERW+HDjV5Z6MkcKiUINUjAeygH\nzxxEyf+U4O5X1MvXho1K0RXZ+uMAB+7CxrG8o37+s/8B6urkt/O6AKcTrvRAN5TlDNilGUKf9uOF\nAIBzebwAnWsq9LOYAAAgAElEQVQ/B4vRIja7aDMGJoE1euWhMkYSBmiTPNvNkyYDAIbkDgUAHJQM\nrL6lPkDoBIQlXIIDz7JmwWb0j1+5jMzAGHDV4Ktw1xj/PLXwIUCaXKbF56c+F+8roCZ6RsYomyeX\nhdAl89hmY2QhdMGBx8rZCmOPZxY6QSQzJOA9lG/PfwsA+MfBf3TtRsqa5JAsXzJZAZcLJ7IlzT88\nbnzoW1Jb/XU18OWX8Ej+CoUQunvMKCixBvYAAazyh+694+7FWz95C7+Y8isAvHC3u9ux9ehW9Env\nIz6kW7nAcTd55BWXjJzfpUsF3JHFi91Qn4BLK5DVNtfCbDCrrqkWRF0IyWXbsmXiZjHIk9gEN77+\n5vXYMnsLbiy5EVcPvRqv3/U6qu+oxoGfHsCRB44AAGoeqsGaG+SZ7UI4X82BS8mwZMgqjUk/fEjD\n4MoQeo41eOMQQfxjJYzC7+Pw+cPieGIJhdAJKenmdGydszX89r0JgLq991CU642jxhloiwUHbjPZ\n0NTRiMH/4T/Gul2w+0y7o7MV+KJeVkDF7XHyIfQBkqwxHwH1xwFAUeIy05qJ64Zfhw43X7HlTPsZ\nLNm2BB7WgwGZA0QH2WYKnNdq8igcOMMAvtl4qYALYeXCrEIYGAM6PP667Oc7ziPLmqXqwJV9haUh\ndAABIXTBjVtNVtxU6u/TLbjv0X39ldMG5QzC1CFTA94TkGehq4mecl5dKtLBQujSKmZq6OXAhaI2\nFEIn9MRkMGF68fREDyMo5MB7KOF2bQqJioCLFcCMVpzrPC875nY7YffpmOPCaeC772RZ3K5jhwGv\nF25r4MNZKeAXnv5tQIaoIFZp5jRkWbNwuu00vmv8DgDwwowXRDFpcwfWN1YKuMHkH5jD92xfPnk5\nfjToRwB4oSvMClzvreXAhSYcAMCAQYYlQyauyhB6pB+ytKqFSQVUrViKsrWmVMhkIXTFzxWqdafg\nlCcPmhz0vHBRjp1C6ISetDhbkPW7LNWOeMkCCXgPJWYCHiKEzrnkrtMjceBtF04DRiPan/RXJHOv\n4F+7Qgl4aSmutGzAgtflbWaliVX5GfloaG3AufZzGJIzBGP7jfWH0H0NQaQ0uuS10qW/I4dPt24e\ncbPsHDXRtJqsqg5cKuCZ1kwYGENYDjxcTAaTrDe2OJ4QIXRpBjoQIoQudeAq7yVF6PS18JKFIUYe\nHsqxUwid0Buh81+yQgLeQ4lUHDRRC6FLCoiwLvlxj0fiwE0cMGgQ2mf7m1wI2edui7aAewzA92ks\naptr8dX3X8nOkQpifmY+Gtp4AReS1wR3KYxRyoHzh2TbUgEXQuhKl6a2Lru0d6mquEgz/oVkNGWZ\nU2USW6SodfQKmcSm+FuQumxlcpv03FAh9Odveh7byrdphvYjRRmRIAdO9HRIwHso8QqhBwq4CxnC\nHLgFQF4e2iVzyEK9cTUBFxLhfnY90P+WI2hztQX0oJYKzoDMAWjqbEJdS50o4MFclrDUTECa2CUK\nuOL6PmmBa9suyb9EJnSCyEs7ZgkCrnTgaklskXB98fUB+0I5cCXSELr0fOW1oULofe19NWujR4Py\n/dWiHF2B5sCJVIMEvIeiawjdl8RmNprhcSsF3A2LbwWXwwxewN3+KimCy3ap6Ixw7PlL/fuULTWl\nS5vyM/xuVBTwCFxWOA5cuK+U8fnjZeL7kzE/weY7NmPtTWvFfUIjD9kcuKISWzRRkt9d/Tv8fdbf\n8YvLf+G/bwgHrkQqjNIPMcprQ4XQYw3DMNh+z3bN8XQVCqETUuxmOw789EBSt5IlAe+hxMOBe1gP\nXO4O2TG31yVWWWMNCBBw92i+Tra7yV+tTMB10WjgUol6qyALoasIeCQui/F3MUenT9MCHLhEwMf3\n5/tWj+07ViYuRoMRt468VRRtQNuBdyWJDeBF7c4xd8rcsfTfOiwB12grqnS8oULoejB5sD8hjkLo\nhJ4YGAMKswtj96zUgeQdGaErsfij/L7t+6Bz4G6vG26lA/e6wElXfikFPDsDF9IA1/kzAICKsgo8\n8onvvmNHAZODZzQr58AFBKE1GUwyYVby7HXPiq8ZJvA8ZWciqYC/NectvH7X6xjbb6zqXLZ0nzgH\nblLMgXfRgQuolVwF1EVP+fvQ+pATaQhdb2gZGaEnra5WZK/KTupENhLwHgoXoi93KNZ/sR79/9Qf\nfz/tL/UJLx8bF8qJur8/Bdfm/5Nd5/G6wZklD16FgO/OakXvpcB/DuALzViNVtztq/rpMrDie2gh\nzUIXGpcAQF4636yDYZigodK54+aKr9UccLAQev+M/uIabem1goBLBUfNgatVYosW5dIwgXBcvdbc\nslIwwynrqick4ERPhwS8hxKsn3Q4VH9TDQDY2vy5f6evrKqwNtu1859iUpqAx+sBa5EIRF6eLCP8\nfVM9AODD/nzo3Ww0i3PmLgMXUsClgvjDgh+Kr3un9xZfqz2oFzcU4tDPDslEQSmgDJgA0VCbAweg\neh/pPmH+ONZJbALKpWFq49JCM4Su2K8WoYgnsRLww/cfxmuzX9P8uQkiWSEB76F0tcOO8AHA6JU4\neV84vbWVz+Z2GwOLr/AOXC7g0uVVnaw85G42mMUSqk7WDc6rVk/VjzSJzWayoSy/DIA83Ks21znt\n359FaR/58i+lQFlN1oB9WgKuGkKXCLIwnlgnsQloOXA10RvTd4xsO1wH3l0Y3ns4ZpTOSPQwCCJi\nuuf/SCIkXja0A+c4DsebjqN3Wm+xEYfyegMr+SDgdAIOB18kxcQvCVMKuJt1yxw4ZzLJSox6WLlA\nyxw460YrG5j1LkU5R/3Bv32Azd9sxpTBU8R9aiF0YZ9UQJVzw2rCryngKiF0qbsWEsCk9yzpXdLl\nJDaBcObAH/jBA7gk/xLcOeZO2TlazloYz66KXQl132aDGW7WLSthSxCxJtOSieZHmzWjWckAOfAe\nSjgO/KX9L2HYM8NQ9OeigDlzLQfubjwnrtd2GxHQFtTj9cjmwF0jioO2NLUYLbD4hMPldeGcPbhw\nKAU825aNeePnyQRHLYQuXCc9TxlCDyb8StQcuPTeaiH00X1Hqwp/NITjwC1GC+4Zd0/A70wLYfwT\nBk7ApQOCrwbQE6G5hJBrQRB6wHIs6prrqB84kXyE80d5vPE4AL4mcLu7HRzHiXWBBadsUgj4hTMn\nxE2XWgi9pUkWQm/tkyUrMarEbDDDwvCi42LdOLcoePvTcBKr1Jy02j6lgGoJ3Qf/9gH23yfvrx1s\nLh3wO/Bgy8i6IuDhzIEHK4Ty3t3v4eDig1G/v54I9dmlyY8EEWscbgfGPDcGDpW+CckCCXgPJWQS\n24UL6NiwXtxscbZgybYlyF6VjeONx8UQutEr+SDgcuHceX9/b7cBgUlsBoB1+kOfLc6WgC5dUsxG\nM6y+mR4n68L3bPAlHeG4SdVwuUpIWNrtC9BeJzxlyBSM7TdWti+UkxYcuBANELLSped2JUwdjgMP\nlrT146E/xqi8wJauycAl+ZcAAHql9UrwSAgisZCA91BCOvCNG9Fx0u+mm//+//Dnf/0ZAPDVma80\nQ+jnLpwUN1WT2IYOAneVfz66rrkuZAjdbPA78K/OfKV5LhCmgPuEWBpKV4sCrL95PX515a/810VQ\nqSuUkxaS2IbkDsHGmRvx9eKv+eti1OZVaw5cOq5YlyKNFxtnbsTam9bi7ouDR2MIortDAt5DCZnE\n1r8/OiTP95YVj4mvzV7/9SavPIntXHODuOlSmQN3/+BScFf5i7F81/hdyBA6s/kVmFkGrvx+2Nuw\nN+iwpVnoWgjCbTaaxY5Zao61n70fHvrhQ+J2JJW6ZNnkKqIsrWL2k7E/wcAsfs16rJrMaE0lBKtt\nnipkWjNRUVaR1BWyiO5BMiewAZSF3mNRc+Acx4HlWBj//g+guhodkr+OFol2mW66GZ5H+LKhRo9C\nwNu+FzfVstA9rEf23t81fhcyhI4pk2DZmQ6ngcX+hs9lx/tn9MfpttPidjgiKzhpi9GCnfN34v3v\n3heXm0kxMAaZyEXiwEPOgWvUEY+VA2cYBm/c9QYG5QzSHBeteyYIbbKsWWj5ZfL2AgfIgfdY1AT8\nxS9fhOkJE3Y/PAfYvFnmwJulAs76rzfskThipxNn2/k14BaPRgid9cgy2o83HQ8aQhfCvFaTFWfb\nz6KmqQalvUvF40Nzh8rOD8fBCmF2s8GMAZkDNEOxDMPIRC4iBx4ihK4lnrEScAC4oeSGgDXe0rGk\nagidIOKBh/Vg29FtAUtbkwkS8B6KWhLbs7v4OuD/58vd0nLgZhbw+v6ojdLVZU4nzjn5JiQDWn1J\nbNN+LHsPNQceLIQuhLstRgtqmmoAAMW9isXjd425C3+e/mfN69UQmpwIGfXBiNaBR7scLJ5h4XAd\n+If3fIjX73pd59EQRHLR7m7HtRuvTerVDiTgPRT2RE3APiETWhDrdukcuMKBe5yd4muRgwdx7vCX\nAID8Nt8ysovkmdwe1gMOftU/fP4wOr38vdTWZwsiYzFacKHD9+Egc4B4PNOSiYcueyjgumAMyRkC\nAGEtD5EKeLjrpYHQDjyc6/QmXAd+1eCrxBrvBEEkDzQH3kNh//Nx4Bbfxh//CFy4gMyL+ISNVp+O\nykLoEu1iOMDr4JdzGaUC/thjOFcOpLuALKevkItNLspu1i2G0KcNm4Z3jr2DNw6/AYDvv6t042II\nXRK+lrYJFUR/5/ydaOpsCutnV4bdgyF10pGE0LXmwN+9+92gTTNiGUIPRaomsREEwUP/g3siLAuv\ndInxww8DADKr5wAAWn061WHiM87dRqCluAAA32iEYwCvywkYFSF0AOfSgd4dgMXrS2Jj5HPt0hB6\nxfgKvHvsXdFZp5vT0djZKDtf6sAFpA5cOH5ZwWVh//hDcoeEfa50LXYsQuhXD706+HXxdOCUxEYQ\nmhgYA0bljUrq1Q7JOzIiKF1KrOjoAKtSI0QZQu8wA/34xmJoKuwrnscyfFMSQOHAATTagN7tvPC7\nTPzabeW4hRD6oJxB4npoBoxqiFo6By4gE/AoErEiceBS+qSp1z1XI+oQehwdOCWxEYQ2GZYMHFx8\nULMoUjJAAp6CPPLuIzA/YRada8S0t8Or8i+f6ftDPZ8GMMuBI72Bfr5p4nXwZ5uzDOD1CThTVgYU\n+5PKGtOA3E4+0Q0AOtzyhhPSLHQDYxDXbVuMFtXEOkFktAQ8mh7OvdN6hz5JhfzM/NAn+ehOSWwE\n0RNxeV2o2lsVNMk20ZCApyB/+PQPAIBvz30b3Q0cDlUHnmngxfRklmSfM/A8lgFYXyEX9o7bgf/9\nX3F/kw3IGTle7CCmTBSThtClrttsNItZ5rKlTkb/MjIBtRB6JDAMg1fufAUfz/1Y9fjWOVvx8m0v\nB+yXzr2HItQ6cC3iGUKnOXCC0KbT04kFry9Apyd4B8REQgLezfjHgX+AWcHgm7PfaJ+kEHDhdRrL\ni0ejpIhXmkqknmUAr0+EWQZAL74mdYuVnx/PtWTBrCHg+7/fj8c+4Ku6GRiDbE22wKJLFomvlSF0\nm8km6+0dbRj4lhG34MpBV6oem148HbePvj1gf0QOXNoWNAJRphA6QRDhQgLezXji4ycAABv2b9A+\nyeGQJbF5fH8FnCvQbqe5gU3/kO9jGf81LMcCQ/k55SbfFHauNUcMoQdbQ8kwjFjy02K0YFv5Nrx8\n28uyHtvC/JMg4H3S+8jC5vEMA0fiwKMNoVMSG0EQ4UIxtBRGrVtVnj0POAuc81VEU6W9XebAPQY+\na1xVwD3ArG+ANIMVHSx/nGUgzqGzHAswDGAyodHG2/Xc9F5wCg48SM9mZQh92rBpAIBP6z4FIHfi\nwnl56XkykYtmDjxaonXglMRGEKmHkTFi2rBpcf0/GSkk4N2MvPQ8AMDZ9rPaJzkcsiQ2oeUn5wwU\ncKsvhB4g4L4PAGJVtenT0fj1mwCA3ILhuGBLB9AetFiKVgh96aSlyLHl4OErHhb3LblsCbKt2bh1\nxK2ye8RThLKt2WGfG+0cOCWxEURyYLfYsa18W6KHERQKoXczhPBzUAeumAOfdjdw8X0A5wrMtuz0\n6VCapIiJNIS+bPsyDH92OLBhA5rm8+vIc/oNgnnxA/xbBXPgDCNmoUvFpH9Gfyy7ahnSzeniviuK\nrsALN7+Am0pvkt0jniIUSX/uVAihUxIbQWjj9DixfPtyOD0qmbxJAgl4CqO2FlxofxdKwKVz4LsK\ngP391UPoDl+EWiqm0hA6ABy9cBTIyUHjdXyf71xbruiMgzlwWQg9SicdjxD6a7Nfw2uzX4voGgqh\nE0Rq4/Q6seKjFXB6k1fA6SN4CqMm4MJa6mAh9FsansZrKgXB1ARcqIcu7bMtDaGL13KcWEUtNy1X\nFNZgDtzAGMQkNrXuaOEQDxGaUToj4mtSwYFTCJ0gUhvdHfiRI0cwceJElJSUYMKECTh48GDAOdu3\nb0daWhrGjRsnfnV0dIQ81tNRa8Mp7AvmwF9zf6W63+MKXO/oEAVc7sBZxV9Op6dTLCyTa8sVxSGo\nA2f8DjzaynLJKkLkwAmC0BvdHfiiRYuwcOFCzJ07F5s2bcLcuXOxe/fugPNKS0uxb98+1XsEO9aT\nURM9t6R0Kcuxonj8YO0PUNK7BBtmai8va3W2BuzL8pnyNItd3McFnAW8eeRN/O6T3wGQO/Bgzlqa\nxKZWhS0cklWEpKJNSWwEkXqYDWbMHz8/aZ8xgM4O/MyZM9izZw/Ky8sBALNmzUJdXR2OHj2q59v2\nGNystgNXvt59ajc2frUx6P1a3G2y7VFngPW+qV+T2T/XrFbFTegoNqN0BvLS8zBhwISAc5RJUwz8\n68C9bHQCHs9lZNGSrCF0SmIjCG3SzGmomlElmz5MNnQV8Lq6OuTn58Nk4h8UDMOgqKgItbW1Aece\nO3YMZWVlmDBhAlavXh32MSlPPfUUCgoKxK+2tjbNc7sDag7cw3mCHg9GqyLc/eetQP9X3gVWrYJR\n8rBXE/CvzvBh+b/e8lcwDINJRZNQ2rtUds6PBv0II/qMELelIfSoHXgKuMhIwuIUQieI5KDD3YGK\nLRUB/RySiaTIQi8rK0N9fT327t2LV155BWvWrMHLL78c8piSJUuWoL6+XvzKyEjeLjKxINgcOOAX\ncJc7vFq+LV65gNs8AK6+Gli6VOYM1QT84JmDyLHl+LuLMQyeue4ZzBo5S8yM5zguILQsCniUDjwV\nRChZHXgqfPghiEThZt1Y98U61UhnsqCrgBcWFqKhoQEeDy8kHMehtrYWRUVFsvOysrKQnc0XySgo\nKMBdd92FHTt2hDzW0wk1By4cdzSdCet+Laxc6G2S20udoZqAO73OgDad04ZNw6Y7NuEnY38CAODA\ngYH/Ygb+deDROvBUCANTEhtBEHqgq4D37dsXZWVl2LCBT5yqrq5GQUEBiiXtJwGgoaEBLMsnO7W2\ntuKNN97A+PHjQx7r6YSaAxcFvPH7sO7XyskF3CrRVJkDnzRR9fohOUNU9wuirXTgDMOIIhKtA4+k\nuEqiSNYktlT48EMQhDa6Py0qKytRWVmJkpISrFq1CuvXrwcAVFRUYMuWLQB4YR87diwuvvhiXHbZ\nZbjmmmswb968kMd6OqohdBUH3tbod+BcY6Pm/Vq48By456f3qV6vdOACgshyCAyhCyIS7TKyVCBZ\nQ+jxfC+CSDWsRiuWTV4Gq6QKZbKh+0fw0tJS7Ny5M2B/VVWV+Pr+++/H/fffr3p9sGM9HdUkNjYw\nic3R7F8T7n7+Oc37tUJeyEUq4FIR0qpMFI4DlzpmBowoIpGG0F+58xUcOncoomsSRbKF0N8pfwcf\nn/hYzD8gCCIQq8mK5VctT/QwgkIxtCRm7qtzYTPZsObGNarHww6ht/gF3PHtV8Ag9fdrMcnXbNtu\nuU18LXVrWrWBo3HggmBFGkK/ZcQtEZ2fSJLNgV8z7BpcM+wa3d+HIFIZh8uBmS/PxOY7NsMuqYOR\nTCRFFjqhzl+//CsqP6/UPB4yic3rBt5/H45mf1nV5gunNO/Xqchpsj63VnwtnS/VdOC5kc+BR+vA\nU4lkc+AEQYTGy3nxzrF3kvrZRAKeAqjNdWvtlxVyeW0z3ll0Na6v/724r6npdNjva5MUMJAKS6cn\ncFkaAwaDstWtvdSBK7PQo3XgqUQkAp4KSXkEQSQHJOApQG1zYOEbIIw58G+/wW13yI83tgXpUqZA\nWuVMNgeuEkIfmDUQVpN6soeWAzcwBnLgBEEQUUJPlhTgL7v/grHPjUWLs0W2X3UOXBpCN/hrmQs0\ntl8I+32lbjDD4i+Ko+bAtea/AX8nM5vJFhBCFxKp7ObknGOKBZHMa0sjFARBJA6byYa1N61N6mRP\nEvAU4OnPnsaBMwfw5uE3ZftDVmJjuAABb4ryb/GJKU+gMKsQAHDkwpGA40suW6J57cMTH8ZPxv4E\nVTOq5AIOBjeW3IjFly7Gp/M/jW5gKQA5cIJIPSxGCyrKKpK63wI9WZKQbUe3YfizwwP2t7nawHH+\nXmAhk9gMQKbSgUcp4Nm2bLx464sAgD2n9siOXVd8HW4ecbPmtb3Te2PjzI0YmjtU5uqFdeB/ueEv\nuKjfRdENLAWIRMA51V5vBEHEmzZXG0avHo02V/L21KBlZEnI7OrZaOpsCtjvcDtkoq0WQpfNgTMs\nMl3y441daKwjCFFdS51sfyQhYmUIvSdADpwgUg+WY/H12a+DtkRONPRkSUK0qpI5XA7VSmtS3A5/\nT2+PipuL1oEDciGSdhWLZOlTtH2yU5mIstBpDpwgiDDpGU/QFENLwNtcbXIHrjYH3njefx9XJxyK\ntd3hOPClxslYfX1g21apEA3MHChuR5uk1VPEqqd8UCEIIr5QCD0JCSbgapXWpLgZf7jH4+yAQ5F/\nEY4DX5wxBUUTfhqwXypEJoNJFOBoHTiF0AmCSFbSzenYOmcr0s3piR6KJvRkSUI0Q+hueQhddRmZ\n5F/U4+wQHfhNdfwfodKBf/D/gEWXLJJlWjKceiKVVIiMBqOYcBVtt62eImyUxEYQqYfJYML04ulJ\n3bWvZzxBuwlKB97sbMZ1G6/Dzjp/sxiPVMBdnXBYgCtqgaebfggg0IFPqQHW3LhG7oydisw3HzIB\nZ4xiRnxEIXSGQugEQSQ/Lc4WZP0uK6D+RjKRvB8tiACUDvzVQ68CAD6p/QStv+ST19wSLfXs2QXH\nTYDdBeRnF8DAAsdz1e8tm5v2qFdFUzpw8TWF0INCSWwEkZq0ulpDn5RAyBqkEMokNgFBQDmOg9sI\nmHz66zYADguQ4QLSc/IwoskkE3gpMmd8zz2q5wQ4cETuwHtiCJ0alBAEoQc94wnaTVCG0AXMRn6i\n2+vsAODv491qBTgGsLsB5OaizJEVeNO8PAAKZ5yjbtO1HLghgj8jZSW2nkBP+aBCEER8oSdLnHF6\nnLjt5dtk89bholwHLmAxWvCbj3+D0tWjAABpPgFv9vUWsbsA2O24xKrSLexTvoSpLISuEdpWOnDx\ndZTLyHqKsPWUn5MguhN2sx0Hfnogqfs0hPVkueuuu/Dpp923VnU8eePwG6j+phoTX5gY8bVaDtxi\ntOCFL17Ad60nAABpvlOafQlrdjcAqxVli1YE3rS4GEB4yWU0Bx4dkQj49cOvx3XF1+GjuR/pOCKC\nIEJhYAwozC5M6g/gYY1sypQpWLx4McrKyrBu3Tp0dgZ2oyLCQ2uJWDhozYFbjBY0tDWI26oO3GzG\nuNLJmveOlwPviSH0SD6opJnT8Nact/CjQT/ScUQEQYSi1dWK7FXZSZ3IFpaAL1y4EPv27cMzzzyD\n999/H0OGDMEjjzyCEydO6D2+bofQ9zqaxCan16kaQm/saJS1+FQ68AwXgF69kGXNQknvEtV7R+zA\nmegcuLKZSU+A01hXTxAE0RUieoKWlpZi5MiRMJlMOHToECZNmoTf//73eo2tWyI46Ehcq4Db61YN\noZ9tPyvbtikd+PQbgVtvBQCU5Zep3jscBy49R5bEFmUhl54SQk/mZggEQaQuYT15P/vsM8yZMwfj\nxo1DZ2cnPvvsM2zZsgWHDh3CX/7yF73H2K3wsrwDj6a6j5fzypy2FhbfMrIWn4Cn3TQTMPD/1PPH\nz1ctDRhOaDvWIfSeAlVXIwhCD8IOoU+dOhXHjh3Dk08+iYEDBwIA7HY7fvWrX+k6wO5GV0LoANDe\ndiHkOR2+8qlCHXSrySoeu3ro1Xh7ztsB18hC6OHMgUeZxNZT5r2lUAidIFKPTEsmmh9tRqYlM9FD\n0SQsG7h//37NY4sWLYrZYHoCTo8TQHQhdABw1B3TPDYAWTiFFrH+uWPwAMB5CjaTvH6qmvsPp0sY\nOfDIeOnWl/DCFy+gIKsg0UMhCCJCWI5FXXMdRvQZkbTFmMJ6ml5//fU4f97fpvLcuXO48cYbdRtU\nd6bDwxdbibZAvuNUrWw7TTIlPoLrxZ/jc94Ojq9pbjVaZdeoCnicHHhPEvDyi8rxwT0fRP1hjSCI\nxOFwOzDmuTFwuB2JHoomYT1NT506hd69e4vbffr0walTp3QbVHfG4eL/GKL9RPfOhV2y7ck1/tej\n3DkAgDZRwHm3Lw2hA7F34NEmsREEQRDRE9bT1Ov1wuPxrz92uVxwudQ7VhHBaXe3A4jegW/xHMRF\np/3b/dv472X5Zejj5EVVCKG3+dx+OA48nOxwTQceZTcygiAIInrCEvDrrrsOt99+O7Zv347t27fj\nzjvvxPXXX6/32LolgoB3Jax63VFg1Z4czN8L/PtnwA8a7fi/G1/E4rNDcMkp4G/V/Hkejv/QFZYD\nj9M6cHLgBEGkCsmcwAaEmcT25JNP4re//S0eeeQRAMCMGTOwdOlSXQfWXQnlwMPJWM7gzFjq/iGw\nbRsA4F//7QD+ewwwdSr2fMjgTLr8HmHNgUdaiS1KBx5J4xOCIIhEkWXNQssvk7cXOBCmAzebzVi2\nbBl27ZSm3m4AACAASURBVNqFXbt24de//jXMZrPeY+uWtHt8DlzDtQrLzIJhS88CRo0KPPCvfwHp\n6TB9Jp8nDysLvQsOPKJ+1xRCJwgiBfCwHmw7uq1L5a/1JuyJ2F27dmHfvn2yOugPPvigLoPqzggO\nXBDqlR+tRJ/0Pthzag+eue4ZPPzOwyHvkZaerS7gDgfQty9Mw0tluyNOYqMsdIIgejjt7nZcu/Fa\nND/ajCyrSivmJCAsAf/tb3+LTZs2oba2FpMnT8a7776LH//4xyTgUSAIuMvrgof1YNn2ZeKxDk8H\n/n7g7yHvYcvMURdwgHfgCoGOdBmZlsjSOnCCIIjkIayn6f/+7//i008/RUFBAaqrq7F7924YDPQg\njgZBwJ0eJzrcHbJjbx8JrJCmhi2rFzBypPpBuz1QwMNw4BGXUqVKbARBEAklLBW22Wyw2WxgWRYc\nx6G0tBTHjmlXBCO0EQXc6xSLugg0O5vDukdaejaQmws8rBJuVxNwPZLYyIETBNGNMTAGjMobldTP\nrLBC6GlpaXC73Rg3bhx+8YtfoKCgAF5v6GQrIpBgDjxcbLYM/sV//RefuPbxx/6DZ8/CwBjAgBGb\naOixjEx6DyrkQhBEdyPDkoGDiw8mehhBCetp+txzz8HlcuFPf/oTWlpa8M9//hMvvfSS3mPrlkjn\nwJUOPFxsVrt/I13RWez4cQB+gTUyxgDBpiQ2giCI4Li8LlTtrYLLm7xFy0I+Tb1eL1566SXY7Xbk\n5eVh7dq12LRpE8aNGxeP8XU7BAHnwKHFya8xHNFnRET3SBMcOABYfe768sv57xn8MUGkle5bekxK\nlwq5UCU2giC6GZ2eTix4fUFYLZwTRUgBNxqN+PDDD+Mxlh6B9I+hqbMJAGA327VOV8WWJqkOxLL8\n96FDgZdfBnbxa8BFATeGJ+BdKqVKDpwgCCLuhN2N7Mknn8SpU6fQ0tIifhGRIy0KIAh4hiVD63RV\n0tIkaxKFXASjEbj9djE7PZgDVxNRaidKEASRWoSVxLZy5UoAwOOPPw6GYcBxHBiGoUS2KJAKeHMn\nn3UuFfD+Gf1xuu10wHVSbPZsyQ199zOpz3OrOXA1wmknKt0vFe2IKrHRMjKCIFIAI2PEtGHTkrYX\nOBCmA2dZVvzyer3idyIyOI4Dy7Hi9iPv8bXlpQI+vNdwHHngSMC1Fkk1P1kIXerAJQRz4GpEKqzU\nzIQgiO6M3WLHtvJtsFsim+KMJ/Q0jSPKOudqIXSjwagqcmkSAU/LyPVvhHDgyjroAvkZ+bj7orvF\nbcFdhyvkUTczIQEnCCIFcHqcWL59OZweZ6KHoklYT1ODwQCj0RjwRUSGVlF8aRKbkTGqOto0t/+1\nLSNHctPoQugnl5zEi7e+KG4Lwh1ulni0Dpyy0AmCSAWcXidWfLQCTm/yCnhYc+Ctra3i646ODrz4\n4osUQo8CLQGXOnADY4BB5XcrdeCWDMkcuEYIXbinVghdKaSCM47GgVMhF4IgiPgT1tPUbreLX336\n9MGSJUuwadMmvcfW7QhHwI0GI4yuwPOkDpyxS+Zklvmaodx7r+z8IblDAGj3HVcihtCjceAUQicI\ngog7UT1NDx06hHPnzoV17pEjRzBx4kSUlJRgwoQJOHgwsDTd9u3bkZaWhnHjxolfHR3+KmXr1q3D\n8OHDMWzYMCxYsAButzvgHqlAWALOGGFwBlb+kTpwpKX5X197LcBxwNixsvOH5PACfq49vH8nMYQe\nzRw4JbERBNHNMBvMmD9+PswGc6KHoklY9iw3N1d0Zl6vFxzH4dlnnw3rDRYtWoSFCxdi7ty52LRp\nE+bOnYvdu3cHnFdaWop9+/YF7D9+/Dgef/xx7N27F/369cPNN9+M559/Hj/72c/Cev9kItwQutEV\n+AHFpiXgGggCfrLlZFhji5cDp2VkBEGkAmnmNFTNqEr0MIISlh3at28fvvjiC3zxxRf4+uuv0djY\niHvuuSfkdWfOnMGePXtQXl4OAJg1axbq6upw9OjRsAe4adMmzJgxA/379wfDMLjvvvvwt7/9Lezr\nkwlBwMf3Hy/bL12mYDSoO3CLdFrcHPoTYWF2IQCgsbMxrLGRAycIgvDT4e5AxZaKqJtOxYOwnqYM\nw6Bfv34YNGgQBg4cCLfbjbq6upDX1dXVIT8/HyZfhjTDMCgqKkJtbW3AuceOHUNZWRkmTJiA1atX\ni/tra2sxaNAgcXvw4MGq1wPAU089hYKCAvGrra0tnB8vbnhZXoWnDpmKk0v8zjggia0zUMBNbMCu\noAzIHBDR+V1x4JFklpOAEwSRCrhZN9Z9sQ5uNnmnbMN6mt52222ybY7jAvZ1hbKyMtTX12Pv3r14\n5ZVXsGbNGrz88ssR32fJkiWor68XvzIyIitRqjeCAzcZTMix+ZeC2f/7OfG1kTHKQujmKJP9x/bl\n58Qf/9HjYZ3flSz0SMLitIyMIAgiNoQl4C6XCzabvyBIWloanM7Qa+MKCwvR0NAAj2+tMsdxqK2t\nRVFRkey8rKwsZGfzS6MKCgpw1113YceOHQCAoqIinDhxQjy3pqYm4PpUQRTwU6eRJgmbW157Q3xt\nNBhh6PT/biN13gJ2ix3cMg4rp6wM6/yurAMnB04QBBF/wg6hnzlzRtw+ffo0OI4LeV3fvn1RVlaG\nDRs2AACqq6tRUFCA4uJi2XkNDQ1gfV21Wltb8cYbb2D8eH6eeNasWdiyZYv4nmvWrMHs2bPD++mS\nDFHAP/xI5lmNkl+lgTHAKJkDFxw4wwGZTuDqY/qMrSuV2CJx4CTgBEGkAlajFcsmLwu7n0QiCCsL\n/cEHH8Tll1+Ou+/mS29u2LABy4T1xyGorKzE3Llz8dvf/hZZWVlYv349AKCiogIzZszAjBkzUF1d\njeeeew4mkwkejwe333475s2bBwAYOnQoVqxYgSuuuAIAcNVVV2HRokUR/6DJgCjgCsEzSATc2OqA\n4Y5bAF/kWxB3jgFafuc76UXEnK448GjehyAIIpmxmqxYftXyRA8jKGEJ+Lx58zBkyBC89dZbAID1\n69fjyiuvDOsNSktLsXPnzoD9VVX+9Pz7778f999/v+Y9FixYgAULFoT1fsmMKOAc70LLWuw4ncnA\nyPqT7Yy19XJHHjrQERO64sAjgRw4QRCpgMPlwMyXZ2LzHZuTtqFJWALe2dmJyZMn46qrrgLAdyfr\n7OyUzYsTofELOC+Snz/lAADs7+c/x2A0ykRbJuArVgAzZ+oyNjGJjebACYIg4OW8eOfYOwFNqJKJ\nsJ6mU6dORUtLi7jd2tqKq6++WrdBdVeEPwST4tcuC6E7OuQCnsUn9zEcgCuvBMaM0WVsXVkHTnPg\nBEEQ8Sesp2l7e7uYJQ4A2dnZSbfGOhUQHLhRERY3SjLNjQ550QBjOh+64RgAnZ26jS1e68BpGRlB\nEERsCEvAWZaVCXZLS4u4NIwIH+UcuIDMcTsc8mNSx5qXp9vYInXg4TZJUUIOnCCIVMBmsmHtTWth\nMyXvVHFYT+E5c+bg6quvxn333QcAWLNmTVilVAk5yjlwAaMiCx0XXQRgP78tON1LLgEuvVS3sUXs\nwCmEThBEN8ZitKCirCLRwwhKWAK+dOlS9O/fH2+++SYYhsEDDzwAuz05s/KSGa1lZLIQelMLMHAg\nBAEXBa9XL13HFvEcOC0jIwiiG9PmasMPq36If1X8S1buOpkI2w7dc889WLlyJYqKivDzn/8cv/nN\nb/QcV7fEL+BBQugcZK1B4+VYI85CN1AWOkEQ3ReWY/H12a/BclGWw4wDIZ+m7e3tWL9+PSZNmoSp\nU6eiqqoK27dvx549e+Ixvm5FWCH03F7Ar34lbsdL8CJeB84YMW8cX2ynuFdxiLP9kIATBEHEhqBP\n0wULFqCwsBBbtmzB0qVLUVtbi5ycHIwYMSJe4+tWhJXEdu+9QFaWuB1twZRIibgSm8GIdTPWoeXR\nFvS19w3/fSgLnSAIIiYEnQP/+9//jksvvRSLFi3C9OnTwTAMPYC7gNBONOgcuNEiOyY4Vg76lmSL\nxoEzDINMa2ZE70MOnCCIVCDdnI6tc7Yi3Zye6KFoEvRp2tDQgPLycqxcuRKDBg3Cr3/9a7jdydsb\nNdkR14Erfu2yELrCcccthB6FA48GEnCCIFIBk8GE6cXTo14yGw+CPk0zMjIwf/58fPrpp9i6dSs6\nOzvhcrkwceJErF69Ol5j7DaIIXSvPCnCoOhGJkXI9tY7ezvifuBRZqGTgBMEkQq0OFuQ9bsstDhb\nQp+cIMJ+mo4aNQp//OMfcfLkSfz85z/Hm2++qee4uiWigLvlAi4LoSuEMW5z4F1YBx7R+9AyMoIg\nUoRWV2uihxCUiO2QyWTCrFmzSMCjwC/g8uL4hjBC6LrPgcdpHTg5cIIgiNhAT1Md8LJebNy/ER1u\neV1zUcBd8jK0xiAh9LgvI6M5cIIgiJSAnqY68NaRt1D+Sjlu+ttNsv1aAi5z4MoQepzmwONWiY1W\nMRAEkQLYzXYc+OkB2M3JW3WUBFwHBJF6//j74tIxQNJOVOnApXPgiQqhkwMnCIIQMTAGFGYXJvUz\nK3lHlsJIXew3574RX3vOnQGQnCH0SLPQox1XMv9nIAiCEGh1tSJ7VXZSJ7LR01QHpLVz3V7/unnP\nn/4AADA65WvpmWAh9CStxNbV9yEIgiC6Bgm4DgihckAu5h7fb9vkdMnOZ1atEl8nrJBLhJXYooUc\nOEEQRGygp6kOSEVbVcBbHP6TX38dWLpU3ExYFnqcHDgJOEEQRGygp6kOhBRwaQjdapVdq5WFrjfh\nOvAcW06X3ocEnCCIVCDTkonmR5uRaYms30M8Sd4irymMVLSl4XRRwKWF2Gw22bUBpVTjNAcebj/w\nuv+oQ6sz+qQOWkZGEEQqwHIs6prrMKLPiLgZqUghO6QDWg7c69MumYArHbhCsOOV9BXu+2RYMpCf\nmR/1+5ADJwgiFXC4HRjz3Bg43I7QJycIeprqgHTtt2oIXSrgZrPsWuUnvXgnsekNCThBEERsoKep\nDqg6cJZVF3BD8KS1yYMmAwCuGXpNzMcpJdmcPkEQBBEcmgPXAVUB7+wUBdwYpKiaMoR+z7h7cG3x\ntRiZNzLWw5RBDpwgCEJOMiewASTguqAq4B0d6g48K0t2rVoW+ui+o/UYpox4OWMScIIgUoEsaxZa\nfpm8vcABCqHrgqqAt7fLBXz2bGDzZmDIENm1iS6lynHxqblOEASRzHhYD7Yd3SY2oUpGSMB1IEDA\n9+4FiorkAj5sGHDrrQHXKkPocSulSsJKEAQh0u5ux7Ubr0W7uz3RQ9GEBFwHpGu/vawXWL2afy3M\ngbMABg1SvTZhWeiUXEYQBJFSkIDrQIAD981zewy8eDMAMH686rUJK6UaJwdOHxQIgiBiAwm4DgQI\neCafyegxSBLYxoxRvTZhzUxIWAmCIEQMjAGj8kYldeItZaHrQFgCriihKpCoWuhiEhv0TWIjCIJI\nBTIsGTi4+GCihxGU5P1okcIECLiJ/5zkMQBGMMC6dZrXJrobme7vQ8lyBEGkAC6vC1V7q+DyukKf\nnCBIwHUgoJSq0wkAcBkBc1oGcO+9mtcKIfR0czqAOM5Nk7ASBEGIdHo6seD1Bej0dCZ6KJpQCF0H\nlA78kPMkCs1AsxXINmcEvVYImdc8VINTrad0HacUmgMnCIJILUjAdUAq4N81fofZ3LO4ZjbQmAb0\nMWcFudIfMs+z5yHPnqfrOKVQFjpBEERqQSF0HVAKOAC8OwxosgG5luACHq/CLUpIWAmCIPwYGSOm\nDZuWtL3AAXLguiAV8M6W8+LrZhuQY0gPem2ilizEq5QqQRBEKmC32LGtfFuihxEUcuA6IBPwLa/I\njuUOLA56baI+7VGyHEEQhB+nx4nl25fD6XEmeiiakIDrgLSUqlMR48hN7x30WgqhEwRBJB6n14kV\nH62A00sC3qOQOXCFgOfYcoJem6gQOiWxEQRBpBYk4DoQTMBz03KDXpuwEDoJK0EQREpBAq4DUgHv\nUAq4LYSAJyqE7nPgVEqVIAgCMBvMmD9+PswGc6KHoonuAn7kyBFMnDgRJSUlmDBhAg4e1K4ty3Ec\npk6dipwcf5i5pqYGRqMR48aNE7+OHTum97C7hFTAW63yY6EceKKz0AmCIAggzZyGqhlVSDOnJXoo\nmuj+1F60aBEWLlyIw4cPY+nSpZg7d67muU8//TSGDRsWsD8zMxP79u0Tv9TOSSakAt5mkR8LNQdO\nIXSCIIjE0+HuQMWWCnS4OxI9FE10FfAzZ85gz549KC8vBwDMmjULdXV1OHr0aMC5Bw8exKuvvopH\nH31UzyHFBWkt9IgFPMEh9O7yPgRBEF3Bzbqx7ot1cLPuRA9FE10FvK6uDvn5+TD5unExDIOioiLU\n1tbKznO73ViwYAEqKythNAYKmMPhwIQJE1BWVoaVK1fC6/UGnAMATz31FAoKCsSvtra22P9QYRDM\ngdtM6m1EBRKWhU4OnCAIIqVIionPFStWYObMmRg5cmTAsfz8fJw8eRK7d+/Ge++9hx07duBPf/qT\n6n2WLFmC+vp68SsjI3jjEL2QCrhX8Ru2GBWKrqC7F3Lpk94HAFDcK3hBG4IgCCI4ugp4YWEhGhoa\n4PF4APBJarW1tSgqKpKd99FHH+HZZ5/F4MGDMWnSJLS0tGDw4ME4e/YsrFYr+vbtCwDo1asX7r33\nXuzYsUPPYXcZqYArCZXRmKgQerxKqY7oMwKvzX4Nn8z7RNf3IQiC6ApWoxXLJi+D1WgNfXKC0FXA\n+/bti7KyMmzYsAEAUF1djYKCAhQXy93Xjh07cOLECdTU1OCTTz5BVlYWampqkJeXhzNnzsDt5ucg\nnE4nNm/ejPHjx+s57C4TTMBDOfCeEEKfUToD/TL6xe39CIIgIsVqsmL5VcthNfVQAQeAyspKVFZW\noqSkBKtWrcL69esBABUVFdiyZUvI6z/55BOMHz8eF198McrKytC/f3/86le/0nvYXUJaSlWJ2Zic\nawopuYwgCMKPw+XA9A3T4XA5Ej0UTXTvRlZaWoqdO3cG7K+qqlI9f/DgwWhqahK3Z86ciZkzZ+o2\nPj3oSgg9UVASG0EQhB8v58U7x94JasgSTVIksXU3tATcyBhDznEnSkjJgRMEQaQWJOA6oCXg4YTP\nQ82R6wU5cIIgiNRC9xB6T0RLwIOJ87EHj2Hf6X3ItmXrNaygUClVgiAIPzaTDWtvWhuydkciIQHX\nAU0HHmT+e2juUAzNHarXkEJCIXSCIAg/FqMFFWUViR5GUMh26YBW0kOiwuPhQCF0giAIP22uNoxe\nPRptrsRU9AwHEnAd6MoceKIgB04QBOGH5Vh8ffbroKuKEg0JuA5EMweeaMiBEwRBpBYk4DqQigIu\nllKFvqVUCYIgiNhAAq4D0SSxJRoKoRMEQfhJN6dj65ytSDenJ3oomlAWug5I+4FLSeo5cAqhEwRB\niJgMJkwvnp7oYQSFHLgOaDnwZF5rTQ6cIAjCT4uzBVm/y0KLsyXRQ9EkeRUlhUlJAScHThAEIaPV\n1ZroIQQleRUlhdES8GQWSXLgBEEQqQUJuA5oCngSi6SYhc5RFjpBEEQqQAKuAynpwJN4bARBEPHG\nbrbjwE8PwG62J3oompCA64CX88JkCEzwT2YHnsxjIwiCiDcGxoDC7MKkzl1K3pGlMCzHwozAvt/J\n/IdADpwgCMJPq6sV2auykzqRLXkVJYVhORYmpztgP4kkQRAEEStIwHWAd+CBv9pUCFNTKVWCIIjU\ngARcB1iOhUmlbCo5cIIgCCJWkIDrgJf1wpSiDpwgCIIAMi2ZaH60GZmWzEQPRRMScB1gORZGlUh0\nMiexEQRBEH5YjkVdcx31A+9p8AIe6LYphE4QBJEaONwOjHluDBxuR6KHogkJuA5oOXAKoRMEQRCx\nggRcB1iOhUFNwFPAgVMpVYIgiNSABFwHeAEPFMJkduDJPDaCIIhEkMwJbAAQWO+T6DJezguDSt4D\nJbERBEGkBlnWLLT8Mnl7gQPkwHVB04GnQAidIAiCADysB9uOboOH9SR6KJqQgOsAy7GqDpzC1ARB\nEKlBu7sd1268Fu3u9kQPRRMScB1gORZG1u/ArUYrACDXlpuoIYUNlVIlCIJIDWgOXAeUDvzJqU/i\neNNxPP6jxxM3qBBQeJ8gCCK1IAHXAS/rhUHiwPtl9MPPJ/48gSMiCIIgIsHAGDAqb1RSJx+TgOsA\n78D9Am4y0K+ZIAgilciwZODg4oOJHkZQkvejRQrDC7g/hk4CThAEkVq4vC5U7a2Cy+tK9FA0IQHX\nAZZjYfT6HbiRMSZwNARBEESkdHo6seD1Bej0dCZ6KJqQgOtAKofQqZQqQRBEakACrgOpGEKnNeoE\nQRCpBQm4Dng5Lwze1HTgBEEQBD/1OW3YtKSeAiVl0QFlNzKjIXn/AAiCIIhA7BY7tpVvS/QwgkIO\nXAdYloVRUsiFHDhBEERq4fQ4sXz7cjg9zkQPRRMScB1QOvBUEnAqpUoQBAE4vU6s+GgFnF4S8B4F\ny3lTVsAJgiCI1IAEXAe8yjnwJE6CEKBa6ARBEKkFCbgOpHIInSAIggDMBjPmj58Ps8Gc6KFoQsqi\nAyzHwkgCThAEkbKkmdNQNaMq0cMIiu4O/MiRI5g4cSJKSkowYcIEHDyoXRye4zhMnToVOTk5sv1v\nvPEGRowYgeHDh2PmzJloaWnRe9hdgpaREQRBpDYd7g5UbKlAh7sj0UPRRHcBX7RoERYuXIjDhw9j\n6dKlmDt3rua5Tz/9NIYNGybb19bWhvnz5+PVV1/FkSNHMGDAADzxxBM6jzp6OI4DBy5lQ+hUSpUg\nCAJws26s+2Id3Kw70UPRRFcBP3PmDPbs2YPy8nIAwKxZs1BXV4ejR48GnHvw4EG8+uqrePTRR2X7\n3377bYwfPx4jRowAACxevBh/+9vf9Bx2lxCWYaWagFMpVYIgiNRCVwGvq6tDfn4+TCZewBiGQVFR\nEWpra2Xnud1uLFiwAJWVlTAa5eHm2tpaDBo0SNwePHgwGhoa4PF4At7vqaeeQkFBgfjV1tamw08V\nHC/rBZB6Ak4QBEGkFkmRhb5ixQrMnDkTI0eO7NJ9lixZgvr6evErIyMjRiMMH5bjS7Cl2jIygiAI\nwo/VaMWyyctgNVoTPRRNdBXwwsJCmVvmOA61tbUoKiqSnffRRx/h2WefxeDBgzFp0iS0tLRg8ODB\nOHv2LIqKinDixAnx3JqaGpmrTzYEAadSqgRBEKmL1WTF8quWw2rqoQLet29flJWVYcOGDQCA6upq\nFBQUoLi4WHbejh07cOLECdTU1OCTTz5BVlYWampqkJeXh2uvvRZ79+7FoUOHAACrV6/G7Nmz9Rx2\nl1Bz4CTgBEEQqYXD5cD0DdPhcDkSPRRNdA+hV1ZWorKyEiUlJVi1ahXWr18PAKioqMCWLVtCXp+Z\nmYmqqirccsstKC4uRn19PR5//HG9hx01qS7gVAudIAiCbwv9zrF34OW8iR6KJrorS2lpKXbu3Bmw\nv6pKfYH84MGD0dTUJNs3Y8YMzJgxQ5fxxRrVOfAUWAdOpVQJgiBSi6RIYutOCGsGTTQHThAEQegI\nCXiM6fR0AgDSJKvcSMAJgiBSC5vJhrU3rYXNZEv0UDQhZYkxgoBbJQJuYOhzEkEQRCphMVpQUVaR\n6GEEhZQlxggCbgusM5MSUClVgiAIoM3VhtGrR6PNFf+CYOFCDjzGSAX8z5N+gw/P7k7wiMKDSqkS\nBEH4YTkWX5/9WkxMTkZIwGOM0+MEwAv4Q5f9Ox6y2xM8IoIgCKI7QiH0GCPOgXsB2JI3+YEgCIJI\nbUjAY4wYQueMgDH5138TBEEQgaSb07F1zlakm9MTPRRNKIQeY0QBZ8wJHglBEAQRLSaDCdOLpyd6\nGEEhBx5jnF5+DjyZO9gEg0qpEgRBAC3OFmT9LgstzpZED0UTEvAYIzrwFBNwKqVKEAQhp9XVmugh\nBIUEPMakqoATBEEQqQUJeIwRs9DNlIFOEARB6AcJeAzZXrMdj3/AtzpN5vq5BEEQRHDsZjsO/PQA\n7ObkreVBAh5Dpvx1Cto97QAAmzktwaOJjFtH3gq72Y7nb3w+0UMhCIJIOAbGgMLswqTuZUHLyHTC\nlmK/2gGZA9D2WPLW/CUIgognra5WZK/KRvOjzciyZiV6OKok70eLFMdaU5/oIRAEQRDdGBJwnbB9\nV5voIRAEQRDdGBJwnbD16ZfoIRAEQRDdGBJwnbC+tz3RQyAIgiCiJNOSieZHm5FpyUz0UDQhAdcJ\nU8mIRA+BIAiCiBKWY1HXXJfU/cBJwAmCIAhCgcPtwJjnxsDhdiR6KJqQgHeFlhbgq6/ETSND7UMJ\ngiCI+EAC3hWuuAK46CLgwgUAQLqB6p8TBEEQ8YEEvCscOMB/b+HbzVE/L4IgiO5DMiewAVSJLTYY\n+M9BTtad4IEQBEEQsSDLmoWWXyZvL3CAHHhs4DhwHAcnxwv41RkXJ3hABEEQRFfwsB5sO7oNHtaT\n6KFoQgIeCzweuH3u+yf7gXcv/mOCB0QQBEF0hXZ3O67deC3a3e2JHoomJOCxwONB50fvAwCsXgD2\n5G0/RxAEQXQPSMBjgdsN530VAACrB0B6emLHQxAEQXR7SMBjgccDp4nPQScHThAEkfoYGANG5Y2i\nfuDdHrdbzEC3ekACThAEkeJkWDJwcPHBRA8jKMn70SKVaGyE88IZAICNBJwgCCLlcXldqNpbBZfX\nleihaEICHgu++gqdvlgGhdAJgiBSn05PJxa8vgCdns5ED0UTEvBYcOgQnL4y6NYnVwFGqolOEARB\n6AsJeCz49ls4BQduJfdNEARB6A8JeCw4fNjvwI3U0IQgCCLVMTJGTBs2Lam7TFIWegxwn/0ef7jB\nBMADq4kEnCAIItWxW+zYVr4t0cMICjnwGPD05cD7RXy9XJvJluDREARBEF3F6XFi+fblcHqciR6K\n98XlvwAAFghJREFUJiTg0cJxAIAPBwNLr/HvphA6QRBE6uP0OrHioxVweknAuwetrcAXX/CvXfza\nwAevk59CIXSCIAgiHpCAR8INNwBlZeCOHsXaPc/jjB2ozwKGXfCf0tzZnLjxEQRBED0GEvBI2LED\nAPDZlOFY+N6DGL8IaEoDfnAS+IPjCgDARf0uSuQICYIgiBhgNpgxf/x8mA3mRA9FExLwKDiRw38/\nlcV/H9AK/IK7HG2/bMPIvJGJGxhBEAQRE9LMaaiaUYU0c1qih6IJCXgUfJcr385vBWC1wm6hIi4E\nQRDdgQ53Byq2VKDD3ZHooWiiu4AfOXIEEydORElJCSZMmICDBwO7u+zcuRPjxo3DuHHjMHr0aCxa\ntAhOJ5/5t337dqSlpYnHx40bh46O+P5CGzsasfKjlVg5GVg5GXjuUvnx/DYAVkpeIwiC6C64WTfW\nfbEObl+nyWRE90IuixYtwsKFCzF37lxs2rQJc+fOxe7du2XnXHzxxdi9ezfMZjNYlsWsWbOwevVq\n/Md//AcAoLS0FPv27dN7qJo0djZi2fZlwBT14/mtACyWuI6JIAiC6Nno6sDPnDmDPXv2oLy8HAAw\na9Ys1NXV4ejRo7Lz0tPTYTbziQIulwsdHR1gGEbPoUVEQVYB9t+3H/vXWfCHdwKPkwMnCIIg4o2u\nDryurg75+fkwmfi3YRgGRUVFqK2tRXFxsezcmpoa3HzzzTh27BhuuOEGLF68WDx27NgxlJWVwWg0\nYt68ebJjUp566ik89dRT4nZbW1tMfg6L0YKx/cYCTVYMO+3Cw9OA23wzAZtGAwUtIAEnCCIhsCwL\nzldYiogdZpixcvJKmGGG1+vV7X0YhoHBEJ2XTppa6IMHD8aXX36JtrY2lJeXY/PmzZg9ezbKyspQ\nX1+P7Oxs1NfX4/rrr0efPn1wxx13BNxjyZIlWLJkibhdUFAQ20FaLEhvBRpXAWluwMABa18HMlwg\nAScIIq64XC7U1tbC7U7eOdpU57Z+t6Hmuxrd38dsNqOoqAiWCKdidRXwwsJCNDQ0wOPxwGQygeM4\n1NbWoqioSPOajIwMzJ49Gxs3bsTs2bORlZUlHisoKMBdd92FHTt2qAq47vh+uTmS/u7iaxJwgiDi\nSG1tLTIzM9G7d++kmnIkIoPjOJw/f141Mh0KXQW8b9++KCsrw4YNGzB37lxUV1ejoKAgYJBHjx7F\noEGDYDab4XK58Morr+Cii/iCKA0NDejXrx8MBgNaW1vxxhtvYP78+XoOW5tgn45IwAmCiBMsy8Lt\ndqN3797iFCWRuvTu3RsXLlwAy7IRhdN1X0ZWWVmJyspKlJSUYNWqVVi/fj0AoKKiAlu2bAEAfPDB\nBxg/fjwuvvhijB8/Hv369cPjjz8OAKiursbYsWNx8cUX47LLLsM111yDefPm6T1sdYLNg5CAEwQR\nJ4Q5b3Le3QPh3zHSXAaG68bZDwUFBaivr4/dDfPygHPn1I9t2wZMmxa79yIIgtDA6/Xi8OHDKCkp\ngdFoTPRwiC4S7N8zmI5RJbZI6OzUPkYOnCCIHopQZGvUqFEwGo3i9p133hnxvebNm4cdvr4TwfjL\nX/6Cp59+OprhxgyWZbF8+XK4fN0p4w058EiwWACtjM+dO4HLLovdexEEQWiQrA68pqYG48aNQ1NT\nk+Y5QlJzd8Dj8cBsNqO1tRUZGRlR3ydaB949fovxwOvVFm+AHDhBEIljxgzg/7d370FRnWccx78r\nrIgWAsXYZDCwVsCqsCw3i4gyXmJSJkHLaGy8kDaMJuaPBpM4dSytNnXIpElUYpo6iQFaL2iIliTV\ntGO0XlK1agMxmMqAupWm2CQGHApqQN/+Qd1KQFjxsqz8Pv8o5z179tmHd/bhvOec9z1+/OYce+hQ\n+N/9St3x/vvv89RTTxEfH095eTk///nPaWxsZNWqVTQ3N2OMIS8vj/T0dABSU1NZtGgRDzzwALNn\nzyYgIIDKykr++c9/Ehsby4YNG7BareTm5nL+/HlefPFF1qxZQ0lJCcHBwRw9ehR/f3/efPNNbDYb\nALm5uWzcuJHg4GAmT57Mpk2b2k0oBq33bOXn59O3b18uXbpEQUEBiYmJVFZWkpOTwxdffMGFCxeY\nP38+8+fP5/HHHwcgJSWFPn36sGPHDkJCQrqdq2ulAu6u/83Nzpw5kJkJ3/9+23YVcBGRDlVUVPDq\nq6+SmpoKwBdffMHs2bOxWCycOHGClJQUampqXDNyXumjjz5ix44d9O3blzFjxlBaWsr06dPb7ffX\nv/6Vjz76iPDwcJ555hleeOEFfv3rX/P222/z7rvvUl5ezoABA8jKyrpqnE899RQnT55k0KBBNDc3\nc+HCBZqbm5k5cybFxcVERUXR2NjIqFGj+O53v8vq1at544032Ldv33WdgXeXCri7Ll//7tcPBnSw\n6pgKuIh4ynWcId8KUVFRruINcOLECWbNmsWnn36Kr68vX375Jf/4xz86fA46MzMTf//WJT2TkpI4\nfpWRhtTUVMLDwwEYPXo0r7/+OgA7duzgoYcechXY7Oxs9u/f3+ExJk6cyOzZs3nggQdIT08nIiKC\nI0eO8Pe//73N3CNNTU188sknrsedPUUF3F2Xz8D79YOWlvbtKuAiIh36+tnpQw89xMqVK5k6dSoA\ngYGBnL/KTcL9+vVz/d/Hx4eWjr5/r2G/zh69e/vttzl8+DC7du1i8uTJPP/880RFRTFw4MAOF9S6\n2nvcKroL3V2XO5efX+s1IYCcnP+3azUyERG31NfXM2TIEACKiopoaGi4ae81YcIE3nrrLRobGzHG\nUFBQ0OF+zc3NnDhxgqSkJBYuXEhmZiaHDh1ixIgR+Pv7s3btWte+VVVV1NfX4+vrS//+/Tl79uxN\ni78zOgN315VD6FFRcPp063PhK1e2btcZuIiIW/Lz85kyZQrf/OY3mTRpEqGhoTftvaZOncrBgwdx\nOBzccccdjBs3jqCgoHb7NTc388Mf/pD6+np8fHwYNGgQRUVFWK1W/vCHP7BgwQJeeOEFLl68yJ13\n3klxcTFBQUE8/fTTjB8/nv79+9/ym9j0GJm7ysogPh6WLYOf/vT/2y8Px5w711rcRURusp76GFlP\n1dDQQEBAAMYYnnzySYwxrFq1ytNhuegxspvtymvgHdEQuohIjzRr1ixqamo4f/48MTExrF692tMh\n3RAq4O668hp4R7q5nquIiNxc7/Twu/S7S1XHXVdeAxcREfEwFXB3dTWELiIicgupgLvrzJnWf1XA\nRUSkB1ABd9dvfwtWK1wxm5CIiIinqIC7o7wc9uyBH/wA7rqrbdt770FpqWfiEhHpAdLT03nllVfa\nbY+NjWXLli2dvnbp0qXk/G9SrHfeeYcFCxZ0uF9FRYVrcZLOOJ3OdneZp6enU1lZ2eVrb6aioiKO\nHTt2Q4+pAu6OYcPgjTdg4cL2bfffD1Om3PqYRER6iOzsbAoLC9tsO3z4MLW1tTz44INuHycjI+O6\n1/juqIBv27aNYcOGXddxr5cKuKf4+8Ojj0JMjKcjERHpcTIyMqipqeHIkSOubQUFBWRlZWG1Wvn4\n449JTU0lPj6eESNGsGzZsg6PU1RU5JofHVrPziMjI0lISGDjxo2u7S0tLdx3330kJiYycuRIZs6c\nSWNjIwCPP/44lZWVOBwOMjIyALDZbK65zKurq5k0aRJ2ux2Hw0HpFSOoFouFvLw8Ro0axZAhQ9r9\nUXLZgQMHSEhIwOFwEB0dzW9+8xugdcKYuXPnMmrUKOx2O/PmzeOrr75izZo1HD58mAULFuBwONi2\nbVt30tyOngMXEfFyGcUZHK+7OeuBDw0eyjsPd/4ctdVqZc6cORQUFLBy5UrOnz9PcXEx+/btA1oL\n6I4dO/Dz8+PcuXOkpKQwadIkkpOTr3rMrVu3UlJSwt/+9jcCAgKYM2eOq83Hx4cNGzYQEhKCMYYn\nnniCVatWsWjRIlavXk1OTk6Hi49A66Qujz76KI899hhVVVUkJycTFxfnWsnMz8+PgwcPcuzYMZKS\nkpgzZw6+vm1L5XPPPcczzzzDww8/DEBdXR0ATz/9NGPHjuX111/HGMPcuXPJz89n4cKFrFu3jpyc\nnDZ/oFwvFXAREblu2dnZpKWl8atf/YotW7YwfPhwhg8fDsC5c+d44oknKC8vp0+fPtTU1FBeXt5p\nAb+8DGhgYCAAjz32GB988AEAxhhWrFjB1q1baWlp4ezZs6SkpHQZY0NDAx9++CF/+ctfAIiMjCQ1\nNZW9e/e6CvisWbMA+M53voOvry+nT59m8ODBbY4zfvx4fvnLX1JVVcWECRNcS6WWlpayf/9+li9f\n7vrcN3OqWxVwEREv19UZ8q0wYsQIIiIiePfddykoKCA7O9vVtnjxYgYOHEhZWRm+vr5kZmZedfnQ\nq7lyGdANGzawc+dOdu/eTWBgIC+//DI7d+7sVtxfX17UnWVJc3JymDJlCu+//z6LFy8mOjqaV199\nFWMMmzdvJioqqluxXCtdAxcRkRsiOzubvLw8Dh48yIwZM1zb6+rqGDx4ML6+vlRWVrJ9+/YujzVp\n0iRKSkpoaGjAGMNrr73W5ngDBw4kMDCQhoYGioqKXG2BgYFXXd4zICCA+Ph417Xt6upqPvjgA8aN\nG3dNn7OyspIhQ4Ywd+5cFi9ezIEDB4DWlc+ef/55V9Gvq6ujurq6y7i6SwVcRERuiBkzZlBZWcn0\n6dP5xje+4dqem5tLYWEhdrudRYsWMWHChC6PlZ6ezrRp04iPjycxMZGwsDBXW1ZWFk1NTQwbNozv\nfe97jB071tVmt9sZOXIk0dHRrpvYrrR+/Xo2bdpEbGws06ZNY82aNW2O7Y5XXnmFkSNHEhcXR25u\nLi+99BIAK1aswN/fH4fDgd1uZ+LEiTidTgDmzZtHXl7eDb2JTcuJioh4GS0nenvp7nKiOgMXERHx\nQirgIiIiXkgFXERExAupgIuIeJnLjz7dxrcw9SqXf49ff6StK3oOXETEy/Tp0wer1cqZM2cICQm5\n5i9+6TmMMZw5cwar1UqfPtd2Tq0CLiLihcLCwjh16hRffvmlp0OR62S1Wq/5UTZQARcR8Up9+/Yl\nIiKCS5cuaSjdi1kslms+875MBVxExIt198tfvJ9+8yIiIl5IBVxERMQLqYCLiIh4odt6LnQ/Pz/u\nvPPOG3Ks//znP20m5xf3KXfdp9x1n3LXfcpd993o3H3++edcuHChw7bbuoDfSFoYpfuUu+5T7rpP\nues+5a77bmXuNIQuIiLihVTARUREvJDP0qVLl3o6CG8xevRoT4fgtZS77lPuuk+56z7lrvtuVe50\nDVxERMQLaQhdRETEC6mAi4iIeCEV8C5UVVWRkpJCVFQUSUlJHD161NMh9Sg//vGPsdlsWCwWysvL\nXds7y5tyCufPn2fq1KlERUURGxvLvffeS3V1NQCfffYZ999/P5GRkURHR7Nnzx7X6zpr600mT56M\n3W7H4XAwduxYysrKAPW7a1FYWIjFYqG0tBRQv3OXzWZj2LBhOBwOHA4HmzZtAjzU94x0avz48aaw\nsNAYY0xJSYlJTEz0bEA9zO7du01NTY0JDw83ZWVlru2d5U05NebcuXNm69at5tKlS8YYY1atWmXS\n0tKMMcb86Ec/MkuWLDHGGHPw4EETGhpqvvrqqy7bepO6ujrX/7ds2WLsdrsxRv3OXSdPnjSjR482\nycnJ5ve//70xRv3OXV//rrvME31PBbwT//73v01AQIBpbm42xhhz6dIl861vfctUVVV5OLKe58pO\n3VnelNOOHTp0yISHhxtjjBkwYICpra11tSUlJZnt27d32dZbFRYWmtjYWPU7N128eNFMnDjRHD58\n2KSlpbkKuPqdezoq4J7qexpC70RNTQ133303vr6tq65aLBbCwsI4deqUhyPr2TrLm3Lasfz8fKZM\nmcKZM2dobm7mrrvucrXZbDZOnTrVaVtvlJWVxT333MPPfvYz1q5dq37npuXLlzNmzBgSEhJc29Tv\nrk1WVhYxMTFkZ2fz+eefe6zvqYCLeFheXh7V1dU899xzng7Fq/zud7+jpqaGZcuW8ZOf/MTT4XiF\niooKNm/eTG5urqdD8Vp79uzhyJEjfPjhhwwcOJBHHnnEY7GogHfinnvuoba2lpaWFgCMMZw6dYqw\nsDAPR9azdZY35bStF198kS1btvDee+/Rv39/QkJC8PX15fTp0659nE4nYWFhnbb1Zo888gh//vOf\nGTx4sPpdF/bu3YvT6SQyMhKbzcaBAweYN28eb775pvqdmy5/bqvVSk5ODnv37vXYd54KeCcGDRpE\nfHw869atA2Dz5s0MHjyYiIgID0fWs3WWN+X0/5YvX05xcTHbt28nKCjItX369OmsXr0agEOHDvHp\np5+SlpbWZVtvUV9fz7/+9S/Xz6WlpYSEhKjfuWH+/PnU1tbidDpxOp0kJyfz2muvMX/+fPU7NzQ2\nNlJfX+/6ubi4mLi4OM/1veu+in6bO3bsmElOTjaRkZEmISHBHDlyxNMh9Sjz5s0zoaGhxsfHxwwa\nNMgMHTrUGNN53pRTY2pqagxgvv3tb5vY2FgTGxtrRo0aZYwx5vTp0+bee+81ERERZsSIEWbnzp2u\n13XW1ls4nU6TlJRkoqOjjd1uNxMnTnTdVKR+d22uvIlN/a5rx48fNw6Hw8TExJjo6GiTkZFhTp48\naYzxTN/TVKoiIiJeSEPoIiIiXkgFXERExAupgIuIiHghFXAREREvpAIuIiLihVTARUREvJCvpwMQ\nEc+x2Wz4+fnh7+/v2rZ27VpiYmJu2Hs4nU4cDkebCTBE5PqpgIv0cps2bcLhcHg6DBG5RhpCF5F2\nLBYLubm5xMXFERUVxfr1611tf/rTn4iPj8dut5OWlsYnn3ziaissLMThcBAbG0tiYiJOp9PVtmTJ\nEhISEoiIiGDbtm238uOI3JZ0Bi7Sy82YMaPNEPr+/fuB1iJeVlbGiRMnSExMZMyYMfTv35+ZM2ey\na9cuYmJiWL9+PdOmTePo0aPs3r2bZ599ln379nH33XfT1NQEwGeffcbZs2ex2+384he/4I9//CNP\nPvkk6enpHvm8IrcLTaUq0ovZbDZKS0vbDaFbLBacTifh4eEATJ06lczMTIKDg3nppZfYtWuXa9+g\noCAqKirIz8/H39+fZ599ts2xnE4nw4cPp6mpCYvFwtmzZwkJCXGtziQi3aMhdBFxi8Vi6fZr/fz8\nXK/38fHh4sWLNyoskV5LBVxEOlRYWAi0nkHv3buXsWPHkpyczMcff0xFRQUAGzduJDQ0lNDQUB58\n8EHWrVtHbW0tAE1NTa5hdBG58XQNXKSX+/o18BUrVgBw8eJF4uLiaGxs5OWXX8ZmswGwfv16srKy\naGlpITg4mJKSEiwWC+PGjWPJkiXcd999WCwW+vbty1tvveWJjyTSK+gauIi0Y7FYqKurIygoyNOh\niMhVaAhdRETEC2kIXUTa0cCcSM+nM3AREREvpAIuIiLihVTARUREvJAKuIiIiBdSARcREfFCKuAi\nIiJe6L9JxmCdf4o0bQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 560x560 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAekAAAHnCAYAAACcxKXnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAMTQAADE0B0s6tTgAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOzdd3hUVf4G8HdaeiUJNTSJIEUITaUI\ngiiICIqK7gouPwGxrIrYWEWEtTcQK2goqy7g2hAU3QWsqFQBsYAQwBB6ep96f39M5s65U5KZZCYz\nd/J+noeHmTt3bk6C5p3vOeeeo5EkSQIRERGFHW2oG0BERESeMaSJiIjCFEOaiIgoTDGkiYiIwhRD\nmoiIKEwxpImIiMIUQ5qIiChMMaSJItimTZug0Wh8Pv/rr7+GRqOBxWIJWBtWrlyJzMzMgF2PqDlh\nSBOF0CWXXAKNRoOlS5cqjpeXlyMxMREajQaHDh0KUevcbdu2DVdddRVat26NpKQknH/++VixYkWo\nm0UUsRjSRCHWo0cPt5B+55130LFjxxC1yLvCwkJce+21+Pnnn1FaWoqXX34Z99xzD9auXRvqphFF\nJIY0UYhdddVVOH36NLZt2yYfe+ONNzBz5ky3cz/77DP0798fycnJ6Nq1K1544QXYbDb59V27duHC\nCy9EQkICBgwYgJ9//tntGm+//Tb69OmD5ORk9OzZE2vWrPG5rWPHjsXUqVPRsmVLaDQajBgxAiNH\njsRXX33l8zVqamrw0EMPoXPnzkhNTcXFF1+s+N737t2L4cOHIyUlBampqejfvz8OHDgAAPjqq68w\nYMAAJCcnIy0tDUOGDEFxcbHPX5tIbRjSRCGm1+sxffp0LFmyBACwZcsWlJWV4corr1Sct2PHDlxz\nzTV46KGHUFhYiNWrV2PhwoV4+eWXAQBlZWUYM2YMLr/8chQWFuLtt9/G66+/rrjGypUrMXfuXCxb\ntgzFxcVYunQpbr31VmzZsqVBbS8rK8O2bdvQt29fn9/zwAMPYMOGDdi4cSNOnz6Nq6++GqNGjUJ+\nfj4A4I477sCll16KgoICnD17FsuWLUNKSgoAYPLkybjzzjtRUlKCkydP4oUXXkBUVFSD2k6kBgxp\nojAwY8YMfPjhhygpKcEbb7yBGTNmQKtV/u+Zk5ODK6+8EpMmTYJer0f//v3xwAMPyOG+fv16aLVa\nzJ8/H9HR0ejRowfuuecexTUWLlyIRx55BAMGDIBWq8XQoUNxww03YOXKlX632WQy4YYbbsB5552H\nyZMn+/Qem82GZcuW4YknnkBWVhaioqJw33334ZxzzsG7774LAIiKikJeXh7+/PNP6PV6ZGdno1Wr\nVvJrubm5OHHiBKKiojBo0CDEx8f73XYitWBIE4WBzMxMjBgxAi+88AI++eQTTJs2ze2cY8eOoUuX\nLopjWVlZyMvLAwDk5+ejffv20Ol08uudO3dWnH/w4EHcd999SElJkf+sXr0aJ06c8Ku9VVVVGD9+\nPIxGI9avXw+9Xu/T+woKClBdXV3n97Fy5UpoNBqMHDkSmZmZmDVrFioqKgAA69atw+HDh9G/f39k\nZWXhscceC+hMdKJw49v/WUQUdLfffjvGjh2La6+9Fm3atMHRo0cVr7dv3x65ubmKY7m5uejQoQMA\ne9AfO3YMVqtVDmrXa7Ru3RoLFizAzTff3OB2FhcX48orr0SLFi2wdu1axMTE+Pze9PR0xMTEIDc3\nF7169VJ8HwMHDgQAdOzYEW+99RYA4NChQ5gwYQLi4+Px5JNP4vzzz8eqVasAAHv27MHo0aORmZmJ\nGTNmNPj7IQpnrKSJwsTo0aOxceNGLFq0yOPrt9xyCz777DN8+OGHsFqt2L17N55//nnceuutAIBx\n48bBarXin//8J4xGI/bv34/FixcrrjFr1iw8/vjj2LFjB2w2G4xGI3bs2IFdu3b51MZTp05h+PDh\naN++PT7++GO/AhoAtFotbrnlFsybNw+HDx+GyWTCokWLcOjQIdx0000A7JV0fn4+JElCUlIS9Ho9\n9Ho9TCYTVqxYgbNnzwIAkpOTodPpfK7iiVRJIqKQGT58uPTII494fO3IkSMSAOngwYPysU8++UTq\n27evlJiYKHXp0kV65plnJIvFIr++bds2acCAAVJ8fLzUv39/6cUXX5Rc/zd/9913pX79+knJyclS\nWlqaNHz4cOmbb76RJEmSvvrqKwmAZDabPbZp/vz5EgApLi5Oio+Pl/+MGTPG6/e4YsUKqV27dvLz\nqqoq6f7775c6dOggJScnS0OGDJF++OEH+fWbb75ZatOmjRQXFye1bt1amjlzplRZWSkZjUZp7Nix\nUkZGhhQXFye1b99e+sc//iFZrdY6fsJE6qaRJEkK7ccEIiIi8oTd3URERGGKIU1ERBSmGNJERERh\niiFNREQUphjSREREYUr1NxhGR0cjIyMjINc6XXYCsEloldIuINcLN+WmcpTVlEGr1aJNQptQN4eI\niACcPXsWRqPR42uqD+mMjAx5Yf7G6vaPRESVVmDf64G5Xrh5dsuzmLN5DtLi0pD/QGR+j0REapOZ\nmen1NXZ3CzQAJE2oWxE8EnhLPBGRmjCkBRpoGGNERBQ2GNKCiK+kubgcEZGqqH5MOpA00MAGAJIE\naCI4rYlIVWw2Gz9kq5hGo3HbH95XDGmBXElHaEhzTJpIXUwmE/Ly8mA2m0PdFGokg8GADh06ICoq\nyq/3MaQF8pg0P7ESURjIy8tDYmIi0tLSoInAwqG5kCQJhYWFyMvLQ1ZWll/vZUgLOCZNROHCZrPB\nbDYjLS2Ne2ZHgLS0NBQVFcFms/nV9c2JYwINwEqaiMKC40M1K+jI4Ph39LdYYkgLNKj9nyFCQ5pj\n0kRE6sKQdiFPHCMiIll2djays7PRo0cP6HQ6+fkNN9zg97X+7//+D999912957322mtYtGhRQ5ob\nMDabDfPnz4fJZArJ1+dAhyDSFzPhmDQRNdSePXsAAEePHkV2drb83BOLxVLnOPqKFSt8+pp33nmn\nf40MApvNhgULFuD+++/3e2Z2IDCkBYpbsIiIwsn48UBubnCu3aULsG5dg9++adMmzJ49G/369cOe\nPXswb948VFZW4pVXXoHZbIYkSXjqqacwduxYAMDQoUMxZ84cjBs3DpMnT0ZiYiIOHDiA/Px89OnT\nB6tWrYLBYMDcuXNRU1ODF154ATk5OXj//feRmpqKX3/9FbGxsfjPf/6DTp06AQDmzp2LNWvWIDU1\nFZdffjnee+89HDp0yK2tS5cuxeLFixEVFQWbzYbly5djwIABOHDgAGbNmoWCggIYjUbcfvvtuP32\n23HbbbcBAAYPHgytVovNmzcjLS2twT8rfzGkBbwFi4ioYX755Re8/vrrGDp0KACgoKAAkydPhkaj\nweHDhzF48GAcO3YMBoPB7b179+7F5s2bERUVhSFDhmDt2rW4/vrr3c7btm0b9u7di44dO+L+++/H\n888/j9deew2ffPIJ1q9fjz179iA+Ph4333yz13bOnj0bR44cQcuWLWE2m2E0GmE2m/HXv/4Vq1ev\nRteuXVFZWYkLLrgAF154IZYsWYJly5bhhx9+QEJCQuB+YD5iSAsivZLmxDEiFWtEpdsUunbtKgc0\nABw+fBg33XQTjh8/Dr1ej6KiIvz5558e7xOeOHEiYmNjAQADBw5Erpceg6FDh6Jjx44AgEGDBuGt\nt94CAGzevBmTJk2SQ3TatGn48ccfPV7j0ksvxeTJkzFu3DiMHTsWWVlZ+Pnnn/H7779j0qRJ8nlV\nVVX47bff0Lt37wb8NAKHIS2I9DFpIqJgca0yJ02ahJdeeglXX301ACApKQk1NTUe3xsTEyM/1ul0\nsFgsjTqvrtvWPvnkE+zcuRNff/01Lr/8cjz77LPo2rUr0tPTPY6ze/saTYWzuwURX0lH6PdFROGn\npKQEnTt3BgCsXLkS5eXlQftaI0eOxAcffIDKykpIkoTly5d7PM9sNuPw4cMYOHAgHnjgAUycOBE7\nduxAjx49EBsbi3feeUc+9+DBgygpKYFer0dcXBxKS0uD1v66sJIWcEyaiCgwFi9ejAkTJqBFixYY\nNWoU2rVrF7SvdfXVV2P79u3Izs5GcnIyhg0bhpSUFLfzzGYzpk6dipKSEuh0OrRs2RIrV66EwWDA\np59+invvvRfPP/88rFYrMjIysHr1aqSkpOC+++7DiBEjEBcX1+QTxzSSysurzMxM5OfnB+RaF/0j\nA/mmAuQvKAdCMEEg2OZ/PR8LvlmAjLgMnHngTKibQ0R1sFqt+OOPP9C1a1fodLpQNyfslZeXIzEx\nEZIk4Z577oEkSXjllVdC3SxZXf+edeUYK2kBx6SJiNTppptuwrFjx1BTU4Pzzz8fS5YsCXWTAoIh\nLZCnGqi7c8ErlXeaEBF5tS7MZ783FCeOuYjkiWNERKQuDGmBRhPZE8d4nzQRkbowpAUaaCJ6P2ki\nIlIXhrQg0veT5pg0EZG6MKQFciXNMCMiUhg7dixeffVVt+N9+vTBRx99VOd758+fj1mzZgGwT/C6\n9957PZ73yy+/yBtm1OXo0aNus7fHjh2LAwcO1PveYFq5ciX2798f0GsypAURX0lzTJqIGmjatGlu\nW0zu3LkTJ0+exFVXXeXzdcaPH9/oPaI9hfSGDRvQrVu3Rl23sRjSQcYxaSIiz8aPH49jx47h559/\nlo8tX74cN998MwwGA/bt24ehQ4eiX79+6NGjB5544gmP11m5cqW8njdgr7LPPfdc9O/fH2vWrJGP\nWywWjB49GgMGDEDPnj3x17/+FZWVlQCA2267DQcOHEB2djbGjx8PAOjUqZO89vahQ4cwatQo9O7d\nG9nZ2Vi7dq18XY1Gg6eeegoXXHABOnfu7HVv661bt6J///7Izs5Gr1698MYbbwCwL5oyY8YMXHDB\nBejduzduvfVWmEwm5OTkYOfOnbj33nuRnZ2NDRs2NOTH7Ib3SQsivZImIvUav3o8couDs590l9Qu\nWPeXuu8zNhgMmDJlCpYvX46XXnoJNTU1WL16NX744QcA9pDcvHkzoqOjUV1djcGDB2PUqFG46KKL\nvF7zs88+w/vvv49du3YhMTERU6ZMkV/T6XRYtWoV0tLSIEkS7rjjDrzyyiuYM2cOlixZglmzZnnc\nEAOwL2xyyy23YObMmTh48CAuuugi9O3bV95BKzo6Gtu3b8f+/fsxcOBATJkyBXq9Mg6ffvpp3H//\n/fjLX/4CACguLgYA3Hfffbj44ovx1ltvQZIkzJgxA4sXL8YDDzyAd999F7NmzVJ8CGkshrQg0sek\nOXGMiBpj2rRpGD58OJ577jl89NFH6N69O7p37w4AqK6uxh133IE9e/ZAq9Xi2LFj2LNnT50h7dhi\nMikpCQAwc+ZMbNmyBYD999WiRYvw2WefwWKxoLS0FIMHD663jeXl5fjpp5/w/fffAwDOPfdcDB06\nFN99950c0jfddBMA4LzzzoNer8epU6eQmZmpuM6IESPw+OOP4+DBgxg5cqS8DefatWvx448/YuHC\nhfL3HcxlWxnSAm6wQUThqr5Ktyn06NEDWVlZWL9+PZYvX45p06bJrz388MNIT0/H7t27odfrMXHi\nRK9bU3ojbjG5atUqfPnll/jmm2+QlJSEl19+GV9++WWD2u26daUvW17OmjULEyZMwKZNm/Dwww+j\nV69eeP311yFJEj788EN07dq1QW3xF8ekBZE+HM2JY0TUWNOmTcNTTz2F7du344YbbpCPFxcXIzMz\nE3q9HgcOHMDGjRvrvdaoUaPw/vvvo7y8HJIk4c0331RcLz09HUlJSSgvL8fKlSvl15KSkrxuHZmY\nmIh+/frJY82HDh3Cli1bMGzYML++zwMHDqBz586YMWMGHn74YWzduhWAfcetZ599Vg724uJiHDp0\nqN52NRRD2kUkd3cTETXWDTfcgAMHDuD6669HgrBb4Ny5c7FixQr07t0bc+bMwciRI+u91tixY3Hd\nddehX79+GDBgADp06CC/dvPNN6OqqgrdunXDFVdcgYsvvlh+rXfv3ujZsyd69eolTxwT/fvf/8Z7\n772HPn364LrrrkNOTo7i2r549dVX0bNnT/Tt2xdz587Fiy++CABYtGgRYmNjkZ2djd69e+PSSy/F\n0aNHAQC33nornnrqqYBOHONWlYLLHmmP7bZ8lM46BbRqFZBrhpN/bPoHnvn+GW5VSaQC3KoysjR0\nq0pW0oJInzhGRETqwpAWyLdgRSiOSRMRqQtDWsBKmoiIwglDWhDpi5mofPoBUbPiuG2I/99GBse/\no+vtYPUJ+n3Sd999N9atW4c///wTu3fvRnZ2tsfz9u3bh7vuugunT58GADz55JOYOHFisJunwEqa\niMKFVquFwWBAYWEh0tLS/P7lTuFDkiQUFhbCYDBAq/WvNg56SF933XV48MEH5dVaPKmqqsKECRPw\n9ttvY+jQobBarSgqKgp209xoNJqIHrXlmDSRunTo0AF5eXkh+X1IgWUwGPy+DQxogpD25QbyVatW\n4aKLLpKDXKfTISMjI9hNc6ORAEkLVtJEFBaioqKQlZUFm83Gbm8V02g0flfQDmGxLOhvv/2G6Oho\njBs3Dvn5+ejduzdefPFFj0G9cOFCec1UAKioqAhYO+RKmv8zEFEYaegveFK/sPiXt1gs2LRpE5Yu\nXYrdu3ejXbt2uP322z2eO3v2bOTn58t/xBVvAiZCQ5qfxImI1CUsQrpDhw4YMWIE2rVrB41Gg8mT\nJ8vrpDYl7idNREThJCxCetKkSdixYwfKysoAABs2bECfPn2avB2RvgsWJ44REalL0EN65syZ8rqk\no0ePRlZWFgBg+vTpWLfOvvVahw4d8PDDD2Pw4MHo3bs3vvzySyxZsiTYTXOjATfYICKi8BH0iWNL\nly71eDwnJ0fxfMqUKZgyZUqwm1OnSJ84xjFpIiJ1CYvu7nDBMWkiIgonDGlBpHd3c0yaiEhdGNIC\nDWrL6AgNaSIiUheGtEBe0N5mC3FLgoNj0kRE6sKQFjgqaXYLExFROGBICxxzxiK2kuaHDyIiVWFI\nK3BMmoiIwgdDWiBX0lKEVtL88EFEpCoMaYE8cYzdwkREFAYY0gJ54liEjkkTEZG6MKQFzu7uyKyk\n2UNARKQuDGmBXElH6Jg0ERGpC0NaEOlj0pHaQ0BEFKkY0oLmMibt+DBCREThjSEtiPTu7kjtISAi\nilQMaYFGXsuEYUZERKHHkBbIu2BFKMeHD34IISJSB4a0B5E+Jk1EROrAkBZwTJqIiMIJQ1og34IV\noSFNRETqwpAWOPeTjkwciyYiUheGtCDS95MmIiJ1YUgLIn1MmoiI1IUhLYj0MWlOHCMiUheGtCDS\nx6QduCwoEZE6MKQFkb52NyeOERGpC0NaEOnd3UREpC4MaYG8LGiEVpwckyYiUheGtMiR0QwzIiIK\nAwxpgfMWrMgMaW6wQUSkLgxpAe+TJiKicMKQFsgTxyJ1dje78YmIVIUhLWgu90kTEZE6MKQF8trd\nEdrdzbFoIiJ1YUgLeJ80ERGFE4a0IOJnd9d25HNZUCIidWBICyJ94hgREakLQ1rgnDgWmZU0ERGp\nC0Pakwjv7iYiInVgSAucE8cYZkREFHoMaUGkrzjGDx9EROrCkBbIlTS7hYmIKAwwpAXN5RasSP3+\niIgiDUNaEOnd3UREpC4MaUGkTxxzfF9czISISB0Y0oJID2kiIlIXhrQg4jfY4IQ4IiJVYUgLNLU/\nDlbSREQUDhjSgkjfBYsfPoiI1IUhTUREFKYY0gLegkVEROGEIS2I9NndnDhGRKQuDGlBpI9JExGR\nujCkBc79pCNTpPYQEBFFKoa0gGPSREQUThjSAo5JExFROGFICzgmTURE4YQhLXCOSUdmxRmpPQRE\nRJGKIS2I9P2kiYhIXRjSgkjv7o7UHgIiokjFkBbJ22CFtBVEREQAGNIK8i5YEZrS7MYnIlIXhrQg\n0veTJiIidWFIC3ifNBERhROGtECjqe3ujtCQdoj074+IKFIwpAW8BYuIiMIJQ1qg0dZW0lZLiFsS\nHPzwQUSkLgxpgcZgAABIZlOIWxJcHJsmIlIHhrRADmmjMcQtCQ6GMxGRujCkBRp9FABAMkV4Jc1u\nbyIiVWBIiwx6+98RGtIMZyIidWFIC+TublNkdnc7sNubiEgdGNICjaG2u5tj0kREFAYY0gI5pCO9\nkma3NxGRKjCkBc7ubhMwYgTwyCMhblFgMZyJiNSFIS2QK+maauDrr4Gnngptg4iIqFkLekjffffd\n6NSpEzQaDfbs2VPnuZIkYeTIkUhJSQl2szySQ7qsLCRfP9gcY9IcmyYiUoegh/R1112HLVu2oGPH\njvWeu2jRInTp0iXYTfJKo9MBAKTSEudBszlErSEiouYu6CE9bNgwZGZm1nver7/+irVr12LOnDnB\nbpJX8i5YpaXOgydOhKg1wcOxaSIidQiLMWmz2YwZM2Zg6dKl0NVWs94sXLgQmZmZ8p+KioqAtUPe\nT1qspPPyAnb9UGM4ExGpS1iE9IIFCzBx4kR079693nNnz56N/Px8+U9CQkLA2iFvVVlT4zx47FjA\nrh8uOCZNRKQO+lA3AAC++eYb5OXl4dVXX4XFYkFZWRk6deqEHTt2ICMjI7SNi6RKmuFMRKQqYRHS\n3333nfz46NGjyM7OxtGjR5u8HXJ3t0Y4eOZMk7cj2NjtTUSkDkHv7p45cyYyMzORn5+P0aNHIysr\nCwAwffp0rFu3Lthf3i9yd7d4sKAgJG0JBoYzEZG6BL2SXrp0qcfjOTk5Ho936tQJJSUlHl8LNo+V\n9NmzIWlLMLHbm4hIHcJi4li48FhJR1BIM5yJiNSFIS1wq6RbtYqo7m4iIlIXhrTArZI+55zIqqRr\nx6Q5Nk1EpA4MaYFbJd2pE1BVZf9DRETUxBjSArdKunVr+98RUk1zgw0iInVhSAsUlbTBADgWUuG4\nNBERhQBDWiBX0gkJwL//7ayk8/ND2KrA4Zg0EZG6MKQ9eftf+HlYN3QpeBSfdAOwa1eoW0RERM0Q\nQ1ogd3cDuHjFxThcdRwf9tICO3YAJlNoGxdAHJMmIlIHhrQgOToZAJBblIsyYxkAwJKUAHzxBTBi\nBKDybmKGMxGRujCkBYPaD4IGGqz5dY187FTHFvYHP/wA7N0bopYFFsekiYjUgSEtaBHbAn1a98FP\nJ3+Sj51KjwU2b7Y/WbUqRC0LDIYzEZG6MKRdDO84XPH8ZMVJe1e3Xg8cOBCiVhERUXPEkHaR3Tpb\nftwusR1KakpQYzUC6emqv1+ai5kQEakLQ9pF71a95cd92/QFAJyuOA2kpQGFhaFqFhERNUMMaRfd\n07vLj/u17gcA6LOkD0wZLdRfSXMxEyIiVWFIu4g1xMqPx2SNAQCUGkuxK1MLFBUBVmuomkZERM0M\nQ9qDj2/4GG+OexOD2g/C5pvtM7u3ZNTY75MuKQlx6xqOY9JEROqiD3UDwtHV510tP76w3YXQa/XY\nklCEBwB7l3daWsjaRkREzQcr6XrER8XjosyL8F/dEeQlQ9WTxzgmTUSkLgxpHzw67FEYYcGLgwBc\ncglQVhbqJhERUTPAkPbBZedchmiNAYdaADCbge+/D3WTGoRj0URE6sKQ9oFGo0FaTAsUxNUeOHs2\npO1pLIY1EZE6MKR9lJ7UCoVZbe1PTp8ObWOIiKhZYEj7KC02DYW2CvuTBx8E7rwztA1qAE4cIyJS\nF4a0j9Li0lBiKoPF8RN7/fWQtoeIiCIfQ9pHabH2e6OLY0LckEbgYiZEROrCkPZRelw6AKAwTjhY\nWRmaxhARUbPAkPaRo5IujBUOqmyWN8eiiYjUhSHto7Q4e0gXtE50HjxzJkStISKi5oAh7SO5kn5m\nHvB//2c/qLKQFseiWVUTEYU/hrSPWiW0AgCcMpiAa6+1H1RZdzcREakLQ9pH56SeAwDILcoFWra0\nH1RbJc3qmYhIVRjSPmoR2wIpMSnILRZCWsUrj/E2LCKi8MeQ9kOX1C72kG7TBoiOBn77LdRN8guD\nmYhIXRjSfujSoguOlx1HjdYGXHAB8MMPgNUa6mY1CLu+iYjCH0PaD11Su0CChCPFR4CLLwbKy4G9\ne0PdLCIiilAMaT+0TbTvgnW68jQwaJD94E8/hbBF/hGrZ3Z9ExGFP4a0HxKj7AuZvL33bXymOWg/\nWFgYwhYREVEk04e6AWqSEJUAAFixZwVWAPZatLg4lE3yCxczISJSF1bSfnCEtIKKQpqIiNSFIe0H\ntYc0x6SJiNSFIe0Ht5BOSlJVSBMRkbowpP3gGtKmFsmqCmlWz0RE6sKQ9kNidKLieXmGeitpThwj\nIgp/DGk/uFbSFS0SgZKSELXGfwxmIiJ1YUj7IVYfq3he3iLeHtI2W4ha1HDs+iYiCn8MaT9oNBrF\n84rkWHtAl5eHqEX+YTATEakLQ7oRypOi7Q9UOC7Nrm8iovDHkG6Ed+JzYdJBNSHNYCYiUheGdCO8\nI+3BQ6OgmpAWseubiCj8MaQb6duOUGVIExFR+GNIB4JKQprVMxGRujCkG+l0AlQT0iKOTxMRhT+G\ntJ92z9yNJ0Y8IT8/ngSUF58KYYt8x2AmIlIXhrSfsltn495B9yqO5Zbnhag1DceubyKi8MeQboA4\nQxwqH67EolEvAABKqgpD3CLfMJiJiNSFId1AcYY4pCW0BACUVHFMmoiIAo8h3QjJMckAgFJjaYhb\n4hsGMxGRujCkGyE5ujakzRUhbon/2PVNRBT+GNKNkBKTAgAotVSGuCW+YTATEakLQ7oRHN3dJVI1\nkJMDHDkS4hb5jl3fREThTx/qBqiZ3N0dLQEzZgAZGcCZMyFulXcMZiIidWEl3QhJ0UkAgNLaHStx\n9mzoGkNERBGHId0IOq0OiYhCaUyoW+I/jk8TEYU/hnQjJWvinJV0mGMwExGpC0O6kZL18ShxVNIG\nQ0jb4g+OTxMRhT+GdCOlRCU5u7tj3Pu9j5cdR25RbtM2ygsGMxGRunB2dyOlxKSgOAawaAG9h5DO\nXJQJAJAeC6+AZNc3EVH4YyXdSNnpvWDSA7tbw2MlHU4YzERE6uJzSM+bNw8lJSWQJAlXXnkl0tPT\n8eGHHwazbapwSecRAIAvO5d7TJQAACAASURBVAPQ6ULbGD+w65uIKPz5HNKffPIJUlJSsGnTJuj1\nenz//fd44okngtk2VRjUdSQAYM5lQE6nohC3pm4MZiIidfE5pLVa+6nffPMNrr/+enTr1g0ajSZo\nDVOL+JSWmPuN/fFPKdWhbQwREUUUn0M6Pj4ezz77LNasWYPLLrsMkiTBZDIFs23qoNFgzhb7wyqN\nJbRtqYc4Js3xaSKi8OdzSK9cuRInT57Ec889h1atWiE3NxeTJ08OZttUI/bzjQCASr0EmM0hbg0R\nEUUKn0M6KysLL730EiZOnIjS0lLU1NRgzpw59b7v7rvvRqdOnaDRaLBnzx6P53z55Ze44IIL0KNH\nD/Ts2RMPPvggbDab799FiGkvHYVYmw5VBgDV4dvlLY5Jc3yaiCj8+RzSY8aMQUlJCSoqKtCnTx+M\nGzcO8+bNq/d91113HbZs2YKOHTt6PSc1NRVr1qzBb7/9hl27duGHH37A22+/7WvTwkI8DKiMAlBV\nFeqmEBFRhPA5pE+fPo2UlBRs2LABEyZMwMGDB/Hxxx/X+75hw4YhMzOzznP69u2Lc845BwAQExOD\n7OxsHD161NemhYU4RIV/Jc0xaSIiVfE5pM21Y63ffvstLrvsMhgMBuj1gV+w7NSpU/jggw8wbtw4\nj68vXLgQmZmZ8p+KioqAt6Eh4jVRqDRAUUlbbVb5sU1ST/c9ERGFB59DulevXrjiiivw6aefYuTI\nkagKQrduWVkZrrrqKjz44IMYMGCAx3Nmz56N/Px8+U9CQkLA29EQcdpoubv7n9/8E+//+j5MVufs\ndzGwwwHHpImIwp/PpfDKlSvxxRdfoE+fPoiLi8Px48fx9NNPB6wh5eXlGDNmDCZMmIDZs2cH7LpN\nJV4XgzwDYKuqxGNfPwYAKHmoRH7dKllhQGh3yWIwExGpi8+VdExMDPr3748ff/wRq1atgiRJGDNm\nTEAaUVFRgTFjxmDMmDGYO3duQK7Z1OJ0sag0AMUnDsvHwrqS5pg0EVHY82tZ0L59++L999/H+++/\nj379+mH9+vX1vm/mzJnIzMxEfn4+Ro8ejaysLADA9OnTsW7dOgDA4sWLsX37dnz00UfIzs5GdnY2\nnnzyyQZ+S6ERb4hFVRRw5u5p8jFFSEuhD2kGMxGRuvjc3b1gwQJs3bpVDtlDhw5h0qRJuOqqq+p8\n39KlSz0ez8nJkR8/8sgjeOSRR3xtSliKj00GKoAVfZ3HzDbnwibhVkkTEVH487mStlqtckAD9sVN\n1LTgSLDFZbQFADw/xHks7CppLmZCRKQqPod0y5YtkZOTA5vNBpvNhmXLliEjIyOYbVOV+GT3n4UY\n0habb+t6F1QVoMrMBVGIiMiPkF6yZAlycnIQGxuL2NhY5OTkYMGCBcFsm6rEGeLcjjVk4tjgZYMx\nde3UQDVLgYuZEBGpi89j0l26dMHWrVvlxUMSEhLQoUMH5OXlBa1xahJviFc8j7ZqYLIY5ee+dnef\nKD+BNoltAto2IiJSJ7+XDBMXD+G4ppPr3top1RLMv+yVn/taSZusJp+7xv3FMWkiInXxubvbE9dg\nas4KqgoUzyUAu7eulZ9bT5+s9xo2yQazzRy0kCYiInWpt5L++eefvb5m5t7JMkel3K9NP/xZdARn\nUIx78F/n68OHAafrDl+z1f7zDFolzTFpIiJVqTekJ0yY4PW12NjYgDZGzeYOm4tSYymevvRpTP7P\njfhf3peK1y2SFSU1JThVcQrnpZ/n8RpGq30Mm/dUExER4ENIHzlypCnaoXqpsanIGW9foMUQFeP2\nulULDHxrIA4VHUKF9lHEjxwNDBmiOMcxG7wpurs5Jk1EFP4aNSZNnhn0UW7HrBrgUNEhAED1M48D\nQ4e6nWOsnQ3eFBPHiIgo/DGkg8Cgdd/tyir8pK1e5ts1ZSVNREThjyEdBAadh5AWgtms8/w+x5g0\nJ44RERHAkA6K+ipps5efOitpIiISMaSDwFNIW4SftMlbJd2EY9IcnyYiCn8M6SCI0nmeOObgrbs7\nkirpwqpC2CTukkZE1BgM6SDwOCbtSyXtuE86SNta+jomLUlSoz4onCw/ifTn0zH5o8kNvgYRETGk\ng8LjmLRYSYf5mPSod0bB8Lj9e3hjxxtIeSYFFaYKn9+fW5wLAFj9y+qgtI+IqLlgSAdBgyvpMBmT\n/vKIc7W0OzbcgVJjKfad3heUNhERkXcM6SCot5JuBmPSRETUeAzpIGjsmLTFZgnK7OumujeaM8eJ\niAKDIR0EYiX93P/sf/tyC5ajkgYQ9JnRvgQ2w5aIKLQY0kEgVtKdSux/+zJxzDEmDQSny9vf0G3o\nLHOuZkZEFBgM6SAQ75PW1eaVP93dQPBuw3LwJbDFLTM1Gi8LjhMRUdAwpINA7O7W1fZai9WzPHHM\npuzSFru7w2HyWDi0gYioOWNIB4HY3e2opKuFuWRyJW02A2VlwMmTwPTpMJYUyOd4Dch//QvYs6dB\n7fJ3gw2xmuf4NBFR09OHugGRSKyk9bXFcpUQ0nJVvX07MGyYfNyEc4D29sceQ7q6Gpg61f64CUKz\noZU0A52IKDBYSQeBopL2ENJyJS0ENAAYy4rkxxabBWcqz+BoyVHhBCMaw98NNsQxaSIianoM6SBQ\njEnfeCMAoLrf+fIxr7dg1VTKjy02C1q90AqdF3d2nlBTE9iG1kOspP2ZOMbZ3UREgcGQDgJFJT3j\nNgBA1ehL5WPeVhwz2szyY49dzY0M6caMSRMRUdPjmHQQKCpprT2Rqy3V8jHXSloC8G1H5eQyj13N\nIayk/cExaSKiwGBIB4HYNazT2BO5ylwlH3NdzCSnH3DreOWxoFTSfoan2AZ/3st9pImIAoPd3UEg\nBpqjkhZD2rWS3pbpfg2PId3IiWMifyeO+RO87CYnIgoMhnQQiIGm19o7KxSVtEH5Y7d6mJNlsZrd\nDwZwTNoX4gcFv0Kas8KJiAKCIR0EYqA5ursVY9LndFScb/Xwr2A5fcL5uiP0Ajgm7e/EMX+qY3Z3\nExEFBkM6CBQh7aG729y+rfPkK6+EzVMlnfOm83zHrO8Qjkmzu5uIqOkxpIMgIz4DANC3dV+5kt5+\nfLv8uklbG5axscAll3ju7v50vfOxIywDWUkHcUyalTQRUWBwdncQDG4/GB9c/wGGdxqOouoit9dN\nFvtGGqXJ0SiJNXqspMUucLM1MJW0L8Tw5pg0EVFosZIOkmt7XIv0uHS5khaZa3e7On9yOToVzPU8\nJi2GdEWpfa3uJljMxNs4NCtpzxZvXYzOizs7P0gREQUQQzrIHLO7RSaLEf/tAhxLsIdgjYf+DIvB\nGe7mLp2B119XhrS37uqaGuC55+ybcTSAWD1zTLp+s/47C0dLjuJE+Yn6TyYi8hNDOsgcE8dE63EA\nY6Y4n1d7CumW6c7HWgAvvqgMaZPJ/U0A8OijwEMP2f+48GWDDbGruqEh3ZwqaSKiYGJIB5nY3f33\ngX9HUnSS2zniDlkOllYZ8mOzDsC55ypD2tvCJnl59r9PNKyyE4O5wYuZcEyaiCggGNJBJlbSDw19\nCDH6GLdzPIa0UEmbtQBKSnyrpK21Aal1/6f15d7oQHR3s5ImIgoMhnSQiZV0SkyKYvMNh2pPIZ2e\n6nysBXD8uG+VtCOkdToUVhWixuJ5slkwJ441pzFpIqJgYkgHmVhJxxviEaWLcjun0kNIm5Od3eJm\nHYBTp4BK537T9Ya0Vov059PR5eUu8ku+3BvtrZL2pwublTQRUWAwpINMnN2t0WgUe007lCVHy4+j\ndfbHxuR4+ZhZC3v4OsabAe8hbasNSJ39w4G3WcfST7s8HueYdMP4uy46EZEvGNJB5nqftCOERRWS\nM3DjDHEAgJqkOPmYuUc3+4NDh5xv8jGkRYog2brV49sDMbu7OXZ3cw9tIgoGhnSQud6CFWuIrfN8\nOaTjnWFu6XGe/UFurvPEeiaOWXUeljETSF5eVlTSXMzEZ83xgwkRBR9DOshcK+lYfd0hHR9l7+au\niXV2i5v7nO9+Yj1j0mYPId2YMWl2d9etOX4wIaLgY0gHmVZj/xG3TbTvfOVzJS05l5k09+rufuKu\nXcCqVe7HHSEtWdxfE3hdzESc3c0NNnzWHL9nIgo+brARZBqNBnmz8pAckwzAh0raUFtJC7dOWZIS\ngA4dlBPH7r3X/veECUC8c5KZHNIm91uvmuo+6ebY9dscew+IKPhYSTeB9snt5ZXGPC1mInJU0j+d\n/Ek+ZraagXPO8fyGDh2AnBzn8zpC2hdcFrRhmuP3TETBx5BuYvVV0o6Q/uroV/Ixs80MTJwItG0L\n3HST8g1FRcCMGc7ntWPVZnPdIR3MiWPNsapkSBNRMDCkm5ivY9Iii80C3HWXfdWxG2+s+wtUVQEA\nzCb3XbAU49Beer65LGjDNMcufiIKPoZ0E/N1TFqk2Ks42v0+awVHSJu9zP6u5dOyoDbPS4TWpzkG\nVnP8YEJEwceQbmL1VdKetrY024SQNpvdXleo3UfaU0hzg43gaY5d/EQUfAzpJlbfxLHs1tnomdFT\ncUxRSQ8dCoweDXz8sfKNhw8D333nrKQt9VXSnnFMumGa4wcTIgo+hnQTq6+7O1Yfi+UTliuOicGJ\npCTgiy+AMWPkQzvaAtc83AXVI4fJm3CYLcKKZMXFAFzGpC2e76Pm7O6GaY7fMxEFH0O6idXX3R2t\nj3Zb31vR3e0Q46zIh94CrO0OfNgDQG0Qi5W07cqxbm+XLJ67zQOywYbLmHRpTSm6vtIVH//+sZd3\nqF9zHIcnouBjSDex+ippnUbn1iWu6O72wFL7r6gVCmWxkjZvt2+moRiT9jK2HYxlQTce3oiDRQcx\n8T8Tfb6G2rCSJqJgYEg3sfoqacBeTYssNgve2fsOrvj3FYoArDxxFJr5gK32X1En5ITZ6gxpk2Mu\nmsX5Xslbd7cU+O7u5rBDFEOaiIKBy4I2sfoqaY1G47G7++a1NwMATleeltcBPx6lnBymEwtlIaTN\nOgBms72L2/Ev7kMl3eCJYy5dv81hr+XmOFmOiIKPlXQTq292twYat0pa7O4Ww9K1QlV0dwvvMWsB\nlJUpv1AQu7tZSRMRBQZDuonV193trZJ2KK4uxtPfPY2T5ScVm3AAQki3bg2zELAmHYCyMkU9623i\nmGIBk4ZOHGuGVSVDmoiCgd3dTay+7m7A85i0w6QPJmF/wX6Um8pxVderFOfJIdy1K8xFp+Tj5tqQ\nVl7U85i0t0ran+B1q6SbQ3c3Z3cTURCwkm5i3irpc1Ltu1ylxKRAr1V+djpQeEB+vL9gPwD7Gt+V\n5krFeWbHBLFOnexd3I7jWgClpYpNNSQv3d2KZUEDNSZd292tgZddPSIAK2kiCgZW0k3MWyX97dRv\nse7AOozoNMLttS8OfeF2zCbZUGWuUhyTZ3HHxTkDG87ubgUf7pMO2Jh0bSWt0TCkiYj8wUq6iUXp\nojweb5fUDrcPvN3nIDNajKg0uVTSWthXJIuOVlbSHkI6V1eO3KJct+sGY3a3472RXEn7Ow7fHMft\nich/DOkmZtAZFM+nZk/Fnpl7/L6OyWpyq6TNL70IHDsGpKQoKun+M4FvCnYqRob/2uM3ZL2S5Xbd\nYCwL6uju1moi9z83f34+x8uOQ/+4Hs9ueTaILSKiSBC5vzXDVMv4lnh02KPy84vaXYQ+rfv4fR2j\n1eg2Jj3z6/uw4KdFwPXXKyppALit+F2frhuQZUGF90mSJFfW/nZ3f37wc7y87WW/3hMq/vx8tubb\nV4Cbs3lOsJqDn0//jHd/9u3fnIjCF0M6BP454p9IiUkB4PvM5/eue0/x3FMlDQDzv5kP9OwJc8d2\niuP7cRZWD//arvcwiyEt3vrV0EpagiTfs+1vd/fYVWNxzxf3+PWeUAm32d19lvTBlI+nwCQsakNE\n6sOQDhF/A8v13mmj1X1MWmROTXE7Jnn4kq5BL4aN+Au+oWPSNskmhz0njjU9jn0TqRtDOsTqW41r\nwSUL8Mff/3BbqcxbJe1gjvM8Qc1VcU2x4rmikvay0ll9XBdEqW+DkEgQtiEdZhU+EfmHIR3mLjvn\nMpybdq7bAif1hnRMtNfXRMXVypA+XXFa8TUcGtrdraikGzi7Ww3VYLi2UbEXORGpDkM6zDkWNnHr\n7ra4TxwTmWMMXl8TFVUX4UzlGfx65ldIkoTPD32OzimdkRqTCqPVuYGHPxWZW3e3tXHd3WoImro+\nxBgtRgxbMQxr969twhbZqeFnR0TeMaRD5G99/gYA6N+2f53nySHtRyVtk2wwR/sW0sU1xejychf0\neqMX9p3Zhz9L/8SV516JtLg0nKk8o7imrwJdSYsT2MJVXT+fXSd34bu873DNe9c0YYvswrXCJyLf\nMKRD5PnLn8eRe47ggnYX1HmeTmu/4dl1TNrTLVgOfxT+gaU1W3xqR3F1MSpMFQCAe/97LwDghl43\noE1CGxwvOy6f19Ax6UBU0moY066rp0Gn0Xl9LdhYSROpW9BD+u6770anTp2g0WiwZ4/3RTuWLVuG\nc889F126dMGMGTNg9rK2dKTQa/XolNLJ5/Ndu7vrqqS7v9Yd1ZJvt968u895L+2XR77E1eddjaEd\nhqJNYhtFd3coK+lwC5p9p/dhS57yQ1BdPx/XtdibUrj97IjIP0EP6euuuw5btmxBx44dvZ5z5MgR\nPProo/juu+9w6NAhnD59Gm+++Wawm6YKjl+yrt3dnpYFbYgvj3ypeH5e2nkAgNbxrRXHG3oLllWy\nNr6SDrPu7t5LeuPiFRcrjtX183H0hoQCQ5pI3YIe0sOGDUNmZmad53zwwQcYP348WrduDY1Gg9tu\nuw2rV68OdtNUQQ5pPyrpxoiPigcAtElsozge0jFpNXR31zH2G8o1y3kLFpG6hcWYdF5enqLS7tSp\nE/Ly8jyeu3DhQmRmZsp/KioqmqqZIWHQ2ieAiZV0jD4GJqsJpcZSv6832POPVRZniAMAtEloeEgH\nfEw6zCppT+r6+YQyKFlJE6lbWIS0P2bPno38/Hz5T0JCQqibFBS/3fEbnhv1HLJbZwNQThxLjk6G\n0WpEQVWB39cdmt5PfjzxN/fX4w32Srp1gofu7s8/d9/y0oNIH5P2pK6QDmX71fCzIyLvwiKkO3To\ngD///FN+fvToUXTo0CGELQq97hnd8cCQB+Tq01FRA0ByTDIKqgp8Xpd5fLfx6Jhs76nInDjVeR2j\n+7nx5TUAPHR3nz4FjB0LXHttvV/P9T5pRzsjbXa3uFpcXdVyKG+DYkgTqVtYhPS1116LdevW4dSp\nU5AkCUuWLMGNN94Y6maFFTHgkqOT5dum6rPnlh1Yc+0a7Lt9H4oeLFK8llzjfn78p/8FACRFJymO\n26prJ6lt2lTv1wxEJS0GYLh2d7t+n96wu5uIGiroIT1z5kxkZmYiPz8fo0ePRlaWfQ/j6dOnY926\ndQCAc845BwsWLMCQIUOQlZWFjIwMzJw5M9hNU63kmGT58YODH8TlXS73em6f9gMQa4hFYnQiUmNT\nlWHvqZIutodx9P6DiuNWre8BG4i1u8VgC9egce0x8CaU7ediJkTqFvQbOJcuXerxeE5OjuL5jBkz\nMGPGjGA3JyKI49Pd0rvh2cuehWaBMkQ3/HUDjpcfd32rgsdKurgCkCTEjLgcELY7rnPi2JkzgFYL\npKcD8L4LVn0V5Y/HfsQvZ37BjP4zFMEert3drh9GfDkP8H170kAI1w84ROSb0K2yQA0m3o6VEZfh\n8Zwrzr3C43GxyznGAmhtgE3oT4k/fhb47DNEu2SO7ccfvTeoVSv737Vd1G7d3bUhW1/YDl4+GAAw\nvd90xXh7uHZ3+7rftmtQNuWOWQxpInULizFp8k+UzrkNZXpcul/v1Wqc/+RRt9/pNkocn3sMuOoq\nRLv8breJJx48COzf7/VruN2CVRtmvgaG2WZWBGC4Bo3R4tuKbK49CAxpIvIVQ1qF6gvpv/T6i9f3\nJkQ5b1mL6n+hW0jH1WajzqVHVhHSXbsC3bt7/RreKmlfA8NkNQW0u3v78e24df2tAR+fFav9urry\nXb/vphwn5mImROrG7m4VeeGyF1Btqcax0mPyMdeQ3jRlE4Z1HOb1GuKs7ShdFDQuYRzvJQ9tftw9\nVdeYtCRJ9d6KZbKaFJV0Y7u7L8y5EAAwpfcUXNzx4nrO9p2v3d2uocxKmoh8xUpaRe4bfB/mDpur\nqKRTYlIU57RPbg+Dzvs2lW4h7fJ6vJdbrx0h/WsG8KZjd82//x04dMj9XCGExLW7Hc/rY7aalWPS\nAZo4Jv7cAsHX7m63SroJq1uGNJG6sZJWIccSoQlRCW5Vqesa364SoxPlx1G6KGi0OgDO0DB4yRpH\nSPe60/73db8BLV57Ddiwwe1cb2PSgD006tsVyrW7O1BBE+iQVnR31zW726VngZU0EfmKlbQKOSZ/\ntU9q7/aa677TrtwqaYOXqnvUKMVTmwaKG4eqHTl75IjbW72NSQO+hYZrd/eJ8hP429q/oai6qI53\n1S8Qs8TF700MaV8raZPV5Hbu2v1r8dtZD2u0BgDvkyZSN1bSKnS68jQAIDPJfXcxf0NanO0tGzcO\nuOMOYLtzdTGrFjjUwnlKjaf/ciQJ0Gi8jkkDfoS0EOyz/zcbABCnj8Mb496o9/11XbexxHb5GtJi\nUBotRsVzi82Ca967BgAgPRb4+6dZSbs7UX4CbRLaNHiZWqKmxEpahRwTxzxV0q77TrtyH5N2+UU1\nfTqQk+M2e9umAba3cz73GNIWeyAoKumaar9napuNVTC9s8L98o0MnECEtGtV7ODr7G6j1aj4+ZQb\nyxvdprowpJXWH1iPdgvb4aWtL4W6KUQ+YUirkKNa7pHRw+21+sakY/Wx8uMoXZR7NfHWW/bFSTp1\nUhz+qjPw8oXO5x5D2mifSKUYk37tVf8r6ZylML/xmtvxxo4pixO9Gso1cB18vU/aaDEqnvu6Brs/\nxHXPGdJKmw7be4fe/+39ELeEyDcMaRXKGZ+DecPm4e4L75aPOfZ/rq8LT3xdrKS7pnXF0nHKJVxd\nJ3htF3rX6wppMQytx/J8GpMWg91UdBZmD/9l1tdL4IkYWAHp7rb5391d15h0uSnwlbR4fYa0kuO/\n/6ZcmpWoMTgmrUJtE9tiwYgFimP7/77f765TsZJ+YPADmN5vuuJ1g9bg9Zd8taf5ZkYjbDYrSqqK\n5I9/NpfbqSxnTwHJ7t30NRbnQuJmnQZmnfvl6+sl8NhOS7X8ONDd3Ypby3xcu9toVY5JB6OSFtvI\nxUyUHB9KxQ9vROGMlXSESIpOQrukdvWfKBAraU+/tOq639pbJV2+b6diLXCr1aIM6cWLPF9PCGmT\nToLJQ0jrtB4O1iqqLsKBggNux0trSp3XDXBI+9rdrXiPJfhj0mrYQSxUWEmT2jCkmzGxkvb0S8ug\n9TOkTSYUb/oUABBXm4d7Y0tRaa6UT/EWGsqQ1njs7q5rTHnU26Nw3mvnuYVeqTGwId2g2d2SSyUd\n5DFp8WfMkFZiJU1qw5BuxqJ0UXIXstssbzSski7atQUAkF5lP/RRRiEA4JIS+8poFi9hJnZLm/We\nu7vFc1ztPrUbALDr5C7F8ZKaEvlxWMzudq2kgzAm7XqLFznxtitSG4Z0M6bT6rBxykZM6jkJk3tP\ndnvd70raaETx2TwAQFptnn6bVo54QzxGlKYCACzwHGaKSloreaykq83eQ9phW/42xfNgdnc36D5p\nlzHpYHR3K8akbVa8/+v7SH02FYVVhQH/Wmrxfd73WLx1sfyc3d2kFgzpZui+QfdBr9UjMSoR57c6\nH+9d9x5iDbFu5/ldSU+bhuIThwEAaVXOw+lx6Yi12ktjM+xhtvPETmQvycaZyjP26510bhpi0sHj\nmHSNtcb9YK2sFlkAgG3HlSEtVqqhmt3teguWeG4wurtdx6Rv+OAGlNSUYOPhjQH/WmoxdMVQzPrv\nLHm4oimXZiVqDIZ0M/TC5S/A/Ki5zhAG6q+kv8gCEv8B5DvWR9m3D8W1C56lCUVvQlQC9LXd6RbJ\nXuVN+XgK9p7eizeevAaQJFTPvks+36Sxeu7urqOSdlSnh4qUG34oKvRw6O52GZMORne365i0o2qs\nb8305iAQ/w0QNSWGNHlVZyU9bDBuu6UlKqKBVec7jxfVFuTpQiWdEJUAfW3hYqmyTyJzVDKaH34A\niopQczxPPt9sNXvu7q5jTLrMWAZAOeMaUE42C4dlQStNlR4raZ3G+8x1f3kbk2ZIO3tjOHGM1IIh\nTV7VVUlXj7oEuvgEAIBVmItT7CWkDTX2cLNU2UPJ8UtSKwEoL0eNJISfxeSxkj5SfARHS456bI+j\nIhUrZ9fnoRqTFt9Tbir3OCZd35rrDW0jQ1rJ8d8Dx6RJLRjS5FWdlbSlRt6cw5ru3HlD7u4WQ/ro\nCegPHwUAWHbvAl5/HVKZfUKXVgJQWqoY4zZZTR4r6QOFB9B5cWe340aLUQ5M19u0xMo6qN3dQvAe\nLDyIbfnb5A8iiu5tY7mykjbbP7Q0ZDU1b8SvJz6uK6T/tedfeGXbKwFrQ7iSQ5qVNKkEQ5q8qnNM\n2lIj/9K3jhktH3dU0i3EMem9v8vd3WYtUH7vnagptE8Y00gASkoUK5iZbWaPE8e8cXR1O9olCnh3\ntzBxTLy2GLxXv3c1Llp2Ee763D7O7lZJS003u1t87Ok2O4epn0zF3V/c7fX1SBGI9duJmhJDmryq\nr5J2jKNadc5f/kVD+iFZEwuD0PubYAJiarOiygAkPQzkJ9ufe62k/QhpcfKVGNLLdy/HB79/oLhu\nY9XX3S1Jkrw39Gs7XsP/cv/n1r0tBvpnBz8D4NvuYL7yNibNe6ad8xrY3U1qwZAmrzxV0o7qucZa\nIy/TaRH+KyqOkZCqT7CHb62E2CTE1WaQuCc1YN8C0y2kbWZUu/TMRtWRL2IlbbQa5a7Maeum4aeT\nPzmvG+i1u4Wq2lEdl9wZawAAIABJREFUF9cUAwBGnTMKCVEJmLZumuJDRJmpzOM634EMUG/BLLa3\nuao0KScuEoU7hjR55amS1mv10ECjGJOu1jhDp7imBKn6RCQJvYoJ3c6XQ/q3DOX1qg0ASktRJXwp\n02/7UOmyK6XYfe76C1YMacB9pyn5uC2ws7s9rd19svwkAGBQ5iDcc+E9yC/Lx97Te+XzXCtpALiw\n3YUBDVDFmHSQVx+rMle53fYWzhyz6TkmTWrBkCavHrn4ETmIRTH6GEV3d7nk7GIuqi5Ci+gUtBbW\n6EhISPMa0jV6AKdPo0SY3GzWQhHaAACts0vdZDUBJ04AG+2LczjGdR3tqbHUKFYaU7yvkerr7j5R\nfgKAfevQdon2DU+KqosA2MeEy03uIZ0el26/nzlAwaEIZim43d03fnAjzn3lXPxZ8mfArx0Mwbgv\nnSiYGNLk1eD2g2Gdp+yazWqRJYe0I8AdIW3V2De0SDUkKkO6czc5pH9vq0zfaj2Ao0fl+6sB4KVB\nwL+ylW0pFyrrLXlbUN2nJ3D55UBBgVxJZ8TbPwHUWGrkbmdRXSH98OaH8eDGB72+7lDf7O6TFfZK\num1iWyTH2AfeHctxpsSkoNxY7rbwSZwhzn6NAG0rKbZR7GXwNu7tbZvNs5Vn6w329X+sB2Cfea8G\njg90HJMmtWBIk88WXr4Q/538X8QaYlFjqZFDqtxq74sura2GUw1Jyvukz+uNuHfWAACqoQyKagOA\nI0cUIe0Qawamnm2Hx4Y/hkqD85fqZe9chr+NqN04o7jYGdJx9pA2Wo1y9eqg1WjrDOmntzyN5394\nvt5qtr5lQR2VdNvEtkiOtoe0Yxew1NhUj5W04/YrfyaPFVcX46sjX3l8TQz7j37/SH7sdW9wD4vE\nVJmr0PKFlrj07Ut9bo8aOCppdneTWjCkqV5vjnsT84fPx72D7kXbxLaI0ceg2lwt/3Ivt9n/dtwj\nndqms3LiWFQC4i8Y6vHaNXoAubkoigWiXTIkzgyseO045g95xO19H3WvfVBUhPyyfABA++T29mta\natxCIyEqwafu7tOVp+t8vb7ubseYdJvENnIl7SBX0kLlatAa5Al6/oxLZy/Nxsi3R8pfz1sbRd6u\nX2V2fqJyhJdj97Bv//y2znYkRScpzg93nDBGasOQpnrN6D8Dj13ymPzc0d3t+OVeUVspOqrhFilt\nAaFSSYhKkLt0XVVH64BTp1AUC0UXOQC5ixxnzri9z+r4L7eoCFuPb0WsPhb92/QH4N7dbdAaEK2L\nhsnsfYMOh9/P/l7n6/Wt3X2q8hQAoFV8K7mSdkiJSXGrpA06Z0j7OmYsSRLySu3LqIr7Zctt8dJ9\n7e36Ykg7vg9fK82UGPsWpIXV6tphi93dpBYMafJbvCEeFaYK+Zd7uc0efsXjRwGwd+u6nu8tpGti\n7fdaFcUCLStdvo4jA//v//D9Kg/94QCshQXYlr8NA9oOQEKUfZlST5V0VEExdh/aIndHO+QW5eKv\nH/5Vfv57Qd0hXd/a3UXVRUiKToJBZ5ADDLB3tydGJbqNSRu0BnkWva/d3b+e/VV+vPnwZrdJW97C\n2JeQdpzja4ilxtj/rU9VnPL4+l0b7kLck3FhV8GGW3uIvGFIk99SY1NRXFPsDGlzBWA2o/iOW+yv\nxyhD2ipZEaWL8jhTvDrWHlBFscqlRAEgrrW9+xobN2LwH9V4/Ev3tuw/+zvKTeUYlDlIXv/aaDGi\nWBiTtkpW6E0WlEfDbVnRv3z4F6z+ZbXzegX76/ze6+vuLqouQotY+83gYne3XqtHYnQirJJVHqMG\ngChdlHzvua/d3btP7pYf//3zv6PT4k6K171NQPP2IUAMacc5vn5gSIxOBOA9pF/d8SqqLdUBXawl\nEDgmTWrBkCa/tYhtgQpThby6V7mxHNDrUVzb9eoIqfsH3Q8AOLfFudBoNIjWua9PXd05E0YdUBml\nvBcaAOLjlN3FrmPWAHC4zF5Fds/oLod0jaUGReXOLnKbZMPpePtjR7C+tPUlzPtqniKgAKDg+EHg\nkUcAS/3jup5md4shnRCVIC/FqdPokBhlDzTx9rCGdHe73hfuKhCVtK8fGBzf95GSI5j43kTsPLHT\n43mBXkilwlSBL494+NTmI66+RmrBkCa/uVbK1ZZqVJgq5BnVju7uZy97Fsa5RrRKaAXA8y/GmoQY\nFH+/CYB7SMfFJimeR3koEE/WjgG3+eYnxLy21H5NSw2KK84qv45w55ckSbj3v/fi8W8fh0ajXM+6\ncvMXwFNPAf/5j/sXc/kePK3dXVxdLIe0VqOVJ1bptXr5sTjzXK/V+93dXV9IexuT9mXimBzSPrbF\n8UFt54md+Hj/xxj5r5Eezwt0KA5fORyXvn0p/ij8o0Hv5+prpBYMafKba0gDwMe/fyyPAzte12q0\niNI5b3D29Iux2lyNI23t49VuIR2fonge7ZI980YAM+Pt1VTbp15B9Hb7EqA1lhoUuIS0SJzB7RpG\n8kpnJs8zwU9XON/r2t1tsVns94kLPx9Hl7dOq5PDu6CqQH5dq9H63d1d34Ic/lbSjqUyxTb42hbX\nDU28vS/Q3d2O5V5de0J8FW7d70TeMKTJb46wAYC/9fkbDFoDVv+yWp5R7TpxzFVabJr8uLC6EIOX\nD7Zf1yWkDbHxiueu3d2PD3c+blPh3MSjsLoQm05u8fr1xYlWZyuUM8crHRV3lMu6pAA+2f8JXtr2\nkvz8SMkR+bHFZsEzW56xfx/Cz8cxw1uv1XsMaZ1GF/Du7saMSftbSYtLo9YlkJWrOCmwoavIsZIm\ntWBIk9/EEM5MykRWiywcLTmKouoiRRevN11adJEfi4F17e/A768C/WsnYFslG3DXXfLrUXVMyE2r\ncob0u9veQoWlCn3dbyEGABwtOSo/LjIqZ4HLy5Ha3L/Yv/f92+vX33dmHx796lEALiHtqKQ1zkpa\nnDim1Wj97u4OdCXdmDFp10ra1zadqjiFa967Bmt+WePT+0Xbjm/z6+t76v4PxBKxRE2BIU1+E0Mo\nzhCH+Kh4VJmrUFxTjJSYFI+zuEV/H/h3LLhkAXpm9JSPbZqyCZllwHkFQJfaIVubZANefhno1AkA\nEJ2c5uFqdho4Q3rvcXtX6JXCcOXOpcCC2gW6xJB2JXd3V1a6vVbf9+Ug/nwct2GJ3d0inVbn92Im\nnvagFoOoMfdJ+zu729eQdr3ep398irX71+IvH/6lzn8PTxyL1wC+7Q/t6ftmdzepBUOa/CaOuSZG\nJSLOEIdKcyWKq4s9jle7ahHbAvOGz0NWiyz5WP+2/YHNm4EhQ6CrvTtG7raNts8Kj05Nr/O6jjHr\nitpJ5JlCr3D/k8DNtZtRHRd+ybuSu7srKtxe83WSkhjG6XH2NleZqzyGtDgmXVd3958lf+KVba/A\nJtk8dnc7dncSrzO973S0TmgtH/dn4pivlaZrSHu7tcn1exOD+dczv8IXJqsJRdVFinkBvnS3ewzp\nMOzu/l/u/zBu1ThUm92XaaXmiyFNfhPDZmC7gYg3OCvp+sajAWcXsGMMu1taN3vFOXIkMG8edLU9\nzfIvV519d6uoFi3rvG6My+/iNi45m1r7uy+/6KjXaygqabMZ+Ne/gKoq2CQb9hfsh06jw+guo+ts\nh7hwi2M98ZKaEsVYvINOo5O7uy9ecbEigERTP5mKu7+4G//59T8oN5Uj3qAcrxeD2/Hh5sZeN2LO\nkDny8VB2d7teTwzpg0UH631/pakSQ5YPwXmvnoc/S51zCnz5+p6+F5tkC7sFTcb+eyw+O/gZNhzc\nEOqm1Kmougi/nPkl1M1oNhjS5DcxiPu36Y84QxyqzFUorCr0WC26ctzPfEnHS6CBBsvGL3O+GBUl\nV9LyL9HakI5OVM72BoAXL38R26dvBzZtUoR0Uo19gw7ZmjVINAFaaJBfesxjuxKM9kpaAuyV9Nq1\nwNSpwLhxOF52HNWWatwx8A6svta5+MnGKRsxufdkxXXEatIR0gC8VtKO7m4AeGX7K/LjOz+7E8nP\nJEOSJDm8N+ZuRJmxTFEhA8pxakfQ6rQ63HXhXXh5zMsAAj9xzGKz1Bl04s/BbDUrJnyJQetLD8Xy\n3cux88ROnK06i5V7VsrHG9rd7WhTqB0rPSbPVHfM5XAs+Rquer/RG+e/cX6DZ9arzS9nfsG8r+aF\nbAEchjT5TQwbg86A+Ch7VVdprqyzu9uxsIdjUY/5l8xH9SPVGNJhiPMkg0GupOWxVUclbRA2nYZ9\np6nZg2ZjYLuBQHKyIqRTayCHPQAgPh5aCUg1ar2GdEYVYNMCRj3sIV1Su2nEV1+h6MQhAEDL+JZy\n9zQADGg7AD1LnDPB5/2aget7Xu+8ZrwzpGMNsfIHFAedVqe4nhg6r+98HWXGMtRYahBrsC+L+vmh\nz1FmLJO70R2e/O5JOYwcPzedRgetRoup2VMBKPeWFonrnPt6C1aVucrj2LhI7IreeHgjWjzXAst+\nsn8gO1pyFP3b9Ee8Id6nkBZXNBPb5kt3t7cwDocu7w4vdUD/N+1rzrdLsu8/Hu5V6vHy4wB8+4AU\nCc5/43w8/u3j9a5GGCwMafJbnCEOq69djV9ut/8yidM7u3frCulf7/gVr17xKrqldwMA+ypkepdV\nyAwG3LnD/vAfQ/9hf6C3h5jrimX3DbrP+SQlRXGLVmo1FDtxId7+QSK1woqTZuU2lg4ZtXPFqgyw\nh3SxM7zKdthv6Ur6LRc6rU4+nhydjJ7PLJefL/ijrSJ0xUoae/eihcn5GqCc3Q14HgsuqSmRu4dP\nVpzEifITbjPoV+1bJVeYjk03HB+eHNf3VlE6fumK53gLtp0ndmL6uumIfyoeF+RcAEB5S5245rfY\nFe3YMnPJriUwWU04XnYcnVI64dy0c33q7nZ057dLbKc47kt3dzhX0g6SJEGn+f/2zjs8iqpt4/ds\nyaYnJCEQUikJBCEJECCAGJQXEAQpdl8EFQTrq+inYgUbdorYUAGlCCpNioio9CKCEHonkEBIQkgj\ndZPM98eZM3Om7GYDCQlyftflld1pOzOMc5/nOU8hz1VKZko9n41r0Gf1bMFZ7Dq3q57Ppu5xNXC0\n1n+3Xn6Vc81zb7t7cUMwic5m52CdubtjG8fiiS5POD+wnx86ZgDi+x64ufnNZBl1dzNBy+tGrsO4\npHGq/bwZfWtUCtkiJyfpKS93BG3wUWQFmZO+qIh5wYrFAADfGd+qRFgQBLRl66ZY1CLMWtLo1AkB\n2eqJcjZPGlCnZ1HSCtJ0/bFpzWwW+tI8knMEABATGENOiRZLcSBKZwsMRNqBldlnbh/M3E2s4eMX\nFe8Cew7UkmcDoGhlt/LKcqTmpUKEiOb+zRHsFYyc4uo7aBWUE5EeED1AtdwVa87RtTSkNCx7lV1O\nR2Tz7xsy1IsRNiUMiV8n6tzBlVWVWHti7TVdJ50dBNaX54WLNOeKoRYbUH0hk2pp3RqYNQvYu1dZ\nJgkfWxa0V1QvdUlPPz/4lAMB0jRZoxKgw3kgCF74svskxZJ2EjjbWNr3nA+IJZ1DxGNJLPBKY3I+\nPmVQiTQANM8DBh8GZv4MnUizAobKSl3BFja6GzBuVLHn/B4AQP9W/eVlznLRD184jFCfULkrGLXQ\nXLGkHaVgxX4Wi75z+xr2jVYNRKAMNGi/cUCJL7BX2pFynliK7Zu0h7ebN4rtxdW+yAvLCmESTOgV\n1Uu1/HKju4GG4e6mlFaUyiJdl4OH7KJsJH6ViN9P/o6TuSev6FjaAZL2vN/b/B76zuurirO41mCn\nHurL88JFmnPFsJa0KylY1fLQQ0ArJT1LsaQFBztArhBGe1I3KgW8y4HsZ85ibJ+XDC1pT5PafR4w\nciwAIOkR4MDu34BvvgEEAXfcA6Q0ISLiW0aCz2SqqmASgWULgYd3Q29Je6oFzEvz/7nZZFa5uzMu\n6SuwUJEeFDNIXuZt9dZtl1eaB1EUceTCEbQJaiMvFwQBFpPFUJQKywpVkeGOLOnDFw5j7cm1uv0B\n/TXSuWrWks4uypaPS9258U3i4WX1gghRJehGFJQVwNfmi+RIUmbu5ijiZXEputvRnHQDcndfLLko\nDzjqUqRn7JqBXRm70GduH7T8pOUV1VTXnqf235AWndmevv2yf6O+YQcy3JLmXLOw6UBaq6pWoHPS\nxjU6VARJ1rA8Hy1Z0PQva8lGeTSTPz8Q9wDCQ2Ll73/SjpaN1IMO3zLIOdS+pdAXPdFUKmO9DADg\nqRVpjbs7o1Av0lTUYhvHyvP08U3jZaGi5JXm4WzhWRTZi1QiDZC+1UYvZGpF07nempYFBQxEWoo0\nZ1/adPBRWlGKlMwUWE1WxDaOlZ8dtn64EQVlBfBx80GobyhyXsjB57d9DuDKorunbJ9S7b5XC3bK\nobyyvM5cxNpCN9UF/zlD68XQRnvLlfQakMeiprADEW5Jc65ZjPKCaxUa3V1RzYvrxhvR2Id03Lrg\nLT3a1LI1cHcnBrUHQOY55wydI7uHASBT+ljqpba2fcsAHD6MU1OB1KkACjSFRQwqld0WfRue7/48\nAL1Ia93dmUWZuhcptaSj/KMwqfckVLxWgdEdR+PPkX9CnCDKKWG5Jbk4lUvmM9lCMQBx0Ru9ZKg4\nRPpHAlBeqOzLqTrB0A7MjCxpavFmFWVhX+Y+tAlqAzezmyozwBmF5YWyiz/AI0AWd5eiu6Vr0kbW\nT98xHfZKO/5K/wtjV4w1rNRWWVWJfZn7qv2NK4WdcgDqTti0dd1pkKGrOOoCB0BXhKWmNekbIuz/\nM/UVw8BFmnPFsNaiNjWoVjCRx9RWnUhv2oTo2x8CAHgMHAIcOaKs8yApTKy7e0y7kfjiti/w3ZDv\nAKiv46CkO2lV6trePuUAUlIQlScdK0cT9FRUBFRWAvffT/KsAay8fyU+6PMBAANL2mRWuWyrxCqM\nWTEGv5/8XV5WbC+GWTAjzDdM3oflrrYk5SuvLE9Op9IG8FlMFsOXJbVwI/wiABi7u7UvpyFthqi+\nu2JJs8c6nX9avpaaWNLsPDzbO7w66DUZTcVkXMpA0swkfPXPV9h8Rt+U5aU/XkLcl3H49fiv1f7O\nlcBa0kDdCEKPWT3w1sa3VMvY3ubVsT9rP6xvKV4f7QBJ++9NLekLxRdcCg6sS8b9Og7CG4IqV98V\n2P9nuLubc82isqTrwt3djLilndXupryW/Bqe7/48pg7+EoiJUVZI1ngg45HzbtYcjyY+Kg8s2BfW\nAekyTtvUIuBbBmDlSmXBUU2O74kTwP/+ByxYAAwdqjs/I0taa83M2jMLfeb2US0L9wvXBazJl2Yy\nw8/mh7zSPDmwi9YMp1jNxu5uWk40wJ2IupG7W+vGHBE3AnfE3iF/97H5IMQ7BB4WD9X2zspb0vNz\n1ZIuKCtQRbTT1D2Xorula6FBjVaTFR/1+QgAKSZCMSrMsvTwUgCo8xSjE7knAEAuUlMXOchb07bq\nltXEkl50cJHqu/Yc2edk5j8zsSF1AwBg85nNCPrQePB+KPsQlh5a6vI5XC60e11Ng+VYYebubs41\nCzsnTVsz1irTpgEvvwzzW+9Uu6mn1RMf9PnAeLCwcCGSP/pJ2damDr4K9wuXPx8NAh4dCCxspz6E\nt08g8PPPyoLDBgUOPv9cv0yaq9ZZ0oeOoNG0GcYXwxC1OxX4/XeH6/3d/ZFbkisPNLQibTFZUFJR\ngufWPIed53YCAMauGItpf00DoKR0ydHdzMtJ23XL281bNTCzmW0499w52SMhi7STYDBq1bpiSVeJ\nVbhUfkllSdOc+ZpEd9PftFfZZUuebdbhqHwoAHUmQR2wK4MMAjo07QDg6rlWa2JJa61hnSUtDcoK\nygowZuUYpBUYFw1iSZiRgGE/DpMDCxsarDBzS5pzzcK+sOvkZebjA7zzDgRvbwyKGYQP+3x4ece5\n5x606H2n/FUb1DUgegA2PrgRH/aaBACYkQjM7Kg+hOmee9ULXnvN+W9Sd7g0d62zpC/kYMD8Hfh+\n6Dy82vNVh4eJzAcZrFCKioD9SnpII49GKktaO1iymqzYeW4nJm+fjC5fd8FbG97CV/98JVdRolXg\njCxpbUMPLzcv1b85rYZGlzmypNliNFpLetaeWfhsx2foPae3zmKh1r6vmyLSbmYSzV8Tdzc7cKED\nMraQipFgUZGu60IWO8/thKfVUw74u1oiXV1vcpYLJRdU30cvH43Vx1bL3+mgbHv6dkOvhFFsA71O\nIyu/Lqjp+6khWNLG/jMOpwZoxa4uWX7f8is+xo7RO7Dy6EqEeIfo1vWM7EkCyNa/bLxz69Y1+7GU\nFNI4RCoxqrOkyysglJXjvkY34UsnfaJvPgWgtSKMGDAA2LgROHsWaNYM/u7+SMtPc+juZl3lIkS8\nvv511XpqSRvNSRcUqK0crSVNf0sn0hpLOso/Si60Ql3P1JKet3ce5u2dB4DU8s4sykS3sG5wM7sh\n6Zsk1TkCUrU6s61GgWO0sQsAhPsSkaY9wAFjwbpaIl1RVYEOTTvIUwZXzZKugbub7f0OANnF2Rjw\nvVJcpv/8/nj/P+87jBhny9tq2ZK2BYPbDEZ6QTqyirLQMaSj4XY1ZdnhZar/z2saNc8tac6/AvaF\nfS3QObQz3rj5DYej6rgmcarvbNQ3wsNhyObNJFhMy6pV5K8DkTaVSJbg8eOyNWvE3QegpJMBRKAB\nICsLABHKnJIcZBaRRhysIAH6AixanFrSk99VbasVaepGpsve2vgW3tn4js6Spi5mer6A8QBv+ZHl\n6D2nN5785UmkFaTh0IVDqnOk2Cy2GqVgsfuH+OgHaEaCVZcirY0RaBfcTvYQuDL4qA1q4u4+V3iu\n2m1e/P1FbDqzyXCddtoEUJ6DtSfX4vFVjyN8Sjg6fdWp1lLQhv4wFEkzk+TvNR38qALH+Jw051qF\nvlj+LZhNZmx5eAvim8QDAGKDlPxplUgfY2pO+/qqyogCAKKiSPW08eOBjz8GYGBJ03fRokXweWmC\n7lwiqnywYncsPCogF2QB+wKT3Ok0wnr+vvkQIOgqklXn5pPnpA0abBScUs+7e1m9ZIsPUCLJqUif\nv3Qe03dM1wWDGYq0VS/S61LXASAvbjawS5um5G5xr1ExE3awZTFZ0CW0i2o7I8GiYqEV6bzSPAhv\nCHjlj1d0+6QXpONYTvX1yLWCEeoTKv+/VNuWtCOBcdWSFkURp/NOV78hlCImWtie5wARQOr52XN+\nD77Y+YW8zkjQa4rRNdd08OMsy+FqwUWac8U08WoCHzcfTEyeWN+nUmt0D++Ozs06A1AGIc39mwMR\nEcpGgUy0ua+vPh3rmWeIBf3++8A84srVWdJUbz//HN6HTujOY8SmQgz8mViStKoaMpme09Jvvtjj\nRXmRt5s3EZWZM4H58wEAF/P0RVJYnFrSVvX8os6S9lBb0gDJh9aWEKUuZkCxvlVeCglaE9zbzVsV\nfHRT5E2q7Vx1dxtZ0gCwbdQ2RPlHyd+dWdIC1IOcA1kHAACTNk/S7RM+JRwxn8bolmvRegF8bb5y\n1HptC4KjwYyrlnRuaW61EfjV/ZbWDW6UlkW9WI76qrvKvsx9eHj5w7rlNb2v3N3N+Vdgs9hQ8FIB\nJvTSW4LXMi0DWgIAEpomIO/FPBx4/AAQxKSS+PoCTaW+zn4GUe133qlb5OmrTiNjm4D4GOiNB+sR\nPXECOHgQ2McU15BEumVASzzZ+UkAUjqTKAKjRwPDhwOiiGy785exz05Sm/z5tc9j1u5ZKK9SXmYF\nVnUBDA+rh0qQqTXMLhMh6tJd2Ih7Z+5utsEEtaQX370YI+JHqLZz1d1NX65tG7dF19Cu+HbwtwCI\ndcwKt5FI065eWkvaFcGqLjdYKxg+Nh/F3V3LKViOIu1dtaTZKHhX0Fa8A/SWdHaxPqK7TwuSephV\nlFWj39PS67tecowDS03va0MIHOMizeE44Lluz+HzAZ/jwz4fws/djwS9sG5js5k0Atm6FfD3J9by\nyJFkfnrfPiA0FLCpK5Z5vqweyLDtNH0MBvlsj2wsXw7ccAP5PcoFJZinlQ+x8qvEKhJQRmnbFqIT\nb7cAAV7PvCB/f3zV42pL2qK2pE2CyTCiXxsUpG1BybrItYFjRqQVpMmWdFJYkk4oXXV3U0va0+qJ\n7aO3Y2TCSHkdex1GVqVRFTJALzhG0Ll0R2i9AL423xq5u0/nnXY5KtpRzrqr0d01FWm2GQxFJ9JS\n2lWLRi3kZXSKicZWXC7a3H7KFc1Jc0uaw2lYWM1WPNb5MX1E6r33Aj16kM+NGwPdupHPMTHAt9+S\nde2kBOvDh4FPPiGfg4LgmdhNdSgzK9JGlrTRe4HN0379deCrrwAArUoZwWPSswxzuRlsghWsR7us\nskz1Qnqjrd6qMQoW1C47cVHtvmfvozNLmnKp/BL2Zu6FxWRBE68m+vOW3N3rTq1z6ralAw6j4Dn2\nnJ1Fd2tf0NR1q43HYAOeDmYfdHhOgN6q83HzkdPUWDHJKMwwHBRETYtCj1k9DNOdtFBL+u4b7lYP\nTOrAku7bsq+q+xsVYe08M7Wk2UhuGtB3pZa0oy5xNZ6TruSWNIdz7bFgAbGWXSEqCnjySWDKFGDL\nFp2QmUTI1rZ3dZY0ZfduIDlZ+T6WdO9qeZFR/KXGVZwC3PRueaGqChpjudoXkpFIs41CAP0LkbWk\naR63M0saINWqQn1CdaVQAeLuTs1LxS1zbkH/+XrLjUKtoepE2pm7W2uB0f7e2vNn3cqHsp1b0k7d\n3dK9q6iqQLPJzXDT7Jt0+1OM2odqoZZ0XHCcqmRsyvkUrDm+ploL01WRfjDhQfxw5w+ySLpb3DHt\nVpLf78iSpgVcAKW1a12JdI3npKv4nDSH8+9HEEgQWUyMTtzMVQDiSLCM9w0ddLu6T3rf+Jj/+Y/6\n+5EjiPqAWNQDj0C2rpGUpNos2iNUdyhRFHUi/fORn3XbsRiJdHUR5B5WD7zb+10MjBkoi66jzIDE\nZonk3CA6LDUaazNtAAAgAElEQVTLNszYlr7N4e/SlyvbEpQyLHaY/NlZMRPtoEUWaY0ngK0NrXX3\na3HF3U0DqHaf3+3wONr8ZSPotICH1QPL712Ofi374dWer6KwvBC3zr9VV/JTvoacYyivLJdFurpU\nvg/7fAh/d39VICL9rA0co4OLdsHE69TYs7Es0lcaOObQkjaYk66oqpCDFbXwOWkO5zpDJ9IigI7E\n3We+pbdue4/mMcDixfoDtdEE5sTFwf2fvch9D1j8o7Tsiy+An35SbRZhJlZUdEA0uod3l5aKsLrQ\nBpRFNT88bx7woXEVODYwy93ijvE3jseK+1bIywRBUAmlfDnBSq66o1KzrGXuDGfu7oc7PIzDTxzG\njRE3GlqkjtzdOSUkKEwbnU4bnAAkFc0Zhu5uTXS3K7nJrjSvoBa+h8UDHUI64Nfhv2JMpzHyem2D\nD4BEsMd8GoPRy0cjvSAd3m7eCPRwXj+f/lvRwUZFVYV8j7SWNJ1euKHxDVh2zzLsGrMLQZ5BECAg\nq/jyLOnfT/6Ov9L/qpEl/dLvLyF6ejQ2ndbnd/M5aQ7nOkMr0iGFIFaxn58yz83gbnEHhg0DmjdX\nr9BWPisnLx//UsCtEqRc6aOPkpKqAE5NBf76GnCzE/dt66DWSPa6AQAgAjpLujpUAVsPPAC88AKQ\nr7dE2cpnjkR18d2L0TOip2oZW1DGL984OMzVIjrU0nQkMK2DWqOZTzNkF2frhJPOMTtyd2vPgbWk\nqxNp7TFZS5qeh0siXeKCSEvubtb7EO4Xju+HfW94LoASZT9371ykF6QjzDfM0BvBQtezAyKag+9I\npH1tvhjcZrDcRCbIM8iwr7or9JnbB0kzkxxOoxjNSS88sBCAsTeGt6rkcK4zWKGa9DvwwhYAbduS\nfOohQxxvb9eM4lu1AmbM0FvUd9wBnDsHvPEG+e5NrJioPKDLWeU4QpUIz8+/BgBUQYSFyQMe1/GJ\naq+jU7NOAICp/aYqC9ev121Ho7gBffS3M1Qi/ccWMsfu6UmuTaK6crSHLxzGgawDcqQw7TBlRIQv\niYzXFkzRurvnpMyB/3v+cuS2NmiLtaQzizKdBnVpBYOdk64zS1rzb9A5lNQCMApMY4VOFmmTc5Gm\nsCJNLWlt4Bj9zpZ7BUhv89P5rhVOcYQjq9dIaOk9N3Jnc3c3h3OdwQZAvbQZ8LJDKVICYMndS9Cv\nZT/5u2z5aEXawwMYM0Zxhd9wA+m0tWgREBKipIqZ1QFX4j6SD42UFCVyXBRhaawI2ANjPnN+ERs2\nIGDxLxCfysHTSU8ry3/7Tbcp28PZqXtaUwiGFVS/UpCc75ISVUBcdUFnsZ/Fot0X7XD+0nnYzDaH\nLlBA6aetraqldXePXDYS+WX52JtJ7uOe83uQ+FWiPN9KXeZNvZuioqpCtriN0AqGh8VDF92tHTQY\noZ2TzivNQ2VVJV5Y+wLuXUQawlBLWvtv4MgVDQCVojIHUlheiDDfMIzqMKra8wGAGyNuBAB8cdsX\n8pSHkSVtNVlVjVcAUuP9bMFZrDq6CoMXDpa9Cq6k21Ec5UMbLXeW9saLmXA41yGzbp+F9SPXk+Yb\nH31ErGKJobFDcX97pQY4LaiCCibMOyFB+dy2LbBlC7BzpzqH2wFiKXnRCWnpcvUzEYDVXXHbNq8u\nWLhXL+LibtsW2LFDWb5CmWv2lt6F/syctIc2Uv3ECbnEqZBOxCjW7o9V96+Cn1WZ6/UrA2CVLLhy\n5UXqqrs7sygTTb2bOg1soyJ95s7/AN99Jy+nIl1eWe4w13hXxi78cuwXAIq7m5aSpS7v7/Z8h1m7\nZ6le+lrBEARBF93NWtLsvmyqF+vuPp13Go3eb4Rxa8ZhXeo6rDxKep+zgWMsjqxcQJ9bHe4bjpd7\nvoy0ccYtKIe2UfqnB3oGQpwg4tHER2WPh3bAUlheCF+br+7fpbl/c4gQMXDBQCw/shx/nvoTK4+u\nhMc7HobzxhTWa+Eo1cqpJW0gwtyS5nCuQx7q8BCSo5JJVPdzz+nWsxZikKdU4Yxa0h98AGzfrt6h\ne3fA3R2uQF/tAhTRrBIACyPS/gYGy6sbgDfd+2P3ecklP348KU/6KtNeM015ecdIutForxI161HA\nFJj49lsyOJk7FwDw0hkiknPyb8GA6AHw++QreVO/UijizIi0kSW9NW0rUvNSVcvOXzqPJt76PGuW\nSP9IAMAJvyp8Pf1BdJ/ZHeWV5SpLmvbhNoLOr1J3NyvS+aX5ePDnBzFq+Sh8u+dbeR8jIXHm7mZT\nxFixYd3dKZkpAIDpO6ajxF6CInsRisqLVIFjLJ5WTwgQDC1preUa5hsGQRBUNdgpq+5fhSX3LNEt\nB0iQYdfQrvjtxG8qoS4oK9C5ugGp/C5DXmkePtxKAhOn/jVVtz2FHfTQz9rrdeWes1RUVciWPrek\nORwOAMXiYIN8ZJEOCtJVMasJtPKY0DgYbk89Iy+3eKgFb9ARQGDSrt9aB7y24BwStqeSblyTJpEc\n8LVryQYDB6r2j5bexX4pSiEV9/wioLISKCtT3PRr1gAAbr0YAHEikGgn6VaeS5SWpH5lIP2zAaBU\nEQ6tJV2Sm40es3qg+bTmKivwXOE5p/PRgGJJv5UMjBlEgojOFpyV86TtlXbVfLMWKtLU3U3LYp6/\ndF7lss4uzoa90o7kb5NVDSUobHT3xZKL2J6uDMjYFDG2LClrSbPRyFRks4qyDAPHACKgXm5eLou0\nIxy1p6Q82eVJlFSUYOH+hfKygrICwykItp46QO4ptWK1pWZZ2Bz1ssoytAlqoyslayTEdJ7dcE66\n0i4/Z1ykORwOAGBwm8HoFNKJuMQp1IK0uha444gA6T0W+J9BEOKJ21wUALOHJ8J9w/GMFOC6fAEw\nn838euEF4p7fs4c0GREEdTT6bbcBDz4of430IvnYbIEWjwv5wKBBJNiNRoJnZ5PSqhTq/vZRXt4q\nSzpP8cVrA8dSJyrz49o8b6OKZSyN3BshwKQ+3vrU9bLolVeWo6jccb1uKs60HCWtsnW24KzKGr5U\nfglpBWnYeHojNp/RF8Rho7s/2/EZ8svy5TxiNkWMPRd2TpotY6oSaQeBYwBxeRuJtLbet5FI39X2\nLgAkUtwZyZGk+M7RnKPyssKyQkORbt5IbUlnFmViz/k9AEgMgKPqcuzArKyiDDazTZeHX+M56Sq7\nPLDh7m4OhwOAVF3aOWYnuoZ1VRZWSi/fKxTp99cC45LG4eO+H0OQAtZEARA8vXBm3BlM2aBYWmVS\ngK67xR147z1SAhVQ2nV2764cOCgIGDsWU1cDrXKAxK5kfpIVacvHU4DVq4HUVGCTNLe4di0QH6/M\np5eXAwUFqmA6X/a9mpMDLFkCpKfr3N3HMg7In+9bfJ9qXXWWtCAI2NP4NXRkgqnZLkr2KrvTphq0\nQhYVxsRmiTAJJuw4t0OVg3yp/JKu/OjdN9yNRXeRYiKsYPx97m9YTVY80vERAGp3N3subKcw6s4V\nIMgiy1rSRsF7WpGeun0qhDcEXRpUpF+kbt85Q+dg68NbmZx7Y5p6N4VJMOHTHZ9ixNIRuG/xfcgs\nyjTsoc5WRAOATWc2qQYMZ/LPGP4Ga/lfKr8Em0Uv0mzjGIqzHt72SjusZiusJitPweJwOC5wJSI9\nfDh8/tyMyf0mw8/dDwJbkMRDenl7KwFbxdJPeVo9iYhGSi/pEFJfGX37KvsHBQFxcXj6L+DYdKBr\ny5vgb/VBR/Y9/8cfjs+NWso5OSRn/M8/5VV+7Ltz0yaSZtarl87dfUx0XHmrOpEGgPBiK5b+ANgM\nSrHaK+06S5otspJxiVwoFZNgr2B0CumEDakbVCU1L5Vf0gVQjUsahzva3gEAqujuozlH0TKgpRyX\n4MiSPp13Wrby6ADAYrKoLGlHgWMAKaLCBo6NWzMOABFHShOvJvBzV673474fY2q/qXC3uKNbuLoe\nvRFWsxVNvZuiUqzE3L1zZbe3kSWtLRBz+AKZMmkVQAIsHUW8s0KeX5YPm9mmixw3sqRpbrfRIKyi\nqgIWkwVWsxX2Kjv2Z+1H12+66urS1yVcpDmca4GVK4EOHYA+fS7/GAMHqlzUNB3MWgmSgwzIxU8A\njUgDSpvOYikAjIlKR2CgcgwAERHtkTvyEPpq32XNmpG5bC2pqeTvIX29a79Sg+1OnICXRqSPlzjO\nKaZzzk7Jz0dEPrB0lb7HdXllue4lLkfegxFpewncLe4QBAG9onohpyQHv51UUtNm75mNO39UtzBl\nhYRadUX2IpzIPYHWga3lwYDRnLSb2Q2VYqVsXRqJdGZRJo7nkgA+o4h4R+5udlAwZ+gc1bpnuz2r\nTr9zgVAffUlaI5H2sHio+nfT6YLogGgA6upon+74FF/u/BKA2pIurSg1tqQdBIcBxmlo9io7rCYr\n3MxusFfa8cXfX2DH2R24Z9E9ji+0luEizeFcC9x2G/DPPyoRdRnqSmbSdgDg9ta34/5jHtg6E4rA\nMm5mnUjT4LAuXZSDjB5N/lIXuL9UYSw4WN17m9KuHRlsaKFFSo7rayj7GWfTwLNS/fo6YvBzlMij\nLpSZlObJG9n15UPtVXpLumUjRaTPFZ4DTp5EyY4t8DAR0aVzyVvObIFZMMtirA1AYwcQVFSO5BxB\nRVUFYgJj5Kpt7H70XGjRlxO5ZDRERVqEKEemf5fyHX459gsGxgxUVYCjVCfSBx8/iL4t++rW1xQ5\nU4HBqBWoIAg6axoAYgJjAKgt6adWP4XHVj2GeXvn6TwUhnPSBi5tal0bBb+x7m57lV2Og9iVscth\nSl5tw0Waw/m300gqKGJRi4+b2Q3zNwcj8RxUVjDlnniSr/3+f6QmH48/DqxbB4wbp2w0YwZQWKiI\n88GDwO+/AwEBxlHojRvLDUWqI+E8GVz4GdWw8PaGV7l60HFI0oD2Br0ZIu4cpXKhy5SUAO+/T7wD\nVKQr9FMK5ceP4JLkEn5vLTB2JxDIdBQ7V3gOW3/9GiWX8uTUNlrIpVKsRBNvtbuYMm/oPAR6KuVK\nqajsy9wHgAgTDUJjg66oJU1rnJ+4eAL3L74f725+F4A6yInu9/KNL+uvH0Ski+3FsmBqBxNGaVKX\ngzYQDQDSC427axlVk6OWtFFHrgeWPoD/LvmvapmrljQV7k1nNsl55RRqSVvNVtgr7bLHpHOzzlfc\n89pVuEhzOP92Nmwg1ckGD9avo3PcHpq5yv/7P7SeNh/iBBFD2ki50YJACpmwVcxMJtU8NkJCgN76\nRiEyQ4eSvtsusHFXe5x6KEVfBAUARBFeJWor7LykJavm6zf3KwOQlQUsW0YGFgkJwIULJM97/HjS\nl1sSaf9yfdETe2YGir6cDgAYuwv4ciVgq1AGCQIEvJ+7AiUWpQc4WxK1qXdTnXV4bMRO/DeOEZYL\nFyCsWQOrySoLWmKzRDT1bopAj0Dsy9onb2pkSS/Yv0Bez1YLo8g9ntPTgZdektP66HlR4afRzIap\ngLWMo6pxRpZ0uF84bGabwzlpbeU1V6O72WWDFgxSrZPnpCVLOqMwAz5uPtjxyA5dqlhdUecifezY\nMXTv3h0xMTHo3LkzDhw4oNumqqoKzz77LNq2bYu4uDjcfPPNOG7g9uJwOJdBu3ZEmIyCzugybTUu\nL+clN2vC0U+Ak/f9RVzaw4YZu7sN8LlYhKiIOGVQMIzpllVUBM9dew33Cyo2XExc6UOHksYjKSnA\nE0+QuX4AOHNGsaRz9aa73QQUSbfKSzLGbJIl3yYb6J/hjZUVB3GyEeBRSkYVrGs5yCMI3sXq0UbA\nfQ+TQLlTpJEFevcG+vdHWx9iObcPbo+EpgkQBAHtgttha9pWxH0Rh42nN8qCGts4FmbBLLu7nSG7\nmwcNItH68+YBgK5sp1aUa0ukPx/wuep7YrNEfHGbPlccMBZpL6sXmvk0k+ekjVzlLDaLTc47pxhZ\n0s6itmV3N2NJh/iEOP3d2qbORXrs2LEYM2YMjh49ihdffBEPMrmUlOXLl2PLli1ISUnB3r170bt3\nb7z8srFrhsPh1CJUpLW1wU2192qIvgg0D71BqSkeG0vm16ujmxQ1TAPNoqJIlTNpHtzrhVd1u3iV\nk0pqa+YCD6RoVmpri//4I3BUciFbLLJIuxXqVb7cDBS5kSA7q1R90lpG7plZBEZtLEQVRBS4Ax5F\n5KXP1i0PyimG9zF16pDfjr1A+/ZAixak7rqUL74i+nXcEXsHvhz4pbwt7am9L2sfnvjlCdmS9rP5\nIdI7FCdynBs1FpNFCdKig4IyYkHKpUGlOdm6EunYxrHYNkrpNPVx348dVoIzsrA9rZ4I8w2TLWln\nKXFADeakHZQQBRh3N2NJh3j/i0Q6KysLO3fuxPDhwwEAd9xxB9LS0nRWsiAIKCsrQ2lpKURRREFB\nAcLCHFe34XA4tQSdp64w8inXAt9/Dzz0kH7O28ianjhR+fzLL8CXkkhRkb5wgQSkSW06PZlxha+F\nvNRDpNifvieA75YC4+ydsOJ7aaNNjus+IzdXKbDC3Iupq8kx7WZiSXsxRldVCRFzSxXQlZkm9Si2\nA7m5Knd3UJkFJvUUOuklniHlqGUouWrh1iAsunuRknucnY37Y0iKlgABqXmpcsqUb0EZWu45g5Pn\n9VHxLEGeQUqNbEmcacwAddseyCZeTjZNy2KyGPbhvlxY74JREBtFawEDRKRDfUNxofgCzl86r8s3\n1x3DQKSp1Xz84nH8dID0WnfUjANQW9IHsw8itzT3qlvStXf3DUhLS0NISAgs0otAEARERETgzJkz\naMWkbwwaNAjr1q1D06ZN4ePjg9DQUGzYsMHwmJMnT8bkyZPl75cu6aMSORyOiziypDWR4JfNffeR\n/1zh3nvJoKG0FOjfX1lORTpdUkIpp5qdq/b3CkRBfhFaM820BC8vTB70GfBOUvW/zbi7WZ7+C5gb\nD+xqBhTYpK5lEhUlxJKzVKkj0D0qAHz2GTz2pgCkZTeCMvJQrm5IpoY1XNh/i4oKIDgYQ7t3R+mG\nUjy66lF8u+dbOeXKPysfLS8Ca1s6d/2qIqupSEv3sWck6eW96fQmDIsdpkoJq+35aFaY2TxzLSZB\nbz96uXnJaVwhH4cYusRZjALHqCDHfhaLiqoKZERmoKyyDBF+ESgqL0JuaS5EUZQHNNSSZuujsx6S\nq0GDCBzbuXMn9u/fj7Nnz+LcuXPo3bs3Hn30UcNtn332WaSnp8v/eXs7/4ficDhOcCTS9UF0NPDK\nK8Bbb6mXv/46iQj/4APyXfLMsZYpnU9t3fc+JVUsMhLo2hX46y/9b3XvDsxnIsxOniTWtMT3fwZg\nhtTUy03Sv0xvdQW1ilLJkjZZ4FUOmCU3uIcdwGuvQfhpkbxt0JY9KpEOKIY6WO8EM6dcWAicPQts\n3Ur+AsDWrbBZbLJI7Zeiv/1LgBaOS4rL4hzooUSQywOwAmKJtg5sjcaejbEudR1EUVR1k3LaXvQy\nYIXZmSVtJNKeVk9VrrVR2hiLtphJM59mctlWmhudW5KLsooyRAdE49aW/VAlVqFs7Wp5Hxo4xgar\n3RF7h9PfrW3qVKTDw8ORkZGBCsl9JIoizpw5g4gIdWGBOXPm4JZbboG/vz9MJhNGjhyJdevW1eWp\ncTgcAPjmGyJYr7xCvo8ZQ/7+5z9X/1wczYNHRJBAr06dlO+nSd/nu/cDb97wpByJ3LpdLyXojb5n\nJPe4jv79lVKnpaUqN/d9Gy9iTE4UkJ4Oi79SptKdsd4rJZE2u3tCCAiQ3e9G0ehBxZBF+tnMFkib\nAnVUPGtJ79sHhIWRwjNScBdFFumMFLhVAO6/rEFLjUiz87k0B9soR5l6DgRBwIDoAUjJTMHbG99W\nzdHWtiXNHs9ZapdDkfbVF0RxhNaSvjnqZmRcylD1DM8pyUFZZRlsFhu8pWyBoiG3yeupu5vex5JX\nStC7hZPshTqgTkU6ODgYHTt2xDzpQVu8eDHCwsJUrm4AaNGiBf7880+US+6XlStXol27dnV5ahwO\nByACtmWLUupz3DjS9IJtnlHXTJyotiRdoSkp8/nDIuC1buPlxWG+YYrY03xsI29bUBDJH8/KIpHO\nlNhY5XObNkBoKPKjlJKi2czUumxJm61AZKRcTpSmYMmDCqhFOmD/SSLobBwAe/2Lmc4mmmm/0HNk\nLrpMqIR/KSD8ugbNGZGedMskPNvtWfk7rbcddDqb1H9npzEKlDnd6f2no4lXEyw5vEQ1RyuL6oMP\nAv36oVp+/JEMfLKzDVezvaONhFi7jhVZrSVdHdo5aZpKuOrYKnlZdlG23IzDy0yu9ZK0S2VVJUSI\nsJqs+Gv0Xzj+1PE6TUdzRJ27u2fMmIEZM2YgJiYG7733HmbPng0AGD16NJYvJ+3onnjiCTRv3hzx\n8fGIi4vDH3/8gS++MA7N53A4dYggGFcKq0u6dycRzjWBqYwGX1881eUpAEDHkI7A5MnAM88QNzmg\nzusePx4YO1YJSgOAm25SPicmKp8lK/t8qZJ/e46pYllx6CAAwGJxAyIiZLe4bEmPVwYPrEjT7Vj3\nOg4rLT1x5Ijyedcu1WWHPfai/LlRKYCMDDRXqnfCX/BQlf6ULelfNwIzZxJXOoURaR+bD6IDo5Fe\nkK6ypD3OnCMFbL77Th8db8RDD5EAv0WLqt/WCVSk2WuxmqxO22Vq0VrSfVr0gcVkwa/Hf5WXnb90\nHiJE2Cw2eJmIABdJu9DWlLTuOFsG9mpS5yLdunVrbNu2DUePHsXOnTvRvn17AMA333yD22+/HQBg\ns9nw9ddf49ChQ9i7dy9+++03tKjp/7QcDufags6HX0F/bACAtzem9JuCgvEFpJFG06bAlCnGud4t\nWxKBDmEidFlh7sp0HpMGK7TDlRYqxv4WLyA8XBHpu/9LBI3pse1TDkxcTz4POgo92prl9NwvMqUu\nRRGhTECzfymAoiLyly47dU7l7u4R3gMD0zxw+xEA58+rLdzvvgN++EH+GupDIqfZGuH5FUXALbco\n+7CBujk5JHf9KHNB0aQqmGqZhk/7T8eU/G6ksIwDjERaEIQaRVZrLWk/dz90CumkahFK55ptZhu8\nRfI89h5B+lbTeevajG6/HBpE4BiHw7kO2bWLWJs33nh5+1NBFQSYTWbXylc2McjLtVqBzp1JXXS2\nZKmBR8FLepGjcWO8uQ54ZBcwwzwECAtTRDqiBWmE4u6On093xwMpQEQ+8NAeQOyzBW3GvqJuTtKk\niT5wT9tIxd0duHABjYsVd7q/QblUP5OnStgCPQOx4mcvdDkL8hvvvKPe4d57gVWrgPbtEepGrpct\n33laG9u1fDnQsSPJV58wAVi6FHj+eeK6r6pSOqUdOQIcOEDm+jU80fg2PDNlGzB3rv4CXn0V6NsX\n5i0kn9rTpHYvu5ndkPJoCjKey9Dvq8H29DigSB1cdlPkTaoa6LTEqM1sg5dUC/68DzBmxRhZzK2m\nK2sPe6VwkeZwOPVD+/bAu+9efuGUzZuVFpeuEhzs+FiZmWq3Ow0qk3gj7AH889geMn+cmQnfzjfi\nqxVAUGoWEBAAmyTSIjPve/uM9ZgzKxemTz8Dduwgrv2331bniffqpT+f2FgizJTSUuCxx2ASgUjJ\nvW0k0t75Japa4B4WD6BIKvqxezcwe7Z+8DFwILB/P0LTFQu6q3FJbeC//yXH+fxzUqcdIDnwN99M\nBjhZktdh9WpS6e7uu/XHSJGqzFy8qM/Pf+cdYO1aJO0mFn/yupO63eOaxLnUerTLsRKUppKAPNpV\nq2dET9U2Z/9YCoC4xr2Yhi3F9mL0n0/SALlIczgczuVgsdS8v7aRJQ2QOW4PD7UbXBKz0R1IhbMX\nRn6FmCZtiZALAvDhh2S7J54A/PxkS1pVwcpqJc1HHn+cWOsU1hV/883684mMJH21WaSAssZSQTS2\nsAot4mLJzUeHpsoAwH3WHNJEBFAajLyozGuzhK1Sir00zwXe/MsLyxYYbkqschrsZreTQc6BA8D2\n7ertVqzQ7ytVVsP69eT+0OpzjGD/31bgtznAGzVI8tk1agcW3rEQ03p/hF0zgLbZQA+/9hiXNA4p\nj5KBQZugNqp9zopk/sBmtsGrQpHD1LxU5XSzjMvPXi3q19nO4XA4VxONdayDteqlbb++/WvMGDRD\nH42clKRES0dHw22dFYDdaS1oGVak2XlwSkSEOrCMgdYmz2cM7W3fAEtjgW5xVcDj4wEp68z9UyZA\njoq1gwYnoftOA1IXUvcK4LXVTspuZmWRAjCAOtDNiIoKdQe2vRrRe/ttYMkSVRqaSQT6nAQK1bVI\nnNLxsyXo+O67wMaNgOQNN5WUYnI/pfiVNhXtrDRDYrPY4G1XXBO02xUAvdVeXGzYNa6u4JY0h8P5\n97NnD5kDrUnjkEDFbewsXQgA0KgR3LqSMp4uiTT7km9pEDUcHq648mkwlgQVmhxaZ2TAAETmA89s\nB4Svv4GwYKG8raUKehyJNBP4bXNewEwddb5/v/Ntvb3VAWdakV6/nlzrqFG6XT0d1dj54w/9stVS\nERI6eACIoDJoC6gUSAMdm9mm8kxQJt0ySd0EZN488gytX+/gxGofLtIcDuffT3y8XKmsWmhUdtPq\n5z1ZaL3pGlvSPj76wQNb8Ck+XrVqyKDnAQCD2txOLNB331VWSpb9x2vI3HU4jQbv21fZpkULoHlz\n3SkFM4azzaAgi4o9e6rZgKGsDEhNJZ+LitSFWwDiMZg/n1RY02CWHBXhvuHqFcOHY/U8IEZgLOMq\naUSSx+Sklah7WAvabm8SNosNXmXqEY1ZMGNct3Fq65umBi9danicuoCLNIfD4bAsWkTaajaqWY3m\n6f2nI7FZIiYkT6h+Y60oa4O5fH1Jk5Hhw4HkZGX5woUYMPQFHH/qOJ55cSlpvRkXR8SZKdry7DYg\ntXiMUiFtOumFjeBgMv++YwexgEOV4iCs1WqzuejO9Xdc2lPFkCHArFlk3loU9cGCGzfSH9btmhn8\nIQ5OKdQtr7cAAA/zSURBVAcWKh4CFBTg1uPApz73KMv27SNFeJhmJSpL+p9/gI0b5SAyFpvZBq9S\ntUh3Ce1SL8VLtHCR5nA4HBabTR1A5iIxgTH4+5G/Ee4XXv3G1N1NA9+oa33gQCKgAClbOneuerBw\nDxGllgEt9S542jhj2TJg504lsA0gLu7Dh5UKZkFBwA03GEeWA3BvHm24XAebY27E//0f+XviBHFn\nfy+1JOvYUb3dZil3WZsiBiB42Vp4p2WqG7VI4uteqLaUsXUrMGmSbjsApAJccjI8yvXNY3xtvnAr\nUXtAksIMGrPQGAQHFnldwEWaw+FwrjY0L5oKMLWkAwPVUeCA64KwYgUwdSoweDARJF9f4JNPlKju\n1q1JqVOWqVOBBx6Qv7pLDSlsPW6CDqMCUwMGKJ8DAtR/Ab0YT5tG/mpz448fJ/vRPGuWY8eUz3v3\nkvKm9HxnzNJvz0JFmhFrdwNXfoDNHyElJLjNTVr/YMKD+g25SHM4HM51AI3cpiL95pvk71NP6bel\npTyr6/jXrx/w9NPqZU89ZZziRQkKAubMIaU/v/oKflJglVuwgSdh/HgyTz9ihLJMqhoJgAS7Aeqg\nOKMgtYkTVW52mVatyPw8hVrdp04py+LjVc1fjARXxbPPAo8+SlzhErRSnBVKudhGog0exeUQJwIl\n7wC5z2YhbvU/wNq16uPVVgvXGsBFmsPhcK42NKKbWqJduxIBYJpyyNCynO+/X3fn06sX8Mgj8HMn\nudkloh349FO1SLVrR+Z7n3lGWUZ7fQOK8LIiHa5x/ffuTSqV0ZQsNjUrOlot0o4C95jIaqOOYzpm\nzACefFL+SoXdTVTkL6DSTba2TSLgfzyd1CHv25fUON+2jTQPoVMRV9GS5nnSHA6Hc7UZPpwEcfV2\noe1hdLQSuVzH0H7P+aX5wBOvq1dSAWVd5mYzEa+//wbS0sgytk82k8aGiROB554jnx95hMyb/+9/\nSp54165qbwFbHa5JE9K+MzpaFUBWbRQ6ZedO+WPLi8CJAKBppQdOWMi0Q8DFEnW+N+umb9ZMqdpG\n0VZKq0O4Jc3hcDhXG0Eg7mmLi3aSIFwV641a0vll+fqVNPKaFWEAuOsu4IMPlFSxbt2UdWwHsscf\nV0TYy4vkHLPz7/36qS1ptuJav35EaJn5c4BYvS4jCe/8JcDL2614OUvpM96oz+2KlaxFK9CALv+6\nLuEizeFwOBwAQHIkSfdSlc987DHyl3U/p6cDZ8+qd37+eSK8U6caH9yoBSo78NC6u1m3Od2XjSbv\n3Zu06wQwTCojrguMY+lPanEHFQPvrDOh8ZkceZWh2/y11xwfy0i46wju7uZwOBwOAODlni8joWkC\n+rfqryz87DMyP83mNhsFfpnNpAEHpVkz8nfsWODkSceegL/+IrnbguBYpGk51+Bgcj4JCUBCAjw/\n+ghFb09QenRHRal7c7OwQWxlZfA9dBKQsqw2RwA9zkCdQR0ba3wc4Kpa0lykORwOhwOAlD8dGDNQ\nvfByXO0XLiju8S+/dL5tly7KZ7aYCfuZtcIff1z5nJCgLh3qrAANk9512g94cIiyqvcI0lRkzTwg\nknr6w8IcH+sqWtLc3c3hcDic2iUwsPqUsepgBwZGrnJA3zAlKYm0QJ0zR7+tJOAigH7DgTRmyrvc\nQoLJbh1O1gMgrvXkZFIC9JVX1MfilnT9UVZRpmo1ZzVZ4WH1QIm9BPYqZchmM9tgs9hQVF6ESpFJ\nrre4w83shkvll1AlKhGZnlZPWEwWFJQVgMXL6gWTYEJheaFquY+bD6rEKhTZ1SM2X5svKqoqUGxX\nHhKTYIK3mzfKK8tRWqF0cjELZni5efFr4tfEr4lf07VzTUuXotTfC5VlBfClKxo3Nr4mJnrcPuBW\nlAy/C+ZHR8HLzUudzw2g1Msd7gC2RACpjYBKjYlaYQZOBpmwJaIKN+b6kAA5mu41ZAgpovLee+Q7\nn5OuP97d/C7e2PCG/H1Uh1H45vZv8NTqpzBz90x5+YTkCZjYayKG/TgMv534TV7+9aCvMbrjaHT9\npisOZh+Ul//631/Rr1U/hE0OUz2Y+x/bj3C/cPi9p+4dmz8+H2n5aWj3RTt5mY+bDwpeKsAfJ//A\nrfNvlZe3bdwWBx4/gDkpc/DIikfk5X1b9sWa4Wv4NfFr4tfEr+nauabu0eSaNjBWbVCQ8TX9lzTl\n2BQB3NTlV2B6M/matDz399v4DMDxAMBaCZQZqJ+bYMHxgHLcWOWnX8m60q+iSAuiWA8lVGqRsLAw\npKen19rxGtSI8t84SubXxK+JXxO/JhevyVdKCcOFC6ho5Gd8TaeOo9TPS25aQq9JO49eUlYED5sX\nNkeQOehyI5EWzfhjdiVu9LlB34Jz+nSS1w2Q2u7nzukPcJk40zEu0hwOh8NpmFChrazUd85ydV+K\nKAKpqRC9vRH7XWecKEpHhajkXlkEC1oJgTj4eiaEhx8GZs5U7z9jBikxCpC66PkGueSXiTMd44Fj\nHA6Hw2mY0OCzmgo0S58+wG+Saz4qCkJQENaMWo+WAS3hZnaDt9UbbmY3tApshTVPbIMwcyZJ89LC\nRpvzwDEOh8PhXPekpQGlpdVvZ8ShQ0BODukxrSHSPxKHnjiELWlbcPzicbQKaIUe4T0gCALwcHPj\n47VqpXyuqADKy0l+dx3D3d0cDofD4bjC2rXA118DP/0EXLzoPC+7BjjTMW5JczgcDofjCn36kOpp\nV9G25ZY0h8PhcDj1CA8c43A4HA7nGoSLNIfD4XA4DRQu0hwOh8PhNFC4SHM4HA6H00DhIs3hcDgc\nTgOFizSHw+FwOA0ULtIcDofD4TRQuEhzOBwOh9NA4SLN4XA4HE4DhYs0h8PhcDgNFC7SHA6Hw+E0\nUK752t02mw2NGzeulWNdunQJ3rR/KadG8Ht3+fB7d/nwe3f58Ht3+dT2vcvOzkZZWZnhumtepGsT\n3qzj8uH37vLh9+7y4ffu8uH37vK5mveOu7s5HA6Hw2mgcJHmcDgcDqeBYp44ceLE+j6JhkS3bt3q\n+xSuWfi9u3z4vbt8+L27fPi9u3yu1r3jc9IcDofD4TRQuLubw+FwOJwGChdpDofD4XAaKFykARw7\ndgzdu3dHTEwMOnfujAMHDtT3KTUo/ve//yEqKgqCIGDPnj3ycmf3jd9ToLS0FEOGDEFMTAzi4+PR\np08fHD9+HACQlZWFW2+9FdHR0WjXrh02btwo7+ds3fVE3759ERcXh4SEBPTs2RO7d+8GwJ+7mjB7\n9mwIgoBly5YB4M+dq0RFRaF169ZISEhAQkICfvjhBwD19OyJHPHmm28WZ8+eLYqiKP70009iYmJi\n/Z5QA2PDhg1iWlqaGBkZKe7evVte7uy+8XsqiiUlJeKqVavEqqoqURRFcfr06WJycrIoiqL40EMP\niRMmTBBFURR37NghhoaGiuXl5dWuu57Izc2VPy9ZskSMi4sTRZE/d65y6tQpsVu3bmJSUpK4dOlS\nURT5c+cq2ncdpT6evetepDMzM0UfHx/RbreLoiiKVVVVYpMmTcRjx47V85k1PNgH19l94/fUmL//\n/luMjIwURVEUvby8xIyMDHld586dxbVr11a77npl9uzZYnx8PH/uXKSyslLs3bu3uHPnTjE5OVkW\naf7cuYaRSNfXs3fdu7vT0tIQEhICi8UCABAEAREREThz5kw9n1nDxtl94/fUmGnTpmHw4MHIycmB\n3W5H06ZN5XVRUVE4c+aM03XXIyNGjEB4eDhee+01zJ07lz93LjJ58mT06NEDnTp1kpfx565mjBgx\nAu3bt8eoUaOQnZ1db8/edS/SHM7VYNKkSTh+/Djefffd+j6Va4o5c+YgLS0Nb7/9Nl588cX6Pp1r\ngv3792Px4sV49dVX6/tUrlk2btyIvXv34p9//kFQUBBGjhxZb+dy3Yt0eHg4MjIyUFFRAQAQRRFn\nzpxBREREPZ9Zw8bZfeP3VM1HH32EJUuWYPXq1fD09ERgYCAsFgvOnz8vb5OamoqIiAin665nRo4c\niXXr1iEsLIw/d9WwadMmpKamIjo6GlFRUdi+fTvGjBmDH3/8kT93LkKv22q14plnnsGmTZvq7Z13\n3Yt0cHAwOnbsiHnz5gEAFi9ejLCwMLRq1aqez6xh4+y+8XuqMHnyZCxYsABr166Fv7+/vPyuu+7C\nl19+CQD4+++/cfbsWSQnJ1e77nohLy8P586dk78vW7YMgYGB/LlzgcceewwZGRlITU1FamoqkpKS\n8NVXX+Gxxx7jz50LFBUVIS8vT/6+YMECdOjQof6evSue1f4XcPjwYTEpKUmMjo4WO3XqJO7du7e+\nT6lBMWbMGDE0NFQ0m81icHCw2LJlS1EUnd83fk9FMS0tTQQgtmjRQoyPjxfj4+PFLl26iKIoiufP\nnxf79OkjtmrVSmzbtq34559/yvs5W3e9kJqaKnbu3Fls166dGBcXJ/bu3VsO5OHPXc1gA8f4c1c9\nJ06cEBMSEsT27duL7dq1E2+//Xbx1KlToijWz7PHy4JyOBwOh9NAue7d3RwOh8PhNFS4SHM4HA6H\n00DhIs3hcDgcTgOFizSHw+FwOA0ULtIcDofD4TRQuEhzOBwOh9NAsdT3CXA4nLolKioKNpsNHh4e\n8rK5c+eiffv2tfYbqampSEhIUBWB4HA4Vw4XaQ7nOuCHH35AQkJCfZ8Gh8OpIdzdzeFcpwiCgFdf\nfRUdOnRATEwM5s+fL69bs2YNOnbsiLi4OCQnJ+PgwYPyutmzZyMhIQHx8fFITExEamqqvG7ChAno\n1KkTWrVqhV9++eVqXg6H86+EW9IcznXAPffco3J3b9u2DQAR6t27d+PkyZNITExEjx494Onpifvv\nvx/r169H+/btMX/+fNx55504cOAANmzYgDfffBNbt25FSEgIiouLAQBZWVnIz89HXFwc3njjDfz6\n6694+umnMWDAgHq5Xg7n3wIvC8rh/MuJiorCsmXLdO5uQRCQmpqKyMhIAMCQIUMwbNgwNGrUCB9/\n/DHWr18vb+vv74/9+/dj2rRp8PDwwJtvvqk6VmpqKmJjY1FcXAxBEJCfn4/AwEC5KxCHw7k8uLub\nw+HICIJw2fvabDZ5f7PZjMrKyto6LQ7nuoWLNIdzHTN79mwAxBLetGkTevbsiaSkJOzbtw/79+8H\nACxcuBChoaEIDQ3FoEGDMG/ePGRkZAAAiouLZZc3h8OpfficNIdzHaCdk54yZQoAoLKyEh06dEBR\nURE++eQTREVFAQDmz5+PESNGoKKiAo0aNcJPP/0EQRBw0003YcKECejXrx8EQYCbmxsWLVpUH5fE\n4VwX8DlpDuc6RRAE5Obmwt/fv75PhcPhOIC7uzkcDofDaaBwdzeHc53CnWgcTsOHW9IcDofD4TRQ\nuEhzOBwOh9NA4SLN4XA4HE4DhYs0h8PhcDgNFC7SHA6Hw+E0ULhIczgcDofTQPl//1jn197rcbcA\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 560x560 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ed907962-45fb-4872-f599-02ac2436ac74",
        "id": "xfOmidP1Dz6r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "source": [
        "pred_2_classes = opt_model_2.predict_classes(test_images)\n",
        "confusion_mtx = confusion_matrix(test_labels_raw, pred_2_classes) \n",
        "plot_confusion_matrix(confusion_mtx, classes=range(4), title='Model 2 confusion matrix')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUUAAAEmCAYAAAD1FIKpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nudPxAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpNp1vzTm1E1",
        "colab_type": "text"
      },
      "source": [
        "**Result**: 41 samples were assigned the wrong abnormality type, that is a 87.8% accuracy in predicting that feature. On the other side, 30.6% were incorrectly classified as benign or malignant, so the harmfulness prediction accuracy is only 69.4%.\n",
        "The overall accuracy is better than in the previous model (61.3% vs 57.7%). Even after a very long training the loss was still decreasing; increasing the learning rate would be a risky move here, since the evolution is already quite noisy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9u8lGKM0Xwhe"
      },
      "source": [
        "## Experiment 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gmZPgT0OXwhm"
      },
      "source": [
        "What about another convolutional block? Does it help distinguishing between malignant and benign bodies? The next experiment provides an answer to these question, by training a deeper model with an extra Conv2D layer with 512 features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "2816e7e2-1142-436e-8be8-45129dc87f7c",
        "id": "9McdJHAmXwho",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "# Model 3\n",
        "\n",
        "model_3 = models.Sequential()\n",
        "model_3.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(150, 150, 1)))\n",
        "model_3.add(layers.MaxPooling2D((2, 2)))\n",
        "model_3.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model_3.add(layers.MaxPooling2D((2, 2)))\n",
        "model_3.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
        "model_3.add(layers.MaxPooling2D((2, 2)))\n",
        "model_3.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
        "model_3.add(layers.MaxPooling2D((2, 2)))\n",
        "model_3.add(layers.Flatten())\n",
        "model_3.add(layers.Dense(64, activation='relu'))\n",
        "model_3.add(layers.Dropout(0.5))\n",
        "model_3.add(layers.Dense(4, activation='softmax'))\n",
        "\n",
        "model_3.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_23 (Conv2D)           (None, 148, 148, 64)      640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_22 (MaxPooling (None, 74, 74, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 72, 72, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_23 (MaxPooling (None, 36, 36, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 34, 34, 256)       295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_24 (MaxPooling (None, 17, 17, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 15, 15, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_25 (MaxPooling (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 64)                1605696   \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 4)                 260       \n",
            "=================================================================\n",
            "Total params: 3,155,780\n",
            "Trainable params: 3,155,780\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0befe55b-ed26-4be2-fbef-cdf5d71341b9",
        "id": "EQWFk6buXwhx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Early stopping (stop training after the validation loss reaches the minimum)\n",
        "earlystopping = EarlyStopping(monitor='val_loss', mode='min', patience=80, verbose=1)\n",
        "\n",
        "# Callback for checkpointing\n",
        "checkpoint = ModelCheckpoint('model_3_4cl_best.h5', \n",
        "        monitor='val_loss', mode='min', verbose=1, \n",
        "        save_best_only=True, save_freq='epoch'\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model_3.compile(optimizer=RMSprop(learning_rate=0.001, decay=5e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "history_3 = model_3.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=int(0.8*n_train_img) // 128,\n",
        "        epochs=500,\n",
        "        validation_data=validation_generator,\n",
        "        callbacks=[checkpoint, earlystopping],\n",
        "        shuffle=True,\n",
        "        verbose=1,\n",
        "        initial_epoch=0\n",
        ")\n",
        "\n",
        "# Save\n",
        "models.save_model(model_3, 'model_3_4cl_end.h5')\n",
        "!cp model* \"/content/gdrive/My Drive/models/\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.9434 - acc: 0.2987Epoch 1/500\n",
            " 5/16 [========>.....................] - ETA: 2s - loss: 1.3707 - acc: 0.3514\n",
            "Epoch 00001: val_loss improved from inf to 1.37069, saving model to model_3_4cl_best.h5\n",
            "16/16 [==============================] - 9s 537ms/step - loss: 1.9075 - acc: 0.3060 - val_loss: 1.3707 - val_acc: 0.3514\n",
            "Epoch 2/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.3887 - acc: 0.3416Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 1.3746 - acc: 0.3555\n",
            "Epoch 00002: val_loss did not improve from 1.37069\n",
            "16/16 [==============================] - 6s 352ms/step - loss: 1.3862 - acc: 0.3438 - val_loss: 1.3774 - val_acc: 0.3514\n",
            "Epoch 3/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.3813 - acc: 0.3448Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 1.3575 - acc: 0.3613\n",
            "Epoch 00003: val_loss improved from 1.37069 to 1.36982, saving model to model_3_4cl_best.h5\n",
            "16/16 [==============================] - 6s 376ms/step - loss: 1.3799 - acc: 0.3467 - val_loss: 1.3698 - val_acc: 0.3514\n",
            "Epoch 4/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.3685 - acc: 0.3533Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.3592 - acc: 0.3672\n",
            "Epoch 00004: val_loss improved from 1.36982 to 1.36924, saving model to model_3_4cl_best.h5\n",
            "16/16 [==============================] - 6s 379ms/step - loss: 1.3676 - acc: 0.3517 - val_loss: 1.3692 - val_acc: 0.3570\n",
            "Epoch 5/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.3815 - acc: 0.3565Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.3520 - acc: 0.3613\n",
            "Epoch 00005: val_loss did not improve from 1.36924\n",
            "16/16 [==============================] - 6s 383ms/step - loss: 1.3793 - acc: 0.3557 - val_loss: 1.3710 - val_acc: 0.3514\n",
            "Epoch 6/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.3611 - acc: 0.3533Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.3475 - acc: 0.3613\n",
            "Epoch 00006: val_loss improved from 1.36924 to 1.36236, saving model to model_3_4cl_best.h5\n",
            "16/16 [==============================] - 6s 383ms/step - loss: 1.3607 - acc: 0.3527 - val_loss: 1.3624 - val_acc: 0.3514\n",
            "Epoch 7/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.3538 - acc: 0.3589Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.3548 - acc: 0.4160\n",
            "Epoch 00007: val_loss did not improve from 1.36236\n",
            "16/16 [==============================] - 6s 389ms/step - loss: 1.3549 - acc: 0.3550 - val_loss: 1.3639 - val_acc: 0.4168\n",
            "Epoch 8/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.3605 - acc: 0.3385Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.3367 - acc: 0.3613\n",
            "Epoch 00008: val_loss improved from 1.36236 to 1.35425, saving model to model_3_4cl_best.h5\n",
            "16/16 [==============================] - 6s 389ms/step - loss: 1.3599 - acc: 0.3413 - val_loss: 1.3543 - val_acc: 0.3514\n",
            "Epoch 9/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.3522 - acc: 0.3735Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.3646 - acc: 0.3633\n",
            "Epoch 00009: val_loss did not improve from 1.35425\n",
            "16/16 [==============================] - 6s 379ms/step - loss: 1.5194 - acc: 0.3691 - val_loss: 1.3719 - val_acc: 0.3533\n",
            "Epoch 10/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.3616 - acc: 0.3500Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.3239 - acc: 0.3652\n",
            "Epoch 00010: val_loss improved from 1.35425 to 1.34270, saving model to model_3_4cl_best.h5\n",
            "16/16 [==============================] - 6s 386ms/step - loss: 1.3602 - acc: 0.3501 - val_loss: 1.3427 - val_acc: 0.3551\n",
            "Epoch 11/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.3395 - acc: 0.3659Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.3209 - acc: 0.3691\n",
            "Epoch 00011: val_loss did not improve from 1.34270\n",
            "16/16 [==============================] - 6s 378ms/step - loss: 1.3367 - acc: 0.3670 - val_loss: 1.3442 - val_acc: 0.3589\n",
            "Epoch 12/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.3354 - acc: 0.3693Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.3117 - acc: 0.3809\n",
            "Epoch 00012: val_loss improved from 1.34270 to 1.30169, saving model to model_3_4cl_best.h5\n",
            "16/16 [==============================] - 6s 389ms/step - loss: 1.3324 - acc: 0.3706 - val_loss: 1.3017 - val_acc: 0.3794\n",
            "Epoch 13/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.3366 - acc: 0.3643Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.3359 - acc: 0.3555\n",
            "Epoch 00013: val_loss did not improve from 1.30169\n",
            "16/16 [==============================] - 6s 378ms/step - loss: 1.3369 - acc: 0.3655 - val_loss: 1.3498 - val_acc: 0.3533\n",
            "Epoch 14/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.3229 - acc: 0.3667Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.3016 - acc: 0.3672\n",
            "Epoch 00014: val_loss improved from 1.30169 to 1.30131, saving model to model_3_4cl_best.h5\n",
            "16/16 [==============================] - 6s 385ms/step - loss: 1.3224 - acc: 0.3711 - val_loss: 1.3013 - val_acc: 0.3645\n",
            "Epoch 15/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.3274 - acc: 0.3698Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.2836 - acc: 0.4062\n",
            "Epoch 00015: val_loss improved from 1.30131 to 1.29402, saving model to model_3_4cl_best.h5\n",
            "16/16 [==============================] - 6s 379ms/step - loss: 1.3258 - acc: 0.3681 - val_loss: 1.2940 - val_acc: 0.4019\n",
            "Epoch 16/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.3131 - acc: 0.3735Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.3184 - acc: 0.4551\n",
            "Epoch 00016: val_loss did not improve from 1.29402\n",
            "16/16 [==============================] - 6s 374ms/step - loss: 1.3163 - acc: 0.3731 - val_loss: 1.3174 - val_acc: 0.4561\n",
            "Epoch 17/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.3351 - acc: 0.3804Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.3249 - acc: 0.3379\n",
            "Epoch 00017: val_loss did not improve from 1.29402\n",
            "16/16 [==============================] - 6s 370ms/step - loss: 1.3389 - acc: 0.3835 - val_loss: 1.3131 - val_acc: 0.3439\n",
            "Epoch 18/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.2940 - acc: 0.3793Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 1.2394 - acc: 0.3516\n",
            "Epoch 00018: val_loss improved from 1.29402 to 1.21880, saving model to model_3_4cl_best.h5\n",
            "16/16 [==============================] - 5s 336ms/step - loss: 1.2938 - acc: 0.3731 - val_loss: 1.2188 - val_acc: 0.3570\n",
            "Epoch 19/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.3900 - acc: 0.3814Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 1.2634 - acc: 0.3848\n",
            "Epoch 00019: val_loss did not improve from 1.21880\n",
            "16/16 [==============================] - 6s 366ms/step - loss: 1.3833 - acc: 0.3835 - val_loss: 1.2578 - val_acc: 0.3869\n",
            "Epoch 20/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.2658 - acc: 0.3973Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 1.2023 - acc: 0.3984\n",
            "Epoch 00020: val_loss did not improve from 1.21880\n",
            "16/16 [==============================] - 6s 372ms/step - loss: 1.2595 - acc: 0.4039 - val_loss: 1.2211 - val_acc: 0.3925\n",
            "Epoch 21/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.2332 - acc: 0.4334Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.2058 - acc: 0.5000\n",
            "Epoch 00021: val_loss improved from 1.21880 to 1.20992, saving model to model_3_4cl_best.h5\n",
            "16/16 [==============================] - 6s 392ms/step - loss: 1.2382 - acc: 0.4287 - val_loss: 1.2099 - val_acc: 0.4972\n",
            "Epoch 22/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.2224 - acc: 0.4260Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.1941 - acc: 0.4180\n",
            "Epoch 00022: val_loss did not improve from 1.20992\n",
            "16/16 [==============================] - 6s 386ms/step - loss: 1.2208 - acc: 0.4302 - val_loss: 1.2238 - val_acc: 0.4131\n",
            "Epoch 23/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.2056 - acc: 0.4323Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.2294 - acc: 0.4746\n",
            "Epoch 00023: val_loss did not improve from 1.20992\n",
            "16/16 [==============================] - 6s 382ms/step - loss: 1.2183 - acc: 0.4219 - val_loss: 1.2408 - val_acc: 0.4710\n",
            "Epoch 24/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.2001 - acc: 0.4515Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.1412 - acc: 0.4883\n",
            "Epoch 00024: val_loss improved from 1.20992 to 1.17406, saving model to model_3_4cl_best.h5\n",
            "16/16 [==============================] - 6s 391ms/step - loss: 1.1988 - acc: 0.4570 - val_loss: 1.1741 - val_acc: 0.4785\n",
            "Epoch 25/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1861 - acc: 0.4334Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0982 - acc: 0.5332\n",
            "Epoch 00025: val_loss improved from 1.17406 to 1.10296, saving model to model_3_4cl_best.h5\n",
            "16/16 [==============================] - 6s 390ms/step - loss: 1.1808 - acc: 0.4396 - val_loss: 1.1030 - val_acc: 0.5290\n",
            "Epoch 26/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1924 - acc: 0.4536Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.1176 - acc: 0.5059\n",
            "Epoch 00026: val_loss improved from 1.10296 to 1.07682, saving model to model_3_4cl_best.h5\n",
            "16/16 [==============================] - 6s 393ms/step - loss: 1.1931 - acc: 0.4521 - val_loss: 1.0768 - val_acc: 0.5084\n",
            "Epoch 27/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1853 - acc: 0.4377Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.1261 - acc: 0.5059\n",
            "Epoch 00027: val_loss did not improve from 1.07682\n",
            "16/16 [==============================] - 6s 392ms/step - loss: 1.1858 - acc: 0.4382 - val_loss: 1.1357 - val_acc: 0.5047\n",
            "Epoch 28/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1460 - acc: 0.4594Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0934 - acc: 0.5078\n",
            "Epoch 00028: val_loss did not improve from 1.07682\n",
            "16/16 [==============================] - 6s 383ms/step - loss: 1.1386 - acc: 0.4630 - val_loss: 1.1423 - val_acc: 0.5047\n",
            "Epoch 29/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1633 - acc: 0.4476Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0967 - acc: 0.5410\n",
            "Epoch 00029: val_loss did not improve from 1.07682\n",
            "16/16 [==============================] - 6s 378ms/step - loss: 1.1610 - acc: 0.4459 - val_loss: 1.1432 - val_acc: 0.5346\n",
            "Epoch 30/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1460 - acc: 0.4732Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.1063 - acc: 0.5195\n",
            "Epoch 00030: val_loss improved from 1.07682 to 1.06790, saving model to model_3_4cl_best.h5\n",
            "16/16 [==============================] - 6s 384ms/step - loss: 1.1474 - acc: 0.4754 - val_loss: 1.0679 - val_acc: 0.5196\n",
            "Epoch 31/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1153 - acc: 0.4865Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.3449 - acc: 0.3770\n",
            "Epoch 00031: val_loss did not improve from 1.06790\n",
            "16/16 [==============================] - 6s 382ms/step - loss: 1.1125 - acc: 0.4873 - val_loss: 1.2941 - val_acc: 0.3813\n",
            "Epoch 32/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1481 - acc: 0.4912Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0939 - acc: 0.5234\n",
            "Epoch 00032: val_loss improved from 1.06790 to 1.05192, saving model to model_3_4cl_best.h5\n",
            "16/16 [==============================] - 6s 381ms/step - loss: 1.1528 - acc: 0.4834 - val_loss: 1.0519 - val_acc: 0.5308\n",
            "Epoch 33/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1263 - acc: 0.5050Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0629 - acc: 0.5332\n",
            "Epoch 00033: val_loss improved from 1.05192 to 1.02553, saving model to model_3_4cl_best.h5\n",
            "16/16 [==============================] - 6s 380ms/step - loss: 1.1219 - acc: 0.5057 - val_loss: 1.0255 - val_acc: 0.5346\n",
            "Epoch 34/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1235 - acc: 0.4838Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0620 - acc: 0.5098\n",
            "Epoch 00034: val_loss improved from 1.02553 to 1.02473, saving model to model_3_4cl_best.h5\n",
            "16/16 [==============================] - 6s 374ms/step - loss: 1.1256 - acc: 0.4834 - val_loss: 1.0247 - val_acc: 0.5103\n",
            "Epoch 35/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0979 - acc: 0.5125Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 1.0771 - acc: 0.5469\n",
            "Epoch 00035: val_loss did not improve from 1.02473\n",
            "16/16 [==============================] - 5s 335ms/step - loss: 1.0991 - acc: 0.5102 - val_loss: 1.0279 - val_acc: 0.5495\n",
            "Epoch 36/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1044 - acc: 0.4923Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 1.0215 - acc: 0.5195\n",
            "Epoch 00036: val_loss did not improve from 1.02473\n",
            "16/16 [==============================] - 6s 375ms/step - loss: 1.1023 - acc: 0.4893 - val_loss: 1.0824 - val_acc: 0.5103\n",
            "Epoch 37/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1048 - acc: 0.4785Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 1.0851 - acc: 0.4863\n",
            "Epoch 00037: val_loss did not improve from 1.02473\n",
            "16/16 [==============================] - 6s 372ms/step - loss: 1.0997 - acc: 0.4769 - val_loss: 1.0590 - val_acc: 0.4916\n",
            "Epoch 38/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1199 - acc: 0.4948Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0174 - acc: 0.5645\n",
            "Epoch 00038: val_loss improved from 1.02473 to 0.99355, saving model to model_3_4cl_best.h5\n",
            "16/16 [==============================] - 6s 382ms/step - loss: 1.1152 - acc: 0.4946 - val_loss: 0.9936 - val_acc: 0.5701\n",
            "Epoch 39/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0863 - acc: 0.4886Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0330 - acc: 0.5605\n",
            "Epoch 00039: val_loss did not improve from 0.99355\n",
            "16/16 [==============================] - 6s 384ms/step - loss: 1.0841 - acc: 0.4914 - val_loss: 1.0087 - val_acc: 0.5626\n",
            "Epoch 40/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0632 - acc: 0.4995Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9864 - acc: 0.5391\n",
            "Epoch 00040: val_loss improved from 0.99355 to 0.96747, saving model to model_3_4cl_best.h5\n",
            "16/16 [==============================] - 6s 389ms/step - loss: 1.0650 - acc: 0.4990 - val_loss: 0.9675 - val_acc: 0.5383\n",
            "Epoch 41/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0914 - acc: 0.4987Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0099 - acc: 0.5449\n",
            "Epoch 00041: val_loss did not improve from 0.96747\n",
            "16/16 [==============================] - 6s 382ms/step - loss: 1.0906 - acc: 0.5012 - val_loss: 0.9822 - val_acc: 0.5439\n",
            "Epoch 42/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0879 - acc: 0.4955Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9892 - acc: 0.5625\n",
            "Epoch 00042: val_loss did not improve from 0.96747\n",
            "16/16 [==============================] - 6s 386ms/step - loss: 1.0810 - acc: 0.5012 - val_loss: 0.9708 - val_acc: 0.5664\n",
            "Epoch 43/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0570 - acc: 0.5135Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9976 - acc: 0.5801\n",
            "Epoch 00043: val_loss did not improve from 0.96747\n",
            "16/16 [==============================] - 6s 378ms/step - loss: 1.0558 - acc: 0.5117 - val_loss: 0.9786 - val_acc: 0.5813\n",
            "Epoch 44/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0861 - acc: 0.4971Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0066 - acc: 0.5645\n",
            "Epoch 00044: val_loss did not improve from 0.96747\n",
            "16/16 [==============================] - 6s 380ms/step - loss: 1.0844 - acc: 0.4953 - val_loss: 0.9864 - val_acc: 0.5664\n",
            "Epoch 45/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0608 - acc: 0.5308Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0831 - acc: 0.5176\n",
            "Epoch 00045: val_loss did not improve from 0.96747\n",
            "16/16 [==============================] - 6s 375ms/step - loss: 1.0635 - acc: 0.5288 - val_loss: 1.0470 - val_acc: 0.5196\n",
            "Epoch 46/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0789 - acc: 0.4966Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9944 - acc: 0.5293\n",
            "Epoch 00046: val_loss did not improve from 0.96747\n",
            "16/16 [==============================] - 6s 387ms/step - loss: 1.0788 - acc: 0.4978 - val_loss: 0.9725 - val_acc: 0.5308\n",
            "Epoch 47/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0362 - acc: 0.5260Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9822 - acc: 0.5898\n",
            "Epoch 00047: val_loss did not improve from 0.96747\n",
            "16/16 [==============================] - 6s 385ms/step - loss: 1.0380 - acc: 0.5249 - val_loss: 0.9833 - val_acc: 0.5813\n",
            "Epoch 48/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0485 - acc: 0.5231Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0183 - acc: 0.5469\n",
            "Epoch 00048: val_loss did not improve from 0.96747\n",
            "16/16 [==============================] - 6s 378ms/step - loss: 1.0500 - acc: 0.5201 - val_loss: 0.9981 - val_acc: 0.5514\n",
            "Epoch 49/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0737 - acc: 0.4987Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.1257 - acc: 0.4785\n",
            "Epoch 00049: val_loss did not improve from 0.96747\n",
            "16/16 [==============================] - 6s 378ms/step - loss: 1.0671 - acc: 0.5032 - val_loss: 1.1614 - val_acc: 0.4766\n",
            "Epoch 50/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0338 - acc: 0.5294Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9854 - acc: 0.5273\n",
            "Epoch 00050: val_loss did not improve from 0.96747\n",
            "16/16 [==============================] - 6s 373ms/step - loss: 1.0447 - acc: 0.5236 - val_loss: 1.0019 - val_acc: 0.5215\n",
            "Epoch 51/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0218 - acc: 0.5307Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9820 - acc: 0.5781\n",
            "Epoch 00051: val_loss did not improve from 0.96747\n",
            "16/16 [==============================] - 6s 371ms/step - loss: 1.0271 - acc: 0.5281 - val_loss: 0.9885 - val_acc: 0.5701\n",
            "Epoch 52/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0288 - acc: 0.5310Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 1.1051 - acc: 0.4258\n",
            "Epoch 00052: val_loss did not improve from 0.96747\n",
            "16/16 [==============================] - 5s 333ms/step - loss: 1.0310 - acc: 0.5271 - val_loss: 1.1237 - val_acc: 0.4262\n",
            "Epoch 53/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0664 - acc: 0.4997Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.9851 - acc: 0.5469\n",
            "Epoch 00053: val_loss did not improve from 0.96747\n",
            "16/16 [==============================] - 6s 361ms/step - loss: 1.0578 - acc: 0.5072 - val_loss: 1.0046 - val_acc: 0.5458\n",
            "Epoch 54/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0429 - acc: 0.5188Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.9538 - acc: 0.5293\n",
            "Epoch 00054: val_loss did not improve from 0.96747\n",
            "16/16 [==============================] - 6s 367ms/step - loss: 1.0400 - acc: 0.5201 - val_loss: 0.9749 - val_acc: 0.5271\n",
            "Epoch 55/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0260 - acc: 0.5268Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9586 - acc: 0.5469\n",
            "Epoch 00055: val_loss did not improve from 0.96747\n",
            "16/16 [==============================] - 6s 387ms/step - loss: 1.0211 - acc: 0.5286 - val_loss: 0.9751 - val_acc: 0.5477\n",
            "Epoch 56/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0003 - acc: 0.5344Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0962 - acc: 0.4648\n",
            "Epoch 00056: val_loss did not improve from 0.96747\n",
            "16/16 [==============================] - 6s 386ms/step - loss: 1.0102 - acc: 0.5306 - val_loss: 1.1434 - val_acc: 0.4598\n",
            "Epoch 57/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0826 - acc: 0.4902Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0785 - acc: 0.4766\n",
            "Epoch 00057: val_loss did not improve from 0.96747\n",
            "16/16 [==============================] - 6s 390ms/step - loss: 1.0870 - acc: 0.4898 - val_loss: 1.1339 - val_acc: 0.4710\n",
            "Epoch 58/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0253 - acc: 0.5252Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9329 - acc: 0.5684\n",
            "Epoch 00058: val_loss did not improve from 0.96747\n",
            "16/16 [==============================] - 6s 378ms/step - loss: 1.0205 - acc: 0.5281 - val_loss: 0.9962 - val_acc: 0.5589\n",
            "Epoch 59/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0121 - acc: 0.5432Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9691 - acc: 0.5645\n",
            "Epoch 00059: val_loss did not improve from 0.96747\n",
            "16/16 [==============================] - 6s 395ms/step - loss: 1.0106 - acc: 0.5420 - val_loss: 0.9990 - val_acc: 0.5607\n",
            "Epoch 60/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0317 - acc: 0.5167Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9622 - acc: 0.5781\n",
            "Epoch 00060: val_loss did not improve from 0.96747\n",
            "16/16 [==============================] - 6s 380ms/step - loss: 1.0254 - acc: 0.5176 - val_loss: 1.0001 - val_acc: 0.5701\n",
            "Epoch 61/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9925 - acc: 0.5443Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9207 - acc: 0.6016\n",
            "Epoch 00061: val_loss improved from 0.96747 to 0.94749, saving model to model_3_4cl_best.h5\n",
            "16/16 [==============================] - 6s 383ms/step - loss: 0.9933 - acc: 0.5404 - val_loss: 0.9475 - val_acc: 0.5944\n",
            "Epoch 62/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0297 - acc: 0.5417Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0278 - acc: 0.5293\n",
            "Epoch 00062: val_loss did not improve from 0.94749\n",
            "16/16 [==============================] - 6s 382ms/step - loss: 1.0334 - acc: 0.5361 - val_loss: 1.0617 - val_acc: 0.5234\n",
            "Epoch 63/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9910 - acc: 0.5210Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9359 - acc: 0.5801\n",
            "Epoch 00063: val_loss did not improve from 0.94749\n",
            "16/16 [==============================] - 6s 381ms/step - loss: 0.9839 - acc: 0.5281 - val_loss: 0.9826 - val_acc: 0.5738\n",
            "Epoch 64/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9962 - acc: 0.5374Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0213 - acc: 0.5215\n",
            "Epoch 00064: val_loss did not improve from 0.94749\n",
            "16/16 [==============================] - 6s 379ms/step - loss: 1.0036 - acc: 0.5355 - val_loss: 1.0379 - val_acc: 0.5178\n",
            "Epoch 65/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0006 - acc: 0.5257Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0407 - acc: 0.5020\n",
            "Epoch 00065: val_loss did not improve from 0.94749\n",
            "16/16 [==============================] - 6s 378ms/step - loss: 1.0102 - acc: 0.5216 - val_loss: 1.1115 - val_acc: 0.4953\n",
            "Epoch 66/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9908 - acc: 0.5172Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9468 - acc: 0.5664\n",
            "Epoch 00066: val_loss did not improve from 0.94749\n",
            "16/16 [==============================] - 6s 375ms/step - loss: 0.9924 - acc: 0.5171 - val_loss: 0.9960 - val_acc: 0.5626\n",
            "Epoch 67/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0106 - acc: 0.5316Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9245 - acc: 0.5586\n",
            "Epoch 00067: val_loss did not improve from 0.94749\n",
            "16/16 [==============================] - 6s 382ms/step - loss: 1.0102 - acc: 0.5325 - val_loss: 0.9543 - val_acc: 0.5533\n",
            "Epoch 68/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9963 - acc: 0.5581Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9014 - acc: 0.5566\n",
            "Epoch 00068: val_loss improved from 0.94749 to 0.93582, saving model to model_3_4cl_best.h5\n",
            "16/16 [==============================] - 6s 375ms/step - loss: 0.9940 - acc: 0.5594 - val_loss: 0.9358 - val_acc: 0.5495\n",
            "Epoch 69/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9864 - acc: 0.5464Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.8980 - acc: 0.5547\n",
            "Epoch 00069: val_loss did not improve from 0.93582\n",
            "16/16 [==============================] - 5s 333ms/step - loss: 0.9794 - acc: 0.5484 - val_loss: 0.9580 - val_acc: 0.5477\n",
            "Epoch 70/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0177 - acc: 0.5353Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.9027 - acc: 0.5703\n",
            "Epoch 00070: val_loss improved from 0.93582 to 0.92830, saving model to model_3_4cl_best.h5\n",
            "16/16 [==============================] - 6s 367ms/step - loss: 1.0130 - acc: 0.5375 - val_loss: 0.9283 - val_acc: 0.5664\n",
            "Epoch 71/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9628 - acc: 0.5507Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.9232 - acc: 0.5645\n",
            "Epoch 00071: val_loss did not improve from 0.92830\n",
            "16/16 [==============================] - 6s 373ms/step - loss: 0.9648 - acc: 0.5474 - val_loss: 0.9714 - val_acc: 0.5570\n",
            "Epoch 72/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9870 - acc: 0.5379Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9498 - acc: 0.5215\n",
            "Epoch 00072: val_loss did not improve from 0.92830\n",
            "16/16 [==============================] - 6s 380ms/step - loss: 0.9805 - acc: 0.5380 - val_loss: 0.9970 - val_acc: 0.5140\n",
            "Epoch 73/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.0379 - acc: 0.5349Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9468 - acc: 0.5742\n",
            "Epoch 00073: val_loss did not improve from 0.92830\n",
            "16/16 [==============================] - 6s 397ms/step - loss: 1.0369 - acc: 0.5312 - val_loss: 0.9842 - val_acc: 0.5664\n",
            "Epoch 74/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9989 - acc: 0.5395Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9204 - acc: 0.5977\n",
            "Epoch 00074: val_loss improved from 0.92830 to 0.89706, saving model to model_3_4cl_best.h5\n",
            "16/16 [==============================] - 6s 389ms/step - loss: 0.9983 - acc: 0.5384 - val_loss: 0.8971 - val_acc: 0.6000\n",
            "Epoch 75/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9583 - acc: 0.5607Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9609 - acc: 0.5781\n",
            "Epoch 00075: val_loss did not improve from 0.89706\n",
            "16/16 [==============================] - 6s 379ms/step - loss: 0.9595 - acc: 0.5604 - val_loss: 0.9421 - val_acc: 0.5813\n",
            "Epoch 76/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9858 - acc: 0.5500Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8984 - acc: 0.5879\n",
            "Epoch 00076: val_loss improved from 0.89706 to 0.85940, saving model to model_3_4cl_best.h5\n",
            "16/16 [==============================] - 6s 396ms/step - loss: 0.9828 - acc: 0.5494 - val_loss: 0.8594 - val_acc: 0.5963\n",
            "Epoch 77/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9612 - acc: 0.5510Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9654 - acc: 0.5176\n",
            "Epoch 00077: val_loss did not improve from 0.85940\n",
            "16/16 [==============================] - 6s 397ms/step - loss: 0.9602 - acc: 0.5527 - val_loss: 0.9462 - val_acc: 0.5159\n",
            "Epoch 78/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9821 - acc: 0.5314Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9753 - acc: 0.5234\n",
            "Epoch 00078: val_loss did not improve from 0.85940\n",
            "16/16 [==============================] - 6s 380ms/step - loss: 0.9807 - acc: 0.5359 - val_loss: 0.9565 - val_acc: 0.5346\n",
            "Epoch 79/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9882 - acc: 0.5479Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8962 - acc: 0.5625\n",
            "Epoch 00079: val_loss did not improve from 0.85940\n",
            "16/16 [==============================] - 6s 389ms/step - loss: 0.9822 - acc: 0.5503 - val_loss: 0.8834 - val_acc: 0.5682\n",
            "Epoch 80/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9797 - acc: 0.5416Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9495 - acc: 0.5410\n",
            "Epoch 00080: val_loss did not improve from 0.85940\n",
            "16/16 [==============================] - 6s 369ms/step - loss: 0.9809 - acc: 0.5425 - val_loss: 0.9503 - val_acc: 0.5439\n",
            "Epoch 81/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9763 - acc: 0.5464Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8886 - acc: 0.5977\n",
            "Epoch 00081: val_loss did not improve from 0.85940\n",
            "16/16 [==============================] - 6s 389ms/step - loss: 0.9764 - acc: 0.5454 - val_loss: 0.8780 - val_acc: 0.6000\n",
            "Epoch 82/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9626 - acc: 0.5622Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9135 - acc: 0.5723\n",
            "Epoch 00082: val_loss did not improve from 0.85940\n",
            "16/16 [==============================] - 6s 371ms/step - loss: 0.9618 - acc: 0.5617 - val_loss: 0.9146 - val_acc: 0.5682\n",
            "Epoch 83/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9860 - acc: 0.5443Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8807 - acc: 0.5762\n",
            "Epoch 00083: val_loss did not improve from 0.85940\n",
            "16/16 [==============================] - 6s 381ms/step - loss: 0.9864 - acc: 0.5415 - val_loss: 0.8920 - val_acc: 0.5738\n",
            "Epoch 84/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9376 - acc: 0.5602Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9485 - acc: 0.5469\n",
            "Epoch 00084: val_loss did not improve from 0.85940\n",
            "16/16 [==============================] - 6s 362ms/step - loss: 0.9339 - acc: 0.5617 - val_loss: 0.9592 - val_acc: 0.5439\n",
            "Epoch 85/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9917 - acc: 0.5453Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9121 - acc: 0.5918\n",
            "Epoch 00085: val_loss did not improve from 0.85940\n",
            "16/16 [==============================] - 6s 379ms/step - loss: 0.9833 - acc: 0.5503 - val_loss: 0.9257 - val_acc: 0.5944\n",
            "Epoch 86/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9270 - acc: 0.5554Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.9773 - acc: 0.5352\n",
            "Epoch 00086: val_loss did not improve from 0.85940\n",
            "16/16 [==============================] - 5s 334ms/step - loss: 0.9291 - acc: 0.5599 - val_loss: 0.9984 - val_acc: 0.5402\n",
            "Epoch 87/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9749 - acc: 0.5469Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.9537 - acc: 0.5273\n",
            "Epoch 00087: val_loss did not improve from 0.85940\n",
            "16/16 [==============================] - 6s 367ms/step - loss: 0.9770 - acc: 0.5445 - val_loss: 0.9825 - val_acc: 0.5290\n",
            "Epoch 88/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9639 - acc: 0.5549Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.9028 - acc: 0.5469\n",
            "Epoch 00088: val_loss did not improve from 0.85940\n",
            "16/16 [==============================] - 6s 371ms/step - loss: 0.9648 - acc: 0.5539 - val_loss: 0.9621 - val_acc: 0.5514\n",
            "Epoch 89/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9608 - acc: 0.5417Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9017 - acc: 0.5566\n",
            "Epoch 00089: val_loss did not improve from 0.85940\n",
            "16/16 [==============================] - 6s 374ms/step - loss: 0.9539 - acc: 0.5464 - val_loss: 0.9385 - val_acc: 0.5589\n",
            "Epoch 90/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9406 - acc: 0.5586Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9645 - acc: 0.5371\n",
            "Epoch 00090: val_loss did not improve from 0.85940\n",
            "16/16 [==============================] - 6s 388ms/step - loss: 0.9392 - acc: 0.5623 - val_loss: 0.9937 - val_acc: 0.5402\n",
            "Epoch 91/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9473 - acc: 0.5557Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9134 - acc: 0.5430\n",
            "Epoch 00091: val_loss did not improve from 0.85940\n",
            "16/16 [==============================] - 6s 392ms/step - loss: 0.9501 - acc: 0.5513 - val_loss: 0.9642 - val_acc: 0.5458\n",
            "Epoch 92/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9597 - acc: 0.5438Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8958 - acc: 0.5801\n",
            "Epoch 00092: val_loss did not improve from 0.85940\n",
            "16/16 [==============================] - 6s 391ms/step - loss: 0.9640 - acc: 0.5460 - val_loss: 0.9522 - val_acc: 0.5832\n",
            "Epoch 93/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9327 - acc: 0.5568Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8797 - acc: 0.5996\n",
            "Epoch 00093: val_loss did not improve from 0.85940\n",
            "16/16 [==============================] - 6s 391ms/step - loss: 0.9348 - acc: 0.5518 - val_loss: 0.9753 - val_acc: 0.5925\n",
            "Epoch 94/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9321 - acc: 0.5507Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9384 - acc: 0.5215\n",
            "Epoch 00094: val_loss did not improve from 0.85940\n",
            "16/16 [==============================] - 6s 394ms/step - loss: 0.9311 - acc: 0.5514 - val_loss: 1.0245 - val_acc: 0.5121\n",
            "Epoch 95/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9496 - acc: 0.5560Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9881 - acc: 0.5215\n",
            "Epoch 00095: val_loss did not improve from 0.85940\n",
            "16/16 [==============================] - 6s 385ms/step - loss: 0.9519 - acc: 0.5546 - val_loss: 0.9724 - val_acc: 0.5196\n",
            "Epoch 96/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9279 - acc: 0.5708Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 1.0477 - acc: 0.5039\n",
            "Epoch 00096: val_loss did not improve from 0.85940\n",
            "16/16 [==============================] - 6s 388ms/step - loss: 0.9379 - acc: 0.5640 - val_loss: 1.0548 - val_acc: 0.5009\n",
            "Epoch 97/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9852 - acc: 0.5524Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9010 - acc: 0.5723\n",
            "Epoch 00097: val_loss did not improve from 0.85940\n",
            "16/16 [==============================] - 6s 373ms/step - loss: 0.9852 - acc: 0.5495 - val_loss: 0.9099 - val_acc: 0.5701\n",
            "Epoch 98/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9326 - acc: 0.5656Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8918 - acc: 0.6074\n",
            "Epoch 00098: val_loss did not improve from 0.85940\n",
            "16/16 [==============================] - 6s 385ms/step - loss: 0.9381 - acc: 0.5654 - val_loss: 0.8914 - val_acc: 0.6056\n",
            "Epoch 99/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9374 - acc: 0.5517Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9099 - acc: 0.5723\n",
            "Epoch 00099: val_loss did not improve from 0.85940\n",
            "16/16 [==============================] - 6s 383ms/step - loss: 0.9351 - acc: 0.5529 - val_loss: 0.9036 - val_acc: 0.5720\n",
            "Epoch 100/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9355 - acc: 0.5602Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9028 - acc: 0.5762\n",
            "Epoch 00100: val_loss did not improve from 0.85940\n",
            "16/16 [==============================] - 6s 377ms/step - loss: 0.9292 - acc: 0.5628 - val_loss: 0.8678 - val_acc: 0.5888\n",
            "Epoch 101/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9460 - acc: 0.5729Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8826 - acc: 0.5645\n",
            "Epoch 00101: val_loss improved from 0.85940 to 0.85790, saving model to model_3_4cl_best.h5\n",
            "16/16 [==============================] - 6s 380ms/step - loss: 0.9401 - acc: 0.5733 - val_loss: 0.8579 - val_acc: 0.5645\n",
            "Epoch 102/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9285 - acc: 0.5521Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8947 - acc: 0.5664\n",
            "Epoch 00102: val_loss did not improve from 0.85790\n",
            "16/16 [==============================] - 6s 371ms/step - loss: 0.9251 - acc: 0.5559 - val_loss: 0.8656 - val_acc: 0.5626\n",
            "Epoch 103/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9367 - acc: 0.5443Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.9048 - acc: 0.5645\n",
            "Epoch 00103: val_loss did not improve from 0.85790\n",
            "16/16 [==============================] - 5s 329ms/step - loss: 0.9341 - acc: 0.5435 - val_loss: 0.8800 - val_acc: 0.5645\n",
            "Epoch 104/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9371 - acc: 0.5512Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.9080 - acc: 0.5801\n",
            "Epoch 00104: val_loss did not improve from 0.85790\n",
            "16/16 [==============================] - 6s 354ms/step - loss: 0.9331 - acc: 0.5514 - val_loss: 0.8802 - val_acc: 0.5925\n",
            "Epoch 105/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9366 - acc: 0.5505Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.9105 - acc: 0.5684\n",
            "Epoch 00105: val_loss did not improve from 0.85790\n",
            "16/16 [==============================] - 6s 371ms/step - loss: 0.9344 - acc: 0.5576 - val_loss: 0.8839 - val_acc: 0.5701\n",
            "Epoch 106/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9274 - acc: 0.5708Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8889 - acc: 0.6074\n",
            "Epoch 00106: val_loss did not improve from 0.85790\n",
            "16/16 [==============================] - 6s 381ms/step - loss: 0.9363 - acc: 0.5668 - val_loss: 0.8733 - val_acc: 0.6093\n",
            "Epoch 107/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9368 - acc: 0.5703Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9027 - acc: 0.5625\n",
            "Epoch 00107: val_loss did not improve from 0.85790\n",
            "16/16 [==============================] - 6s 390ms/step - loss: 0.9355 - acc: 0.5728 - val_loss: 0.8610 - val_acc: 0.5645\n",
            "Epoch 108/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9297 - acc: 0.5676Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9282 - acc: 0.5469\n",
            "Epoch 00108: val_loss did not improve from 0.85790\n",
            "16/16 [==============================] - 6s 392ms/step - loss: 0.9229 - acc: 0.5718 - val_loss: 0.9025 - val_acc: 0.5514\n",
            "Epoch 109/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9337 - acc: 0.5401Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8828 - acc: 0.6016\n",
            "Epoch 00109: val_loss did not improve from 0.85790\n",
            "16/16 [==============================] - 6s 374ms/step - loss: 0.9360 - acc: 0.5410 - val_loss: 0.9370 - val_acc: 0.6019\n",
            "Epoch 110/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9161 - acc: 0.5660Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9004 - acc: 0.5664\n",
            "Epoch 00110: val_loss did not improve from 0.85790\n",
            "16/16 [==============================] - 6s 390ms/step - loss: 0.9220 - acc: 0.5638 - val_loss: 0.9929 - val_acc: 0.5645\n",
            "Epoch 111/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9051 - acc: 0.5638Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9429 - acc: 0.5840\n",
            "Epoch 00111: val_loss did not improve from 0.85790\n",
            "16/16 [==============================] - 6s 378ms/step - loss: 0.9134 - acc: 0.5612 - val_loss: 1.0256 - val_acc: 0.5832\n",
            "Epoch 112/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9458 - acc: 0.5625Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8576 - acc: 0.5938\n",
            "Epoch 00112: val_loss did not improve from 0.85790\n",
            "16/16 [==============================] - 6s 383ms/step - loss: 0.9447 - acc: 0.5620 - val_loss: 0.9103 - val_acc: 0.5944\n",
            "Epoch 113/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9432 - acc: 0.5654Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8916 - acc: 0.5840\n",
            "Epoch 00113: val_loss did not improve from 0.85790\n",
            "16/16 [==============================] - 6s 379ms/step - loss: 0.9402 - acc: 0.5677 - val_loss: 0.9467 - val_acc: 0.5869\n",
            "Epoch 114/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9064 - acc: 0.5634Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8785 - acc: 0.5684\n",
            "Epoch 00114: val_loss did not improve from 0.85790\n",
            "16/16 [==============================] - 6s 386ms/step - loss: 0.9044 - acc: 0.5648 - val_loss: 0.9400 - val_acc: 0.5701\n",
            "Epoch 115/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9021 - acc: 0.5734Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8778 - acc: 0.5996\n",
            "Epoch 00115: val_loss did not improve from 0.85790\n",
            "16/16 [==============================] - 6s 384ms/step - loss: 0.9105 - acc: 0.5718 - val_loss: 0.9103 - val_acc: 0.5925\n",
            "Epoch 116/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9455 - acc: 0.5634Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9177 - acc: 0.5938\n",
            "Epoch 00116: val_loss did not improve from 0.85790\n",
            "16/16 [==============================] - 6s 385ms/step - loss: 0.9452 - acc: 0.5579 - val_loss: 0.9316 - val_acc: 0.5907\n",
            "Epoch 117/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8823 - acc: 0.5867Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8846 - acc: 0.5938\n",
            "Epoch 00117: val_loss did not improve from 0.85790\n",
            "16/16 [==============================] - 6s 375ms/step - loss: 0.8868 - acc: 0.5872 - val_loss: 0.9100 - val_acc: 0.5888\n",
            "Epoch 118/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8999 - acc: 0.5836Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8673 - acc: 0.6113\n",
            "Epoch 00118: val_loss did not improve from 0.85790\n",
            "16/16 [==============================] - 6s 374ms/step - loss: 0.8940 - acc: 0.5882 - val_loss: 0.9205 - val_acc: 0.6019\n",
            "Epoch 119/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9233 - acc: 0.5692Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8828 - acc: 0.6309\n",
            "Epoch 00119: val_loss did not improve from 0.85790\n",
            "16/16 [==============================] - 6s 377ms/step - loss: 0.9311 - acc: 0.5648 - val_loss: 0.9077 - val_acc: 0.6224\n",
            "Epoch 120/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9103 - acc: 0.5618Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.8807 - acc: 0.5820\n",
            "Epoch 00120: val_loss did not improve from 0.85790\n",
            "16/16 [==============================] - 5s 334ms/step - loss: 0.9196 - acc: 0.5544 - val_loss: 0.8749 - val_acc: 0.5813\n",
            "Epoch 121/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9229 - acc: 0.5607Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8760 - acc: 0.5879\n",
            "Epoch 00121: val_loss did not improve from 0.85790\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 0.9194 - acc: 0.5628 - val_loss: 0.8861 - val_acc: 0.5850\n",
            "Epoch 122/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9201 - acc: 0.5547Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.9038 - acc: 0.5957\n",
            "Epoch 00122: val_loss did not improve from 0.85790\n",
            "16/16 [==============================] - 6s 378ms/step - loss: 0.9201 - acc: 0.5562 - val_loss: 0.9026 - val_acc: 0.5888\n",
            "Epoch 123/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9167 - acc: 0.5814Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.9390 - acc: 0.5410\n",
            "Epoch 00123: val_loss did not improve from 0.85790\n",
            "16/16 [==============================] - 6s 377ms/step - loss: 0.9167 - acc: 0.5782 - val_loss: 0.8817 - val_acc: 0.5458\n",
            "Epoch 124/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8998 - acc: 0.5784Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9102 - acc: 0.6094\n",
            "Epoch 00124: val_loss did not improve from 0.85790\n",
            "16/16 [==============================] - 6s 381ms/step - loss: 0.9024 - acc: 0.5758 - val_loss: 0.8760 - val_acc: 0.6093\n",
            "Epoch 125/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9019 - acc: 0.5781Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8861 - acc: 0.5918\n",
            "Epoch 00125: val_loss improved from 0.85790 to 0.85072, saving model to model_3_4cl_best.h5\n",
            "16/16 [==============================] - 6s 395ms/step - loss: 0.9036 - acc: 0.5752 - val_loss: 0.8507 - val_acc: 0.5925\n",
            "Epoch 126/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9134 - acc: 0.5795Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8790 - acc: 0.5977\n",
            "Epoch 00126: val_loss improved from 0.85072 to 0.84310, saving model to model_3_4cl_best.h5\n",
            "16/16 [==============================] - 6s 383ms/step - loss: 0.9117 - acc: 0.5794 - val_loss: 0.8431 - val_acc: 0.6019\n",
            "Epoch 127/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9197 - acc: 0.5735Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9018 - acc: 0.5508\n",
            "Epoch 00127: val_loss did not improve from 0.84310\n",
            "16/16 [==============================] - 6s 383ms/step - loss: 0.9216 - acc: 0.5708 - val_loss: 0.8535 - val_acc: 0.5551\n",
            "Epoch 128/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9142 - acc: 0.5693Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8553 - acc: 0.5898\n",
            "Epoch 00128: val_loss did not improve from 0.84310\n",
            "16/16 [==============================] - 6s 390ms/step - loss: 0.9077 - acc: 0.5742 - val_loss: 0.8635 - val_acc: 0.5888\n",
            "Epoch 129/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9048 - acc: 0.5883Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8570 - acc: 0.5820\n",
            "Epoch 00129: val_loss did not improve from 0.84310\n",
            "16/16 [==============================] - 6s 382ms/step - loss: 0.9031 - acc: 0.5887 - val_loss: 0.8794 - val_acc: 0.5813\n",
            "Epoch 130/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8938 - acc: 0.5740Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8628 - acc: 0.6152\n",
            "Epoch 00130: val_loss did not improve from 0.84310\n",
            "16/16 [==============================] - 6s 377ms/step - loss: 0.9010 - acc: 0.5738 - val_loss: 0.8992 - val_acc: 0.6075\n",
            "Epoch 131/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9178 - acc: 0.5719Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9010 - acc: 0.5859\n",
            "Epoch 00131: val_loss did not improve from 0.84310\n",
            "16/16 [==============================] - 6s 384ms/step - loss: 0.9157 - acc: 0.5753 - val_loss: 0.9092 - val_acc: 0.5869\n",
            "Epoch 132/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9020 - acc: 0.5795Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8750 - acc: 0.5820\n",
            "Epoch 00132: val_loss did not improve from 0.84310\n",
            "16/16 [==============================] - 6s 372ms/step - loss: 0.9067 - acc: 0.5733 - val_loss: 0.8962 - val_acc: 0.5850\n",
            "Epoch 133/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9005 - acc: 0.5745Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8997 - acc: 0.5645\n",
            "Epoch 00133: val_loss did not improve from 0.84310\n",
            "16/16 [==============================] - 6s 381ms/step - loss: 0.8969 - acc: 0.5771 - val_loss: 0.9051 - val_acc: 0.5645\n",
            "Epoch 134/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9185 - acc: 0.5666Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8779 - acc: 0.5898\n",
            "Epoch 00134: val_loss did not improve from 0.84310\n",
            "16/16 [==============================] - 6s 373ms/step - loss: 0.9206 - acc: 0.5642 - val_loss: 0.9237 - val_acc: 0.5869\n",
            "Epoch 135/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8950 - acc: 0.5823Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8758 - acc: 0.5664\n",
            "Epoch 00135: val_loss did not improve from 0.84310\n",
            "16/16 [==============================] - 6s 381ms/step - loss: 0.8955 - acc: 0.5811 - val_loss: 0.8756 - val_acc: 0.5682\n",
            "Epoch 136/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9066 - acc: 0.5777Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8680 - acc: 0.5723\n",
            "Epoch 00136: val_loss did not improve from 0.84310\n",
            "16/16 [==============================] - 6s 378ms/step - loss: 0.9061 - acc: 0.5743 - val_loss: 0.8558 - val_acc: 0.5738\n",
            "Epoch 137/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9058 - acc: 0.5724Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.8757 - acc: 0.5840\n",
            "Epoch 00137: val_loss did not improve from 0.84310\n",
            "16/16 [==============================] - 5s 334ms/step - loss: 0.9057 - acc: 0.5718 - val_loss: 0.8714 - val_acc: 0.5850\n",
            "Epoch 138/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9091 - acc: 0.5777Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8433 - acc: 0.6094\n",
            "Epoch 00138: val_loss did not improve from 0.84310\n",
            "16/16 [==============================] - 6s 361ms/step - loss: 0.9090 - acc: 0.5753 - val_loss: 0.8924 - val_acc: 0.6056\n",
            "Epoch 139/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8944 - acc: 0.5772Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8494 - acc: 0.5898\n",
            "Epoch 00139: val_loss did not improve from 0.84310\n",
            "16/16 [==============================] - 6s 370ms/step - loss: 0.8890 - acc: 0.5807 - val_loss: 0.9201 - val_acc: 0.5813\n",
            "Epoch 140/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8907 - acc: 0.5804Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9053 - acc: 0.5527\n",
            "Epoch 00140: val_loss did not improve from 0.84310\n",
            "16/16 [==============================] - 6s 385ms/step - loss: 0.8971 - acc: 0.5782 - val_loss: 0.9974 - val_acc: 0.5421\n",
            "Epoch 141/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9024 - acc: 0.5862Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8957 - acc: 0.5938\n",
            "Epoch 00141: val_loss did not improve from 0.84310\n",
            "16/16 [==============================] - 6s 396ms/step - loss: 0.9026 - acc: 0.5842 - val_loss: 0.8673 - val_acc: 0.5981\n",
            "Epoch 142/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8846 - acc: 0.5846Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8685 - acc: 0.5957\n",
            "Epoch 00142: val_loss improved from 0.84310 to 0.82958, saving model to model_3_4cl_best.h5\n",
            "16/16 [==============================] - 6s 390ms/step - loss: 0.8796 - acc: 0.5862 - val_loss: 0.8296 - val_acc: 0.6000\n",
            "Epoch 143/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9307 - acc: 0.5687Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9018 - acc: 0.5820\n",
            "Epoch 00143: val_loss did not improve from 0.82958\n",
            "16/16 [==============================] - 6s 387ms/step - loss: 0.9213 - acc: 0.5698 - val_loss: 0.8613 - val_acc: 0.5888\n",
            "Epoch 144/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8690 - acc: 0.5979Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8770 - acc: 0.5859\n",
            "Epoch 00144: val_loss did not improve from 0.82958\n",
            "16/16 [==============================] - 6s 388ms/step - loss: 0.8719 - acc: 0.5951 - val_loss: 0.8631 - val_acc: 0.5869\n",
            "Epoch 145/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8799 - acc: 0.5836Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8988 - acc: 0.5820\n",
            "Epoch 00145: val_loss did not improve from 0.82958\n",
            "16/16 [==============================] - 6s 382ms/step - loss: 0.8798 - acc: 0.5812 - val_loss: 0.8743 - val_acc: 0.5850\n",
            "Epoch 146/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9044 - acc: 0.5635Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8808 - acc: 0.5840\n",
            "Epoch 00146: val_loss did not improve from 0.82958\n",
            "16/16 [==============================] - 6s 390ms/step - loss: 0.9015 - acc: 0.5635 - val_loss: 0.8441 - val_acc: 0.5888\n",
            "Epoch 147/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8763 - acc: 0.5804Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8890 - acc: 0.5723\n",
            "Epoch 00147: val_loss did not improve from 0.82958\n",
            "16/16 [==============================] - 6s 380ms/step - loss: 0.8780 - acc: 0.5753 - val_loss: 0.8450 - val_acc: 0.5757\n",
            "Epoch 148/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8783 - acc: 0.5931Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8788 - acc: 0.5977\n",
            "Epoch 00148: val_loss did not improve from 0.82958\n",
            "16/16 [==============================] - 6s 376ms/step - loss: 0.8843 - acc: 0.5897 - val_loss: 0.8459 - val_acc: 0.6019\n",
            "Epoch 149/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8576 - acc: 0.5952Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9211 - acc: 0.5469\n",
            "Epoch 00149: val_loss did not improve from 0.82958\n",
            "16/16 [==============================] - 6s 381ms/step - loss: 0.8617 - acc: 0.5922 - val_loss: 0.8724 - val_acc: 0.5551\n",
            "Epoch 150/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9206 - acc: 0.5660Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9317 - acc: 0.5586\n",
            "Epoch 00150: val_loss did not improve from 0.82958\n",
            "16/16 [==============================] - 6s 380ms/step - loss: 0.9134 - acc: 0.5658 - val_loss: 0.8781 - val_acc: 0.5664\n",
            "Epoch 151/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8993 - acc: 0.5767Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8480 - acc: 0.6191\n",
            "Epoch 00151: val_loss improved from 0.82958 to 0.81505, saving model to model_3_4cl_best.h5\n",
            "16/16 [==============================] - 6s 379ms/step - loss: 0.8941 - acc: 0.5777 - val_loss: 0.8151 - val_acc: 0.6206\n",
            "Epoch 152/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9062 - acc: 0.5767Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8926 - acc: 0.5938\n",
            "Epoch 00152: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 376ms/step - loss: 0.9038 - acc: 0.5792 - val_loss: 0.8665 - val_acc: 0.6000\n",
            "Epoch 153/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8690 - acc: 0.5830Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8863 - acc: 0.5977\n",
            "Epoch 00153: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 372ms/step - loss: 0.8695 - acc: 0.5812 - val_loss: 0.8563 - val_acc: 0.6019\n",
            "Epoch 154/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8883 - acc: 0.5875Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.8919 - acc: 0.5430\n",
            "Epoch 00154: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 5s 339ms/step - loss: 0.8887 - acc: 0.5854 - val_loss: 0.8480 - val_acc: 0.5514\n",
            "Epoch 155/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8802 - acc: 0.5697Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8489 - acc: 0.5801\n",
            "Epoch 00155: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 0.8804 - acc: 0.5718 - val_loss: 0.8845 - val_acc: 0.5794\n",
            "Epoch 156/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8808 - acc: 0.5859Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.9202 - acc: 0.5547\n",
            "Epoch 00156: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 368ms/step - loss: 0.8862 - acc: 0.5869 - val_loss: 0.9560 - val_acc: 0.5551\n",
            "Epoch 157/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8972 - acc: 0.5687Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8352 - acc: 0.6094\n",
            "Epoch 00157: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 386ms/step - loss: 0.8908 - acc: 0.5708 - val_loss: 0.8693 - val_acc: 0.6056\n",
            "Epoch 158/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8780 - acc: 0.5692Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8518 - acc: 0.6113\n",
            "Epoch 00158: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 385ms/step - loss: 0.8787 - acc: 0.5708 - val_loss: 0.8793 - val_acc: 0.6131\n",
            "Epoch 159/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8538 - acc: 0.5908Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8628 - acc: 0.6211\n",
            "Epoch 00159: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 382ms/step - loss: 0.8656 - acc: 0.5880 - val_loss: 0.9060 - val_acc: 0.6206\n",
            "Epoch 160/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8931 - acc: 0.5883Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9506 - acc: 0.5430\n",
            "Epoch 00160: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 385ms/step - loss: 0.8965 - acc: 0.5852 - val_loss: 0.9669 - val_acc: 0.5421\n",
            "Epoch 161/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8594 - acc: 0.5867Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9200 - acc: 0.5527\n",
            "Epoch 00161: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 386ms/step - loss: 0.8621 - acc: 0.5832 - val_loss: 0.9271 - val_acc: 0.5495\n",
            "Epoch 162/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.9116 - acc: 0.5495Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8433 - acc: 0.6016\n",
            "Epoch 00162: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 384ms/step - loss: 0.9069 - acc: 0.5552 - val_loss: 0.8473 - val_acc: 0.6000\n",
            "Epoch 163/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8853 - acc: 0.5805Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8678 - acc: 0.5859\n",
            "Epoch 00163: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 378ms/step - loss: 0.8826 - acc: 0.5809 - val_loss: 0.8787 - val_acc: 0.5776\n",
            "Epoch 164/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8584 - acc: 0.5807Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8672 - acc: 0.5996\n",
            "Epoch 00164: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 388ms/step - loss: 0.8661 - acc: 0.5786 - val_loss: 0.8667 - val_acc: 0.5963\n",
            "Epoch 165/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8754 - acc: 0.5862Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8836 - acc: 0.5703\n",
            "Epoch 00165: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 387ms/step - loss: 0.8689 - acc: 0.5842 - val_loss: 0.8944 - val_acc: 0.5682\n",
            "Epoch 166/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8945 - acc: 0.5788Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8798 - acc: 0.6035\n",
            "Epoch 00166: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 382ms/step - loss: 0.8882 - acc: 0.5807 - val_loss: 0.8890 - val_acc: 0.6056\n",
            "Epoch 167/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8877 - acc: 0.5804Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8885 - acc: 0.6074\n",
            "Epoch 00167: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 383ms/step - loss: 0.8903 - acc: 0.5792 - val_loss: 0.8811 - val_acc: 0.6037\n",
            "Epoch 168/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8932 - acc: 0.5873Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9200 - acc: 0.5801\n",
            "Epoch 00168: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 376ms/step - loss: 0.8923 - acc: 0.5917 - val_loss: 0.9161 - val_acc: 0.5794\n",
            "Epoch 169/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8730 - acc: 0.5767Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9033 - acc: 0.5762\n",
            "Epoch 00169: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 378ms/step - loss: 0.8658 - acc: 0.5842 - val_loss: 0.8715 - val_acc: 0.5776\n",
            "Epoch 170/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8880 - acc: 0.5782Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8718 - acc: 0.6133\n",
            "Epoch 00170: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 372ms/step - loss: 0.8868 - acc: 0.5797 - val_loss: 0.8496 - val_acc: 0.6168\n",
            "Epoch 171/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8769 - acc: 0.5931Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.8587 - acc: 0.5859\n",
            "Epoch 00171: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 5s 334ms/step - loss: 0.8690 - acc: 0.5931 - val_loss: 0.8332 - val_acc: 0.5888\n",
            "Epoch 172/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8549 - acc: 0.5984Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8732 - acc: 0.5801\n",
            "Epoch 00172: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 374ms/step - loss: 0.8622 - acc: 0.6001 - val_loss: 0.8195 - val_acc: 0.5869\n",
            "Epoch 173/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8830 - acc: 0.5830Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8961 - acc: 0.5645\n",
            "Epoch 00173: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 370ms/step - loss: 0.8866 - acc: 0.5827 - val_loss: 0.9821 - val_acc: 0.5645\n",
            "Epoch 174/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8891 - acc: 0.5740Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8560 - acc: 0.5742\n",
            "Epoch 00174: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 384ms/step - loss: 0.8850 - acc: 0.5762 - val_loss: 0.9294 - val_acc: 0.5757\n",
            "Epoch 175/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8669 - acc: 0.5935Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8419 - acc: 0.5879\n",
            "Epoch 00175: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 384ms/step - loss: 0.8634 - acc: 0.5945 - val_loss: 1.0036 - val_acc: 0.5888\n",
            "Epoch 176/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8460 - acc: 0.5880Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8501 - acc: 0.6152\n",
            "Epoch 00176: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 396ms/step - loss: 0.8450 - acc: 0.5898 - val_loss: 0.9693 - val_acc: 0.6131\n",
            "Epoch 177/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8939 - acc: 0.5843Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8463 - acc: 0.5684\n",
            "Epoch 00177: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 381ms/step - loss: 0.8867 - acc: 0.5885 - val_loss: 0.9701 - val_acc: 0.5720\n",
            "Epoch 178/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8844 - acc: 0.5766Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8395 - acc: 0.5840\n",
            "Epoch 00178: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 404ms/step - loss: 0.8843 - acc: 0.5752 - val_loss: 0.9617 - val_acc: 0.5850\n",
            "Epoch 179/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8596 - acc: 0.5878Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8578 - acc: 0.5938\n",
            "Epoch 00179: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 384ms/step - loss: 0.8571 - acc: 0.5867 - val_loss: 0.8857 - val_acc: 0.5888\n",
            "Epoch 180/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8749 - acc: 0.5846Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8854 - acc: 0.5781\n",
            "Epoch 00180: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 385ms/step - loss: 0.8740 - acc: 0.5872 - val_loss: 0.8969 - val_acc: 0.5738\n",
            "Epoch 181/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8647 - acc: 0.5854Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8471 - acc: 0.6230\n",
            "Epoch 00181: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 382ms/step - loss: 0.8613 - acc: 0.5910 - val_loss: 0.8811 - val_acc: 0.6187\n",
            "Epoch 182/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8867 - acc: 0.5995Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8737 - acc: 0.6035\n",
            "Epoch 00182: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 380ms/step - loss: 0.8851 - acc: 0.5996 - val_loss: 0.8785 - val_acc: 0.6037\n",
            "Epoch 183/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8774 - acc: 0.5894Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8683 - acc: 0.6074\n",
            "Epoch 00183: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 382ms/step - loss: 0.8716 - acc: 0.5926 - val_loss: 0.8742 - val_acc: 0.6000\n",
            "Epoch 184/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8665 - acc: 0.5896Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8746 - acc: 0.6191\n",
            "Epoch 00184: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 379ms/step - loss: 0.8718 - acc: 0.5857 - val_loss: 0.8924 - val_acc: 0.6150\n",
            "Epoch 185/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8754 - acc: 0.5964Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9214 - acc: 0.5723\n",
            "Epoch 00185: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 387ms/step - loss: 0.8701 - acc: 0.5977 - val_loss: 0.9250 - val_acc: 0.5720\n",
            "Epoch 186/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8954 - acc: 0.5767Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8900 - acc: 0.5938\n",
            "Epoch 00186: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 380ms/step - loss: 0.9028 - acc: 0.5753 - val_loss: 0.8504 - val_acc: 0.6037\n",
            "Epoch 187/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8757 - acc: 0.5905Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9393 - acc: 0.5488\n",
            "Epoch 00187: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 380ms/step - loss: 0.8726 - acc: 0.5902 - val_loss: 0.8656 - val_acc: 0.5589\n",
            "Epoch 188/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8816 - acc: 0.6062Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.8646 - acc: 0.5879\n",
            "Epoch 00188: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 5s 338ms/step - loss: 0.8808 - acc: 0.6045 - val_loss: 0.8196 - val_acc: 0.5981\n",
            "Epoch 189/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8650 - acc: 0.6027Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.9327 - acc: 0.5781\n",
            "Epoch 00189: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 0.8613 - acc: 0.6021 - val_loss: 0.8820 - val_acc: 0.5888\n",
            "Epoch 190/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8716 - acc: 0.5984Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8744 - acc: 0.5742\n",
            "Epoch 00190: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 371ms/step - loss: 0.8679 - acc: 0.5986 - val_loss: 0.8175 - val_acc: 0.5850\n",
            "Epoch 191/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8598 - acc: 0.5936Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9307 - acc: 0.5879\n",
            "Epoch 00191: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 392ms/step - loss: 0.8580 - acc: 0.5966 - val_loss: 0.8780 - val_acc: 0.5981\n",
            "Epoch 192/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8551 - acc: 0.5942Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8654 - acc: 0.6074\n",
            "Epoch 00192: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 387ms/step - loss: 0.8599 - acc: 0.5986 - val_loss: 0.9044 - val_acc: 0.6093\n",
            "Epoch 193/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8679 - acc: 0.6016Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8505 - acc: 0.5938\n",
            "Epoch 00193: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 388ms/step - loss: 0.8636 - acc: 0.6041 - val_loss: 0.8988 - val_acc: 0.5888\n",
            "Epoch 194/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8828 - acc: 0.5814Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8640 - acc: 0.5996\n",
            "Epoch 00194: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 388ms/step - loss: 0.8834 - acc: 0.5812 - val_loss: 0.8420 - val_acc: 0.6037\n",
            "Epoch 195/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8502 - acc: 0.5926Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8802 - acc: 0.5840\n",
            "Epoch 00195: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 387ms/step - loss: 0.8433 - acc: 0.5931 - val_loss: 0.9348 - val_acc: 0.5869\n",
            "Epoch 196/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8778 - acc: 0.5984Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8599 - acc: 0.5703\n",
            "Epoch 00196: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 387ms/step - loss: 0.8698 - acc: 0.6011 - val_loss: 0.8957 - val_acc: 0.5738\n",
            "Epoch 197/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8855 - acc: 0.5820Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8860 - acc: 0.5859\n",
            "Epoch 00197: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 383ms/step - loss: 0.8859 - acc: 0.5842 - val_loss: 0.8801 - val_acc: 0.5869\n",
            "Epoch 198/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8286 - acc: 0.6125Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8410 - acc: 0.6152\n",
            "Epoch 00198: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 384ms/step - loss: 0.8276 - acc: 0.6138 - val_loss: 0.9174 - val_acc: 0.6093\n",
            "Epoch 199/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8615 - acc: 0.6146Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8732 - acc: 0.5996\n",
            "Epoch 00199: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 375ms/step - loss: 0.8570 - acc: 0.6127 - val_loss: 0.9250 - val_acc: 0.5981\n",
            "Epoch 200/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8481 - acc: 0.6052Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8595 - acc: 0.5898\n",
            "Epoch 00200: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 378ms/step - loss: 0.8417 - acc: 0.6090 - val_loss: 0.9386 - val_acc: 0.5850\n",
            "Epoch 201/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8759 - acc: 0.5942Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8758 - acc: 0.6250\n",
            "Epoch 00201: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 379ms/step - loss: 0.8685 - acc: 0.5966 - val_loss: 0.9314 - val_acc: 0.6206\n",
            "Epoch 202/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8510 - acc: 0.6047Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8337 - acc: 0.6074\n",
            "Epoch 00202: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 382ms/step - loss: 0.8593 - acc: 0.6016 - val_loss: 0.8888 - val_acc: 0.6019\n",
            "Epoch 203/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8702 - acc: 0.5931Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8527 - acc: 0.5879\n",
            "Epoch 00203: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 386ms/step - loss: 0.8735 - acc: 0.5887 - val_loss: 0.9887 - val_acc: 0.5907\n",
            "Epoch 204/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8487 - acc: 0.6027Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8570 - acc: 0.6074\n",
            "Epoch 00204: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 6s 379ms/step - loss: 0.8446 - acc: 0.6036 - val_loss: 0.8323 - val_acc: 0.6075\n",
            "Epoch 205/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8709 - acc: 0.6069Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.9109 - acc: 0.5605\n",
            "Epoch 00205: val_loss did not improve from 0.81505\n",
            "16/16 [==============================] - 5s 334ms/step - loss: 0.8745 - acc: 0.6056 - val_loss: 0.8711 - val_acc: 0.5626\n",
            "Epoch 206/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8298 - acc: 0.6048Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8529 - acc: 0.5938\n",
            "Epoch 00206: val_loss improved from 0.81505 to 0.80705, saving model to model_3_4cl_best.h5\n",
            "16/16 [==============================] - 6s 365ms/step - loss: 0.8300 - acc: 0.6061 - val_loss: 0.8071 - val_acc: 0.5981\n",
            "Epoch 207/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8709 - acc: 0.5995Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8971 - acc: 0.5820\n",
            "Epoch 00207: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 371ms/step - loss: 0.8697 - acc: 0.6016 - val_loss: 0.8448 - val_acc: 0.5869\n",
            "Epoch 208/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8615 - acc: 0.5964Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8810 - acc: 0.5781\n",
            "Epoch 00208: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 385ms/step - loss: 0.8570 - acc: 0.5977 - val_loss: 0.8246 - val_acc: 0.5832\n",
            "Epoch 209/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8537 - acc: 0.6022Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8654 - acc: 0.6133\n",
            "Epoch 00209: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 383ms/step - loss: 0.8549 - acc: 0.6026 - val_loss: 0.8328 - val_acc: 0.6187\n",
            "Epoch 210/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8429 - acc: 0.6057Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9516 - acc: 0.5469\n",
            "Epoch 00210: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 402ms/step - loss: 0.8425 - acc: 0.6060 - val_loss: 0.8987 - val_acc: 0.5514\n",
            "Epoch 211/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8553 - acc: 0.6058Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8829 - acc: 0.6094\n",
            "Epoch 00211: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 384ms/step - loss: 0.8536 - acc: 0.6046 - val_loss: 0.8329 - val_acc: 0.6168\n",
            "Epoch 212/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8659 - acc: 0.5878Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8683 - acc: 0.5938\n",
            "Epoch 00212: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 383ms/step - loss: 0.8624 - acc: 0.5931 - val_loss: 0.8239 - val_acc: 0.6000\n",
            "Epoch 213/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8361 - acc: 0.6048Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8603 - acc: 0.5879\n",
            "Epoch 00213: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 389ms/step - loss: 0.8347 - acc: 0.6071 - val_loss: 0.8133 - val_acc: 0.5925\n",
            "Epoch 214/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8251 - acc: 0.6159Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9494 - acc: 0.5840\n",
            "Epoch 00214: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 375ms/step - loss: 0.8274 - acc: 0.6155 - val_loss: 0.8940 - val_acc: 0.5888\n",
            "Epoch 215/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8609 - acc: 0.6011Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8842 - acc: 0.5918\n",
            "Epoch 00215: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 384ms/step - loss: 0.8602 - acc: 0.6036 - val_loss: 0.8364 - val_acc: 0.5944\n",
            "Epoch 216/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8777 - acc: 0.5948Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8450 - acc: 0.6016\n",
            "Epoch 00216: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 383ms/step - loss: 0.8734 - acc: 0.5952 - val_loss: 0.8850 - val_acc: 0.5981\n",
            "Epoch 217/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8287 - acc: 0.6032Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8945 - acc: 0.5742\n",
            "Epoch 00217: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 379ms/step - loss: 0.8284 - acc: 0.6066 - val_loss: 0.9658 - val_acc: 0.5682\n",
            "Epoch 218/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8189 - acc: 0.6133Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8671 - acc: 0.6270\n",
            "Epoch 00218: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 377ms/step - loss: 0.8151 - acc: 0.6135 - val_loss: 0.9058 - val_acc: 0.6318\n",
            "Epoch 219/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8599 - acc: 0.5931Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8731 - acc: 0.5820\n",
            "Epoch 00219: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 371ms/step - loss: 0.8587 - acc: 0.5961 - val_loss: 0.9015 - val_acc: 0.5776\n",
            "Epoch 220/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8336 - acc: 0.6090Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8401 - acc: 0.6133\n",
            "Epoch 00220: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 375ms/step - loss: 0.8310 - acc: 0.6100 - val_loss: 0.8876 - val_acc: 0.6131\n",
            "Epoch 221/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8715 - acc: 0.5915Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8489 - acc: 0.6191\n",
            "Epoch 00221: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 367ms/step - loss: 0.8639 - acc: 0.5966 - val_loss: 0.8778 - val_acc: 0.6206\n",
            "Epoch 222/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8403 - acc: 0.6085Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.9067 - acc: 0.6035\n",
            "Epoch 00222: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 5s 334ms/step - loss: 0.8377 - acc: 0.6105 - val_loss: 0.9287 - val_acc: 0.6037\n",
            "Epoch 223/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8514 - acc: 0.5896Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8254 - acc: 0.5938\n",
            "Epoch 00223: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 369ms/step - loss: 0.8503 - acc: 0.5884 - val_loss: 0.8796 - val_acc: 0.5925\n",
            "Epoch 224/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8391 - acc: 0.6180Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.9025 - acc: 0.6133\n",
            "Epoch 00224: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 366ms/step - loss: 0.8420 - acc: 0.6168 - val_loss: 0.8979 - val_acc: 0.6093\n",
            "Epoch 225/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8464 - acc: 0.6106Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8697 - acc: 0.5762\n",
            "Epoch 00225: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 379ms/step - loss: 0.8423 - acc: 0.6110 - val_loss: 0.8984 - val_acc: 0.5738\n",
            "Epoch 226/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8474 - acc: 0.6027Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8379 - acc: 0.6289\n",
            "Epoch 00226: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 389ms/step - loss: 0.8455 - acc: 0.6011 - val_loss: 0.8607 - val_acc: 0.6243\n",
            "Epoch 227/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8183 - acc: 0.6094Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8659 - acc: 0.6074\n",
            "Epoch 00227: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 396ms/step - loss: 0.8193 - acc: 0.6104 - val_loss: 0.8942 - val_acc: 0.6019\n",
            "Epoch 228/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8357 - acc: 0.6048Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8810 - acc: 0.6172\n",
            "Epoch 00228: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 386ms/step - loss: 0.8361 - acc: 0.6061 - val_loss: 0.9008 - val_acc: 0.6131\n",
            "Epoch 229/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8445 - acc: 0.5782Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8639 - acc: 0.6426\n",
            "Epoch 00229: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 376ms/step - loss: 0.8396 - acc: 0.5809 - val_loss: 0.8800 - val_acc: 0.6374\n",
            "Epoch 230/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8379 - acc: 0.6167Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8776 - acc: 0.6113\n",
            "Epoch 00230: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 391ms/step - loss: 0.8326 - acc: 0.6196 - val_loss: 0.9247 - val_acc: 0.6000\n",
            "Epoch 231/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8386 - acc: 0.6059Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8216 - acc: 0.6113\n",
            "Epoch 00231: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 379ms/step - loss: 0.8444 - acc: 0.6021 - val_loss: 1.0787 - val_acc: 0.5981\n",
            "Epoch 232/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8300 - acc: 0.5968Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8071 - acc: 0.6328\n",
            "Epoch 00232: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 379ms/step - loss: 0.8322 - acc: 0.5976 - val_loss: 0.9235 - val_acc: 0.6224\n",
            "Epoch 233/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8518 - acc: 0.5964Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8513 - acc: 0.6016\n",
            "Epoch 00233: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 382ms/step - loss: 0.8488 - acc: 0.5981 - val_loss: 1.0504 - val_acc: 0.5888\n",
            "Epoch 234/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8162 - acc: 0.6095Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8242 - acc: 0.6172\n",
            "Epoch 00234: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 380ms/step - loss: 0.8196 - acc: 0.6061 - val_loss: 0.9963 - val_acc: 0.6075\n",
            "Epoch 235/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8400 - acc: 0.6180Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8109 - acc: 0.6309\n",
            "Epoch 00235: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 375ms/step - loss: 0.8430 - acc: 0.6135 - val_loss: 0.9947 - val_acc: 0.6168\n",
            "Epoch 236/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8518 - acc: 0.5984Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8268 - acc: 0.5898\n",
            "Epoch 00236: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 378ms/step - loss: 0.8515 - acc: 0.6011 - val_loss: 1.0273 - val_acc: 0.5776\n",
            "Epoch 237/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8166 - acc: 0.6255Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.7971 - acc: 0.6211\n",
            "Epoch 00237: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 378ms/step - loss: 0.8133 - acc: 0.6274 - val_loss: 0.9689 - val_acc: 0.6093\n",
            "Epoch 238/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8216 - acc: 0.6120Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.7976 - acc: 0.6250\n",
            "Epoch 00238: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 372ms/step - loss: 0.8212 - acc: 0.6145 - val_loss: 1.0380 - val_acc: 0.6131\n",
            "Epoch 239/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8198 - acc: 0.6016Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.8908 - acc: 0.5781\n",
            "Epoch 00239: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 5s 329ms/step - loss: 0.8244 - acc: 0.6021 - val_loss: 1.1398 - val_acc: 0.5776\n",
            "Epoch 240/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8405 - acc: 0.6069Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8481 - acc: 0.5840\n",
            "Epoch 00240: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 369ms/step - loss: 0.8359 - acc: 0.6080 - val_loss: 1.0408 - val_acc: 0.5850\n",
            "Epoch 241/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8460 - acc: 0.5989Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8633 - acc: 0.5820\n",
            "Epoch 00241: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 374ms/step - loss: 0.8390 - acc: 0.6066 - val_loss: 1.0945 - val_acc: 0.5813\n",
            "Epoch 242/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8381 - acc: 0.6170Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8479 - acc: 0.6035\n",
            "Epoch 00242: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 379ms/step - loss: 0.8363 - acc: 0.6190 - val_loss: 0.8570 - val_acc: 0.6075\n",
            "Epoch 243/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8618 - acc: 0.5880Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8708 - acc: 0.6211\n",
            "Epoch 00243: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 391ms/step - loss: 0.8574 - acc: 0.5879 - val_loss: 0.8462 - val_acc: 0.6206\n",
            "Epoch 244/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8025 - acc: 0.6232Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9030 - acc: 0.5879\n",
            "Epoch 00244: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 385ms/step - loss: 0.8039 - acc: 0.6218 - val_loss: 0.8864 - val_acc: 0.5888\n",
            "Epoch 245/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8353 - acc: 0.6062Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9061 - acc: 0.6055\n",
            "Epoch 00245: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 391ms/step - loss: 0.8257 - acc: 0.6074 - val_loss: 0.8596 - val_acc: 0.6037\n",
            "Epoch 246/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8058 - acc: 0.6138Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8793 - acc: 0.6250\n",
            "Epoch 00246: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 385ms/step - loss: 0.8047 - acc: 0.6135 - val_loss: 0.8576 - val_acc: 0.6299\n",
            "Epoch 247/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8280 - acc: 0.6200Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8900 - acc: 0.6152\n",
            "Epoch 00247: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 374ms/step - loss: 0.8260 - acc: 0.6208 - val_loss: 0.8729 - val_acc: 0.6168\n",
            "Epoch 248/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8459 - acc: 0.6036Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9078 - acc: 0.6191\n",
            "Epoch 00248: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 390ms/step - loss: 0.8417 - acc: 0.6055 - val_loss: 0.8826 - val_acc: 0.6168\n",
            "Epoch 249/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8089 - acc: 0.6281Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9579 - acc: 0.6094\n",
            "Epoch 00249: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 385ms/step - loss: 0.8120 - acc: 0.6249 - val_loss: 0.9450 - val_acc: 0.6131\n",
            "Epoch 250/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8350 - acc: 0.6042Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8534 - acc: 0.6328\n",
            "Epoch 00250: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 380ms/step - loss: 0.8387 - acc: 0.6035 - val_loss: 0.8434 - val_acc: 0.6374\n",
            "Epoch 251/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8154 - acc: 0.6127Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8603 - acc: 0.6191\n",
            "Epoch 00251: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 376ms/step - loss: 0.8165 - acc: 0.6145 - val_loss: 0.8599 - val_acc: 0.6187\n",
            "Epoch 252/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8341 - acc: 0.6106Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8558 - acc: 0.5840\n",
            "Epoch 00252: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 380ms/step - loss: 0.8308 - acc: 0.6090 - val_loss: 0.8597 - val_acc: 0.5813\n",
            "Epoch 253/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8265 - acc: 0.6202Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8782 - acc: 0.6016\n",
            "Epoch 00253: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 376ms/step - loss: 0.8200 - acc: 0.6220 - val_loss: 0.8717 - val_acc: 0.6019\n",
            "Epoch 254/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8433 - acc: 0.6143Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8865 - acc: 0.6055\n",
            "Epoch 00254: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 375ms/step - loss: 0.8415 - acc: 0.6170 - val_loss: 0.8805 - val_acc: 0.6075\n",
            "Epoch 255/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8342 - acc: 0.6069Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8739 - acc: 0.6230\n",
            "Epoch 00255: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 380ms/step - loss: 0.8415 - acc: 0.6021 - val_loss: 0.8783 - val_acc: 0.6206\n",
            "Epoch 256/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8060 - acc: 0.6074Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.8536 - acc: 0.6113\n",
            "Epoch 00256: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 5s 336ms/step - loss: 0.8032 - acc: 0.6105 - val_loss: 0.8456 - val_acc: 0.6131\n",
            "Epoch 257/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8223 - acc: 0.6135Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8836 - acc: 0.6035\n",
            "Epoch 00257: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 372ms/step - loss: 0.8276 - acc: 0.6118 - val_loss: 0.8771 - val_acc: 0.6019\n",
            "Epoch 258/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8230 - acc: 0.6074Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8476 - acc: 0.6152\n",
            "Epoch 00258: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 370ms/step - loss: 0.8360 - acc: 0.6061 - val_loss: 0.8526 - val_acc: 0.6112\n",
            "Epoch 259/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8449 - acc: 0.5968Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8517 - acc: 0.6055\n",
            "Epoch 00259: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 377ms/step - loss: 0.8439 - acc: 0.5971 - val_loss: 0.8550 - val_acc: 0.6075\n",
            "Epoch 260/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8340 - acc: 0.5905Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8515 - acc: 0.6270\n",
            "Epoch 00260: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 389ms/step - loss: 0.8317 - acc: 0.5922 - val_loss: 0.8602 - val_acc: 0.6280\n",
            "Epoch 261/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8155 - acc: 0.6233Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8558 - acc: 0.6133\n",
            "Epoch 00261: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 391ms/step - loss: 0.8199 - acc: 0.6200 - val_loss: 0.8542 - val_acc: 0.6112\n",
            "Epoch 262/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8167 - acc: 0.6111Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9348 - acc: 0.5957\n",
            "Epoch 00262: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 383ms/step - loss: 0.8308 - acc: 0.6100 - val_loss: 0.9389 - val_acc: 0.5944\n",
            "Epoch 263/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8160 - acc: 0.6182Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8458 - acc: 0.5918\n",
            "Epoch 00263: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 397ms/step - loss: 0.8110 - acc: 0.6211 - val_loss: 0.8471 - val_acc: 0.5907\n",
            "Epoch 264/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8426 - acc: 0.6159Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8415 - acc: 0.6191\n",
            "Epoch 00264: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 387ms/step - loss: 0.8385 - acc: 0.6155 - val_loss: 0.8526 - val_acc: 0.6168\n",
            "Epoch 265/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8138 - acc: 0.6212Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8438 - acc: 0.6191\n",
            "Epoch 00265: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 389ms/step - loss: 0.8187 - acc: 0.6205 - val_loss: 0.8446 - val_acc: 0.6187\n",
            "Epoch 266/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8361 - acc: 0.6101Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8637 - acc: 0.5859\n",
            "Epoch 00266: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 393ms/step - loss: 0.8290 - acc: 0.6155 - val_loss: 0.8749 - val_acc: 0.5869\n",
            "Epoch 267/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8179 - acc: 0.6168Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8983 - acc: 0.6113\n",
            "Epoch 00267: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 373ms/step - loss: 0.8205 - acc: 0.6138 - val_loss: 0.8906 - val_acc: 0.6131\n",
            "Epoch 268/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8108 - acc: 0.6141Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8260 - acc: 0.6191\n",
            "Epoch 00268: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 384ms/step - loss: 0.8083 - acc: 0.6143 - val_loss: 0.8379 - val_acc: 0.6150\n",
            "Epoch 269/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8328 - acc: 0.5984Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8834 - acc: 0.6270\n",
            "Epoch 00269: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 380ms/step - loss: 0.8293 - acc: 0.6011 - val_loss: 0.8712 - val_acc: 0.6299\n",
            "Epoch 270/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8300 - acc: 0.6207Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8836 - acc: 0.6270\n",
            "Epoch 00270: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 375ms/step - loss: 0.8322 - acc: 0.6165 - val_loss: 0.8761 - val_acc: 0.6262\n",
            "Epoch 271/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8033 - acc: 0.6302Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8881 - acc: 0.6309\n",
            "Epoch 00271: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 377ms/step - loss: 0.8078 - acc: 0.6294 - val_loss: 0.8811 - val_acc: 0.6299\n",
            "Epoch 272/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8077 - acc: 0.6111Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8856 - acc: 0.6133\n",
            "Epoch 00272: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 378ms/step - loss: 0.8101 - acc: 0.6110 - val_loss: 0.8911 - val_acc: 0.6131\n",
            "Epoch 273/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8059 - acc: 0.6245Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 2s - loss: 0.8645 - acc: 0.6250\n",
            "Epoch 00273: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 5s 335ms/step - loss: 0.8016 - acc: 0.6230 - val_loss: 0.8552 - val_acc: 0.6243\n",
            "Epoch 274/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8172 - acc: 0.6203Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.9594 - acc: 0.5918\n",
            "Epoch 00274: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 357ms/step - loss: 0.8120 - acc: 0.6239 - val_loss: 0.9090 - val_acc: 0.5888\n",
            "Epoch 275/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8042 - acc: 0.6111Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 3s - loss: 0.8473 - acc: 0.6250\n",
            "Epoch 00275: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 380ms/step - loss: 0.8010 - acc: 0.6115 - val_loss: 0.8639 - val_acc: 0.6206\n",
            "Epoch 276/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8043 - acc: 0.6090Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8985 - acc: 0.6152\n",
            "Epoch 00276: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 385ms/step - loss: 0.8050 - acc: 0.6120 - val_loss: 0.9004 - val_acc: 0.6131\n",
            "Epoch 277/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8215 - acc: 0.6234Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8635 - acc: 0.6348\n",
            "Epoch 00277: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 385ms/step - loss: 0.8216 - acc: 0.6249 - val_loss: 0.9160 - val_acc: 0.6299\n",
            "Epoch 278/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8286 - acc: 0.6095Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8694 - acc: 0.6152\n",
            "Epoch 00278: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 390ms/step - loss: 0.8239 - acc: 0.6140 - val_loss: 0.8513 - val_acc: 0.6112\n",
            "Epoch 279/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8151 - acc: 0.6193Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8611 - acc: 0.6211\n",
            "Epoch 00279: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 394ms/step - loss: 0.8189 - acc: 0.6211 - val_loss: 0.8808 - val_acc: 0.6150\n",
            "Epoch 280/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7837 - acc: 0.6351Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9438 - acc: 0.5977\n",
            "Epoch 00280: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 383ms/step - loss: 0.7926 - acc: 0.6299 - val_loss: 0.9699 - val_acc: 0.5944\n",
            "Epoch 281/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8286 - acc: 0.6164Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8948 - acc: 0.6172\n",
            "Epoch 00281: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 384ms/step - loss: 0.8295 - acc: 0.6175 - val_loss: 0.9013 - val_acc: 0.6093\n",
            "Epoch 282/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8274 - acc: 0.6255Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8976 - acc: 0.6504\n",
            "Epoch 00282: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 381ms/step - loss: 0.8296 - acc: 0.6210 - val_loss: 0.9091 - val_acc: 0.6467\n",
            "Epoch 283/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8131 - acc: 0.6229Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8927 - acc: 0.6172\n",
            "Epoch 00283: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 384ms/step - loss: 0.8096 - acc: 0.6226 - val_loss: 0.8964 - val_acc: 0.6112\n",
            "Epoch 284/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.8248 - acc: 0.6244Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.9231 - acc: 0.5820\n",
            "Epoch 00284: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 380ms/step - loss: 0.8235 - acc: 0.6249 - val_loss: 0.9509 - val_acc: 0.5813\n",
            "Epoch 285/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7928 - acc: 0.6164Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8862 - acc: 0.6406\n",
            "Epoch 00285: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 384ms/step - loss: 0.7919 - acc: 0.6185 - val_loss: 0.8900 - val_acc: 0.6355\n",
            "Epoch 286/500\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7899 - acc: 0.6297Epoch 1/500\n",
            " 4/16 [======>.......................] - ETA: 4s - loss: 0.8963 - acc: 0.6191\n",
            "Epoch 00286: val_loss did not improve from 0.80705\n",
            "16/16 [==============================] - 6s 371ms/step - loss: 0.7922 - acc: 0.6309 - val_loss: 0.9257 - val_acc: 0.6131\n",
            "Epoch 00286: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rwrUXkVe-El",
        "colab_type": "code",
        "outputId": "ba2809af-e7c1-400e-ff83-7580fa1af8d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "# History of accuracy and loss\n",
        "tra_loss_3 = history_3.history['loss']\n",
        "tra_acc_3 = history_3.history['acc']\n",
        "val_loss_3 = history_3.history['val_loss']\n",
        "val_acc_3 = history_3.history['val_acc']\n",
        "\n",
        "# Total number of epochs training\n",
        "epochs_3 = range(1, len(tra_acc_3)+1)\n",
        "end_epoch_3 = len(tra_acc_3)\n",
        "\n",
        "# Epoch when reached the validation loss minimum\n",
        "opt_epoch_3 = val_loss_3.index(min(val_loss_3)) + 1\n",
        "\n",
        "# Loss and accuracy on the validation set\n",
        "end_val_loss_3 = val_loss_3[-1]\n",
        "end_val_acc_3 = val_acc_3[-1]\n",
        "opt_val_loss_3 = val_loss_3[opt_epoch_3-1]\n",
        "opt_val_acc_3 = val_acc_3[opt_epoch_3-1]\n",
        "\n",
        "# Loss and accuracy on the test set\n",
        "opt_model_3 = models.load_model('model_3_4cl_best.h5')\n",
        "test_loss_3, test_acc_3 = model_3.evaluate(test_images, test_labels, verbose=False)\n",
        "opt_test_loss_3, opt_test_acc_3 = opt_model_3.evaluate(test_images, test_labels, verbose=False)\n",
        "opt_pred_3 = opt_model_3.predict([test_images, test_labels])\n",
        "pred_classes_3 = np.rint(opt_pred_3)\n",
        "\n",
        "print(\"Model 3\\n\")\n",
        "\n",
        "print(\"Epoch [end]: %d\" % end_epoch_3)\n",
        "print(\"Epoch [opt]: %d\" % opt_epoch_3)\n",
        "print(\"Valid accuracy [end]: %.4f\" % end_val_acc_3)\n",
        "print(\"Valid accuracy [opt]: %.4f\" % opt_val_acc_3)\n",
        "print(\"Test accuracy [end]:  %.4f\" % test_acc_3)\n",
        "print(\"Test accuracy [opt]:  %.4f\" % opt_test_acc_3)\n",
        "print(\"Valid loss [end]: %.4f\" % end_val_loss_3)\n",
        "print(\"Valid loss [opt]: %.4f\" % opt_val_loss_3)\n",
        "print(\"Test loss [end]:  %.4f\" % test_loss_3)\n",
        "print(\"Test loss [opt]:  %.4f\" % opt_test_loss_3)\n",
        "\n",
        "print(classification_report(test_labels, pred_classes_3, digits=4))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 3\n",
            "\n",
            "Epoch [end]: 286\n",
            "Epoch [opt]: 206\n",
            "Valid accuracy [end]: 0.6131\n",
            "Valid accuracy [opt]: 0.5981\n",
            "Test accuracy [end]:  0.6190\n",
            "Test accuracy [opt]:  0.6101\n",
            "Valid loss [end]: 0.9257\n",
            "Valid loss [opt]: 0.8071\n",
            "Test loss [end]:  0.9292\n",
            "Test loss [opt]:  0.9422\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7000    0.4336    0.5355       113\n",
            "           1     0.5333    0.1212    0.1975        66\n",
            "           2     0.7396    0.6698    0.7030       106\n",
            "           3     0.5714    0.3137    0.4051        51\n",
            "\n",
            "   micro avg     0.6890    0.4286    0.5284       336\n",
            "   macro avg     0.6361    0.3846    0.4603       336\n",
            "weighted avg     0.6602    0.4286    0.5022       336\n",
            " samples avg     0.4286    0.4286    0.4286       336\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdAWvBymj1eL",
        "colab_type": "code",
        "outputId": "ea97421d-534f-464f-fe2b-f6108c0bbd13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 991
        }
      },
      "source": [
        "# Model accuracy\n",
        "plt.figure(figsize=(7, 7), dpi=80, facecolor='w', edgecolor='k')\n",
        "plt.title('Model 3 accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.plot(epochs_3, tra_acc_3, 'r', label='Training set')\n",
        "plt.plot(epochs_3, val_acc_3, 'g', label='Validation set')\n",
        "plt.plot(opt_epoch_3, val_acc_3[opt_epoch_3-1], 'go')\n",
        "plt.vlines(opt_epoch_3, min(val_acc_3), opt_val_acc_3, linestyle=\"dashed\", color='g', linewidth=1)\n",
        "plt.hlines(opt_val_acc_3, 1, opt_epoch_3, linestyle=\"dashed\", color='g', linewidth=1)\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "# Model loss\n",
        "plt.figure(figsize=(7, 7), dpi=80, facecolor='w', edgecolor='k')\n",
        "plt.title('Model 3 loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.plot(epochs_3, tra_loss_3, 'r', label='Training set')\n",
        "plt.plot(epochs_3, val_loss_3, 'g', label='Validation set')\n",
        "plt.plot(opt_epoch_3, val_loss_3[opt_epoch_3-1], 'go')\n",
        "plt.vlines(opt_epoch_3, min(val_loss_3), opt_val_loss_3, linestyle=\"dashed\", color='g', linewidth=1)\n",
        "plt.hlines(opt_val_loss_3, 1, opt_epoch_3, linestyle=\"dashed\", color='g', linewidth=1)\n",
        "plt.legend();"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfsAAAHnCAYAAAC/n/QyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 560x560 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfQAAAHnCAYAAABOlK+/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 560x560 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntKW5zoZYf2r",
        "colab_type": "code",
        "outputId": "593fafe8-d5a8-4695-ba12-e9ca19ea8e01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "source": [
        "pred_3_classes = opt_model_3.predict_classes(test_images)\n",
        "confusion_mtx = confusion_matrix(test_labels_raw, pred_3_classes) \n",
        "plot_confusion_matrix(confusion_mtx, classes=range(4), title='Model 3 confusion matrix')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUUAAAEmCAYAAAD1FIKpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+6oBR3advbEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lJb-KXud84i",
        "colab_type": "text"
      },
      "source": [
        "**Result**: after more than 200 epoch, the NN reached a classification accuracy of 61\\%.\n",
        "It is interesting to note how the model is more prone to classify malignant abnormalities as benign rather than viceversa. In a medical context it could be a desirable feature, since false negatives are potentially more harmful than false positives."
      ]
    }
  ]
}